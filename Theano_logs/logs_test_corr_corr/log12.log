.E.ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

FERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(kern, top, TensorConstant{(2,) of 4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(kern, top, TensorConstant{(2,) of 4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(kern, top, TensorConstant{(2,) of 4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

FERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((1, 2), (2, 1)), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

F....ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((2, 0), 0), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(2, 2, 3, 1), filter_dilation=(1, 1), num_groups=1, unshared=False}(InplaceDimShuffle{0,1,2,x}.0, IncSubtensor{Inc;::, ::, ::, int64}.0, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((2, 0), 0), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(2, 2, 3, 1), filter_dilation=(1, 1), num_groups=1, unshared=False}(InplaceDimShuffle{0,1,2,x}.0, IncSubtensor{Inc;::, ::, ::, int64}.0, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((2, 0), 0), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(2, 2, 3, 1), filter_dilation=(1, 1), num_groups=1, unshared=False}(InplaceDimShuffle{0,1,2,x}.0, IncSubtensor{Inc;::, ::, ::, int64}.0, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((2, 0), 0), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(2, 2, 3, 1), filter_dilation=(1, 1), num_groups=1, unshared=False}(InplaceDimShuffle{0,1,2,x}.0, IncSubtensor{Inc;::, ::, ::, int64}.0, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode=((2, 0), 0), subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(2, 2, 3, 1), filter_dilation=(1, 1), num_groups=1, unshared=False}(InplaceDimShuffle{0,1,2,x}.0, IncSubtensor{Inc;::, ::, ::, int64}.0, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

F.C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py:283: DeprecationWarning: Please use assertEqual instead.
  assert_equals(f(a_tens_val, b_tens_val).dtype, c_dtype)
C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py:283: DeprecationWarning: Please use assertEqual instead.
  assert_equals(f(a_tens_val, b_tens_val).dtype, c_dtype)
C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py:283: DeprecationWarning: Please use assertEqual instead.
  assert_equals(f(a_tens_val, b_tens_val).dtype, c_dtype)
C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py:283: DeprecationWarning: Please use assertEqual instead.
  assert_equals(f(a_tens_val, b_tens_val).dtype, c_dtype)
EEEE.E..EEE.ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

FERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(kern, top, TensorConstant{(2,) of 5})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(kern, top, TensorConstant{(2,) of 5})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(kern, top, TensorConstant{(2,) of 5})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

FERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None), filter_dilation=(1, 1), num_groups=3, unshared=False}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

F....ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(input 1, random_projection, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

FERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(kern, top, TensorConstant{(2,) of 4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(kern, top, TensorConstant{(2,) of 4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(kern, top, TensorConstant{(2,) of 4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

FERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: LocalOptGroup(local_abstractconv_gemm,local_abstractconv_gradweight_gemm,local_abstractconv_gradinputs_gemm,local_abstractconv3d_gemm,local_abstractconv3d_gradweight_gemm,local_abstractconv3d_gradinputs_gemm,local_conv2d_cpu,local_conv2d_gradweight_cpu,local_conv2d_gradinputs_cpu)
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1381, in transform
    new_repl = opt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 204, in local_abstractconv_gradinputs_gemm
    unshared=node.op.unshared)(kern, topgrad, shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

ERROR (theano.gof.opt): Optimization failure due to: local_abstractconv_check
ERROR (theano.gof.opt): node: AbstractConv2d_gradInputs{convdim=2, border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(None, None, None, None, None, None), filter_dilation=(1, 1), num_groups=1, unshared=True}(random_projection, input 1, MakeVector{dtype='int64'}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

F
======================================================================
ERROR: test_gradinputs (theano.tensor.nnet.tests.test_abstract_conv.Grouped_conv_noOptim)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1628, in test_gradinputs
    filter_dilation=self.filter_dilation)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 63, in conv2d_corr_gi
    filter_dilation)(filters,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_dtype_upcast (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 281, in test_dtype_upcast
    c_tens = op()(a_tens, b_tens)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_filter_dilation (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 196, in test_filter_dilation
    self.validate((3, 2, 7, 5), (5, 2, 2, 3), 'valid', filter_dilation=(2, 2))
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 142, in validate
    mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1770, in verify_grad
    disconnected_inputs='ignore')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 605, in grad
    grad_dict, wrt, cost_name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1326, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1162, in access_term_cache
    new_output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\op.py", line 711, in L_op
    return self.grad(inputs, output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 674, in grad
    self.unshared)(weights, top,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_full_mode (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 242, in test_full_mode
    self.validate((3, 2, 5, 5), (4, 2, 8, 8), 'full')
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 142, in validate
    mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1770, in verify_grad
    disconnected_inputs='ignore')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 605, in grad
    grad_dict, wrt, cost_name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1326, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1162, in access_term_cache
    new_output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\op.py", line 711, in L_op
    return self.grad(inputs, output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 674, in grad
    self.unshared)(weights, top,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_img_kernel_same_shape (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 165, in test_img_kernel_same_shape
    self.validate((3, 2, 3, 3), (4, 2, 3, 3), 'full')
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 142, in validate
    mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1770, in verify_grad
    disconnected_inputs='ignore')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 605, in grad
    grad_dict, wrt, cost_name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1326, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1162, in access_term_cache
    new_output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\op.py", line 711, in L_op
    return self.grad(inputs, output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 674, in grad
    self.unshared)(weights, top,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_infer_shape_gradI (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 392, in test_infer_shape_gradI
    subsample=subsample)(bdtens, cdtens, shape=shape)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_non_contiguous (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 399, in test_non_contiguous
    self.validate((2, 2, 3, 3), (2, 2, 2, 2), 'valid', non_contiguous=True)
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 142, in validate
    mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1770, in verify_grad
    disconnected_inputs='ignore')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 605, in grad
    grad_dict, wrt, cost_name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1326, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1162, in access_term_cache
    new_output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\op.py", line 711, in L_op
    return self.grad(inputs, output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 674, in grad
    self.unshared)(weights, top,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_shape_Constant_tensor (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 223, in test_shape_Constant_tensor
    (5, 2, 2, 3), border_mode)
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 142, in validate
    mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1770, in verify_grad
    disconnected_inputs='ignore')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 605, in grad
    grad_dict, wrt, cost_name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1326, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1162, in access_term_cache
    new_output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\op.py", line 711, in L_op
    return self.grad(inputs, output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 674, in grad
    self.unshared)(weights, top,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
ERROR: test_subsample (test_corr.TestCorr2D)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 175, in test_subsample
    self.validate((3, 2, 7, 5), (5, 2, 2, 3), 'valid', subsample=(2, 2))
  File "C:\Users\mutation\Desktop\theano-testcase\tests\test_corr.py", line 142, in validate
    mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1770, in verify_grad
    disconnected_inputs='ignore')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 605, in grad
    grad_dict, wrt, cost_name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1371, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1326, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1162, in access_term_cache
    new_output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\op.py", line 711, in L_op
    return self.grad(inputs, output_grads)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 674, in grad
    self.unshared)(weights, top,
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\corr.py", line 114, in __init__
    raise ValueError("_direction must be one of 'forward', "
ValueError: _direction must be one of 'forward', 'backprop weights', 'backprop inputs'

======================================================================
FAIL: test_fwd (test_corr.TestAsymmetricCorr)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1998, in test_fwd
    utt.verify_grad(asymmetric_conv_op, [img, kern], mode=self.mode, eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_gradinput (test_corr.TestAsymmetricCorr)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 2053, in test_gradinput
    asymmetric_func = theano.function([kern_sym, top_sym], asymmetric_out_sym, mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_gradweight (test_corr.TestAsymmetricCorr)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 2038, in test_gradweight
    utt.verify_grad(conv_gradweight, [img, top], mode=self.mode, eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_interface (test_corr.TestCausalCorr)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 2107, in test_interface
    utt.verify_grad(causal_conv_fn, [self.img, self.kern], mode=self.mode, eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_fwd (test_corr.TestGroupCorr2d)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1546, in test_fwd
    eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_gradinputs (test_corr.TestGroupCorr2d)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1618, in test_gradinputs
    grouped_func = theano.function([kern_sym, top_sym], grouped_conv_output, mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_gradweights (test_corr.TestGroupCorr2d)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1595, in test_gradweights
    mode=self.mode, eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_fwd (test_corr.TestUnsharedCorr2d)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1860, in test_fwd
    utt.verify_grad(unshared_conv_op, [img, kern], mode=self.mode, eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_gradinput (test_corr.TestUnsharedCorr2d)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1920, in test_gradinput
    unshared_func = theano.function([kern_sym, top_sym], unshared_out_sym, mode=self.mode)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

======================================================================
FAIL: test_gradweight (test_corr.TestUnsharedCorr2d)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\tests\test_abstract_conv.py", line 1900, in test_gradweight
    utt.verify_grad(conv_gradweight, [img, top], mode=self.mode, eps=1)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tests\unittest_tools.py", line 92, in verify_grad
    T.verify_grad(op, pt, n_tests, rng, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1773, in verify_grad
    name='gradient.py symbolic grad')
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gradient.py", line 1718, in function
    on_unused_input='ignore', name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function.py", line 317, in function
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1839, in orig_function
    name=name)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\compile\function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 108, in __call__
    return self.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 251, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 97, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2143, in apply
    nb += self.process_node(fgraph, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2039, in process_node
    lopt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1933, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 1919, in warn
    raise exc
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\gof\opt.py", line 2034, in process_node
    replacements = lopt.transform(node)
  File "C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\theano\tensor\nnet\opt.py", line 500, in local_abstractconv_check
    node.op.__class__.__name__)
theano.gof.opt.LocalMetaOptimizerSkipAssertionError: AbstractConv2d_gradInputs Theano optimization failed: there is no implementation available supporting the requested options. Did you exclude both "conv_dnn" and "conv_gemm" from the optimizer? If on GPU, is cuDNN available and does the GPU support it? If on CPU, do you have a BLAS library installed Theano can link against? On the CPU we do not support float16.

----------------------------------------------------------------------
Ran 34 tests in 48.468s

FAILED (failures=10, errors=9)
