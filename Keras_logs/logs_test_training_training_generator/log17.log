2020-10-04 14:41:34.655174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py ....F..s..........................                      [100%]

================================== FAILURES ===================================
_____________________________ test_fit_generator ______________________________

    @flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))
    def test_fit_generator():
        model = get_model(num_outputs=2)
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
    
        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
                      sample_weight_mode=None)
        tracker_cb = TrackerCallback()
        val_seq = RandomSequence(4)
        out = model.fit_generator(generator=RandomSequence(3),
                                  steps_per_epoch=3,
                                  epochs=5,
                                  initial_epoch=0,
                                  validation_data=val_seq,
                                  validation_steps=3,
                                  max_queue_size=1,
                                  callbacks=[tracker_cb])
        assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]
>       assert tracker_cb.trained_batches == list(range(3)) * 5
E       assert [0, 1, 2, 0, 1, 2, ...] == [0, 1, 2, 0, 1, 2, ...]
E         At index 6 diff: 3 != 0
E         Left contains 36 more items, first extra item: 0
E         Use -v to get the full diff

test_training.py:492: AssertionError
---------------------------- Captured stdout call -----------------------------
Epoch 1/5

1/3 [=========>....................] - ETA: 0s - loss: 1.3000 - dense_1_loss: 0.9734 - dropout_loss: 0.6531
3/3 [==============================] - 0s 52ms/step - loss: 0.9199 - dense_1_loss: 0.6123 - dropout_loss: 0.6153 - val_loss: 0.4726 - val_dense_1_loss: 0.5564 - val_dropout_loss: 0.1689
Epoch 2/5

 1/12 [=>............................] - ETA: 0s - loss: 0.9422 - dense_1_loss: 0.5648 - dropout_loss: 0.7547
 8/12 [===================>..........] - ETA: 0s - loss: 0.8153 - dense_1_loss: 0.5601 - dropout_loss: 0.5103
10/12 [========================>.....] - ETA: 0s - loss: 0.7864 - dense_1_loss: 0.5351 - dropout_loss: 0.5028
12/12 [==============================] - 0s 18ms/step - loss: 0.7884 - dense_1_loss: 0.5513 - dropout_loss: 0.4741 - val_loss: 0.3475 - val_dense_1_loss: 0.4886 - val_dropout_loss: 0.1341
Epoch 3/5

 1/12 [=>............................] - ETA: 0s - loss: 0.8815 - dense_1_loss: 0.6729 - dropout_loss: 0.4172
 9/12 [=====================>........] - ETA: 0s - loss: 0.6507 - dense_1_loss: 0.4625 - dropout_loss: 0.3763
10/12 [========================>.....] - ETA: 0s - loss: 0.6377 - dense_1_loss: 0.4499 - dropout_loss: 0.3756
12/12 [==============================] - 0s 17ms/step - loss: 0.6280 - dense_1_loss: 0.4164 - dropout_loss: 0.4232 - val_loss: 0.6789 - val_dense_1_loss: 0.6009 - val_dropout_loss: 0.1760
Epoch 4/5

 1/12 [=>............................] - ETA: 0s - loss: 0.7278 - dense_1_loss: 0.6707 - dropout_loss: 0.1141
 8/12 [===================>..........] - ETA: 0s - loss: 0.7746 - dense_1_loss: 0.5961 - dropout_loss: 0.3569
10/12 [========================>.....] - ETA: 0s - loss: 0.7814 - dense_1_loss: 0.5973 - dropout_loss: 0.3682
12/12 [==============================] - 0s 18ms/step - loss: 0.7567 - dense_1_loss: 0.5551 - dropout_loss: 0.4033 - val_loss: 0.5583 - val_dense_1_loss: 0.5046 - val_dropout_loss: 0.1969
Epoch 5/5

 1/12 [=>............................] - ETA: 0s - loss: 0.7539 - dense_1_loss: 0.3387 - dropout_loss: 0.8304
 9/12 [=====================>........] - ETA: 0s - loss: 0.7332 - dense_1_loss: 0.4363 - dropout_loss: 0.5939
10/12 [========================>.....] - ETA: 0s - loss: 0.7276 - dense_1_loss: 0.4480 - dropout_loss: 0.5593
12/12 [==============================] - 0s 17ms/step - loss: 0.7011 - dense_1_loss: 0.4370 - dropout_loss: 0.5281 - val_loss: 0.3006 - val_dense_1_loss: 0.4822 - val_dropout_loss: 0.1261
---------------------------- Captured stderr call -----------------------------
2020-10-04 14:41:43.205909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-04 14:41:43.206554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-04 14:41:43.206928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-04 14:41:43.207308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-04 14:41:43.207649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-04 14:41:43.207993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-04 14:41:43.208342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-04 14:41:43.208697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-04 14:41:43.209290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-04 14:41:43.209607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-04 14:41:43.209969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-04 14:41:43.210194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-04 14:41:43.210720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
---------------------------- Captured stdout call -----------------------------
Epoch 1/5

1/3 [=========>....................] - ETA: 0s - loss: 1.1608 - dense_1_loss: 0.8910 - dropout_loss: 0.5395
3/3 [==============================] - 0s 52ms/step - loss: 0.8207 - dense_1_loss: 0.5821 - dropout_loss: 0.4772 - val_loss: 0.4751 - val_dense_1_loss: 0.5518 - val_dropout_loss: 0.1281
Epoch 2/5

 1/12 [=>............................] - ETA: 0s - loss: 0.6830 - dense_1_loss: 0.4141 - dropout_loss: 0.5378
 9/12 [=====================>........] - ETA: 0s - loss: 0.7979 - dense_1_loss: 0.5189 - dropout_loss: 0.5580
10/12 [========================>.....] - ETA: 0s - loss: 0.7947 - dense_1_loss: 0.5231 - dropout_loss: 0.5430
12/12 [==============================] - 0s 16ms/step - loss: 0.7704 - dense_1_loss: 0.5131 - dropout_loss: 0.5145 - val_loss: 0.6972 - val_dense_1_loss: 0.5893 - val_dropout_loss: 0.1704
Epoch 3/5

 1/12 [=>............................] - ETA: 0s - loss: 0.4846 - dense_1_loss: 0.2170 - dropout_loss: 0.5353
 9/12 [=====================>........] - ETA: 0s - loss: 0.6716 - dense_1_loss: 0.4443 - dropout_loss: 0.4544
10/12 [========================>.....] - ETA: 0s - loss: 0.6846 - dense_1_loss: 0.4530 - dropout_loss: 0.4632
12/12 [==============================] - 0s 17ms/step - loss: 0.7095 - dense_1_loss: 0.4752 - dropout_loss: 0.4685 - val_loss: 0.5824 - val_dense_1_loss: 0.5764 - val_dropout_loss: 0.1778
Epoch 4/5

 1/12 [=>............................] - ETA: 0s - loss: 1.1278 - dense_1_loss: 0.7584 - dropout_loss: 0.7388
 9/12 [=====================>........] - ETA: 0s - loss: 0.8448 - dense_1_loss: 0.5392 - dropout_loss: 0.6113
10/12 [========================>.....] - ETA: 0s - loss: 0.8404 - dense_1_loss: 0.5418 - dropout_loss: 0.5973
12/12 [==============================] - 0s 16ms/step - loss: 0.8319 - dense_1_loss: 0.5447 - dropout_loss: 0.5743 - val_loss: 0.4576 - val_dense_1_loss: 0.4817 - val_dropout_loss: 0.1996
Epoch 5/5

 1/12 [=>............................] - ETA: 0s - loss: 0.7507 - dense_1_loss: 0.6618 - dropout_loss: 0.1779
 9/12 [=====================>........] - ETA: 0s - loss: 0.7334 - dense_1_loss: 0.4699 - dropout_loss: 0.5270
10/12 [========================>.....] - ETA: 0s - loss: 0.7121 - dense_1_loss: 0.4623 - dropout_loss: 0.4995
12/12 [==============================] - 0s 16ms/step - loss: 0.7243 - dense_1_loss: 0.4471 - dropout_loss: 0.5544 - val_loss: 0.3216 - val_dense_1_loss: 0.3943 - val_dropout_loss: 0.1367
---------------------------- Captured stderr call -----------------------------
2020-10-04 14:42:15.542490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-04 14:42:15.543099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-04 14:42:15.543448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-04 14:42:15.543797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-04 14:42:15.544137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-04 14:42:15.544480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-04 14:42:15.544827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-04 14:42:15.545196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-04 14:42:15.545784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-04 14:42:15.546102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-04 14:42:15.546461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-04 14:42:15.546686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-04 14:42:15.547221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_methods
test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_methods
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods passed 1 out of the required 1 times. Success!
test_fit_generator failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	assert [0, 1, 2, 0, 1, 2, ...] == [0, 1, 2, 0, 1, 2, ...]
  At index 6 diff: 3 != 0
  Left contains 36 more items, first extra item: 0
  Use -v to get the full diff
	[<TracebackEntry C:\Users\mutation\Desktop\testcase\tests\keras\engine\test_training.py:492>]
test_fit_generator failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	assert [0, 1, 2, 0, 1, 2, ...] == [0, 1, 2, 0, 1, 2, ...]
  At index 6 diff: 3 != 0
  Left contains 36 more items, first extra item: 0
  Use -v to get the full diff
	[<TracebackEntry C:\Users\mutation\Desktop\testcase\tests\keras\engine\test_training.py:492>]

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_fit_generator - assert [0, 1, 2, 0, 1, 2, ...] ...
======= 1 failed, 32 passed, 1 skipped, 7 warnings in 88.23s (0:01:28) ========
