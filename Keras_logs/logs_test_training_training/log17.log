2020-10-03 18:57:39.505204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py .......s...............F....F..FF.                      [100%]

================================== FAILURES ===================================
___________________________ test_dynamic_set_inputs ___________________________

    def test_dynamic_set_inputs():
        model = Sequential()
        model.add(Dense(16, input_dim=32))
        model.add(Activation('relu'))
    
        model2 = Sequential()
        model2.add(model.layers[-1])
        model2.add(Dense(8))
        preds2 = model2.predict([np.random.random((1, 32))])
        assert preds2.shape == (1, 8)
    
        model3 = Model(inputs=model.inputs, outputs=model.outputs)
        with pytest.raises(ValueError):
            model3._set_inputs(model.inputs)
    
        model3.inputs = None
>       model3._set_inputs(model.inputs)

test_training.py:1653: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000002159488F208>
inputs = [<tf.Tensor 'dense_1_input:0' shape=(?, 32) dtype=float32>]
outputs = [<tf.Tensor 'activation_1_2/Relu:0' shape=(?, 16) dtype=float32>]
training = None

    def _set_inputs(self, inputs, outputs=None, training=None):
        """Set model's input and output specs based on the input data received.
    
        This is to be used for Model subclasses, which do not know at instantiation
        time what their inputs look like.
    
        # Arguments
            inputs: Single array, or list of arrays. The arrays could be
                placeholders, Numpy arrays, or data tensors.
                - if placeholders: the model is built on top of these
                  placeholders, and we expect Numpy data to be fed for them
                  when calling `fit`/etc.
                - if Numpy data: we create placeholders matching the shape of
                  the Numpy arrays. We expect Numpy data to be fed for these
                  placeholders when calling `fit`/etc.
                - if data tensors: the model is built on top of these tensors.
                  We do not expect any Numpy data to be provided when calling
                  `fit`/etc.
            outputs: Optional output tensors (if already computed by running
                the model).
            training: Boolean or None. Only relevant in symbolic mode.
                Specifies whether to build the model's graph in inference
                mode (False), training mode (True), or using the Keras
                learning phase (None).
        """
        if self.__class__.__name__ == 'Sequential':
            # Note: we can't test whether the model
            # is `Sequential` via `isinstance`
            # since `Sequential` depends on `Model`.
            if isinstance(inputs, list):
                assert len(inputs) == 1
                inputs = inputs[0]
            self.build(input_shape=(None,) + inputs.shape[1:])
            return
    
        if self.inputs:
            raise ValueError('Model inputs are already set.')
    
        # On-the-fly setting of symbolic model inputs
        # (either by using the tensor provided,
        # or by creating a placeholder if Numpy data was provided).
        self.inputs = []
        self.input_names = []
        self._feed_inputs = []
        self._feed_input_names = []
        self._feed_input_shapes = []
        inputs = to_list(inputs, allow_tuple=True)
    
        for i, v in enumerate(inputs):
            name = 'input_%d' % (i + 1)
            self.input_names.append(name)
            if isinstance(v, list):
                v = np.asarray(v)
                if v.ndim == 1:
                    v = np.expand_dims(v, 1)
            if isinstance(v, (np.ndarray)):
                # We fix the placeholder shape except the batch size.
                # This is suboptimal, but it is the best we can do with the info
                # we have. The user should call `model._set_inputs(placeholders)`
                # to specify custom placeholders if the need arises.
                shape = (None,) + v.shape[1:]
                placeholder = K.placeholder(shape=shape, name=name)
                self.inputs.append(placeholder)
                self._feed_inputs.append(placeholder)
                self._feed_input_names.append(name)
                self._feed_input_shapes.append(shape)
            else:
                # Assumed tensor - TODO(fchollet) additional type check?
                self.inputs.append(v)
                if K.is_placeholder(v):
                    self._feed_inputs.append(v)
                    self._feed_input_names.append(name)
                    self._feed_input_shapes.append(K.int_shape(v))
    
        if outputs is None:
            # Obtain symbolic outputs by calling the model.
            if self._expects_training_arg:
                outputs = self.call(unpack_singleton(self.inputs), training=training)
            else:
                outputs = self.call(unpack_singleton(self.inputs))
        outputs = to_list(outputs, allow_tuple=True)
        self.outputs = None
        self.output_names = [
>           'output_%d' % (i + 1) for i in range(len(self.outputs))]
E       TypeError: object of type 'NoneType' has no len()

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:467: TypeError
---------------------------- Captured stderr call -----------------------------
2020-10-03 18:58:07.538581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:07.539166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:07.539512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:07.539857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:07.540194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:07.540535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:07.540880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:07.541242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:07.541827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:07.542141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 18:58:07.542503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 18:58:07.542724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 18:58:07.543266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
_______________________ test_model_metrics_list_in_call _______________________

    def test_model_metrics_list_in_call():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2)
    
            def call(self, x):
                self.add_metric(K.sum(x), name='metric_2')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(
            loss='mse',
            optimizer='adam',
            metrics=[metrics.MeanSquaredError('metric_1')])
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1822: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:504: in _standardize_user_data
    self._set_inputs(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_model_metrics_list_in_call.<locals>.TestModel object at 0x000002182982B8D0>
inputs = [array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])]
outputs = [<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 2) dtype=float32>]
training = None

    def _set_inputs(self, inputs, outputs=None, training=None):
        """Set model's input and output specs based on the input data received.
    
        This is to be used for Model subclasses, which do not know at instantiation
        time what their inputs look like.
    
        # Arguments
            inputs: Single array, or list of arrays. The arrays could be
                placeholders, Numpy arrays, or data tensors.
                - if placeholders: the model is built on top of these
                  placeholders, and we expect Numpy data to be fed for them
                  when calling `fit`/etc.
                - if Numpy data: we create placeholders matching the shape of
                  the Numpy arrays. We expect Numpy data to be fed for these
                  placeholders when calling `fit`/etc.
                - if data tensors: the model is built on top of these tensors.
                  We do not expect any Numpy data to be provided when calling
                  `fit`/etc.
            outputs: Optional output tensors (if already computed by running
                the model).
            training: Boolean or None. Only relevant in symbolic mode.
                Specifies whether to build the model's graph in inference
                mode (False), training mode (True), or using the Keras
                learning phase (None).
        """
        if self.__class__.__name__ == 'Sequential':
            # Note: we can't test whether the model
            # is `Sequential` via `isinstance`
            # since `Sequential` depends on `Model`.
            if isinstance(inputs, list):
                assert len(inputs) == 1
                inputs = inputs[0]
            self.build(input_shape=(None,) + inputs.shape[1:])
            return
    
        if self.inputs:
            raise ValueError('Model inputs are already set.')
    
        # On-the-fly setting of symbolic model inputs
        # (either by using the tensor provided,
        # or by creating a placeholder if Numpy data was provided).
        self.inputs = []
        self.input_names = []
        self._feed_inputs = []
        self._feed_input_names = []
        self._feed_input_shapes = []
        inputs = to_list(inputs, allow_tuple=True)
    
        for i, v in enumerate(inputs):
            name = 'input_%d' % (i + 1)
            self.input_names.append(name)
            if isinstance(v, list):
                v = np.asarray(v)
                if v.ndim == 1:
                    v = np.expand_dims(v, 1)
            if isinstance(v, (np.ndarray)):
                # We fix the placeholder shape except the batch size.
                # This is suboptimal, but it is the best we can do with the info
                # we have. The user should call `model._set_inputs(placeholders)`
                # to specify custom placeholders if the need arises.
                shape = (None,) + v.shape[1:]
                placeholder = K.placeholder(shape=shape, name=name)
                self.inputs.append(placeholder)
                self._feed_inputs.append(placeholder)
                self._feed_input_names.append(name)
                self._feed_input_shapes.append(shape)
            else:
                # Assumed tensor - TODO(fchollet) additional type check?
                self.inputs.append(v)
                if K.is_placeholder(v):
                    self._feed_inputs.append(v)
                    self._feed_input_names.append(name)
                    self._feed_input_shapes.append(K.int_shape(v))
    
        if outputs is None:
            # Obtain symbolic outputs by calling the model.
            if self._expects_training_arg:
                outputs = self.call(unpack_singleton(self.inputs), training=training)
            else:
                outputs = self.call(unpack_singleton(self.inputs))
        outputs = to_list(outputs, allow_tuple=True)
        self.outputs = None
        self.output_names = [
>           'output_%d' % (i + 1) for i in range(len(self.outputs))]
E       TypeError: object of type 'NoneType' has no len()

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:467: TypeError
________________________ test_add_metric_in_model_call ________________________

    def test_add_metric_in_model_call():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean = metrics.Mean(name='metric_1')
    
            def call(self, x):
                self.add_metric(K.sum(x), name='metric_2')
                # Provide same name as in the instance created in __init__
                # for eager mode
                self.add_metric(self.mean(x), name='metric_1')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='sgd')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:504: in _standardize_user_data
    self._set_inputs(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_add_metric_in_model_call.<locals>.TestModel object at 0x00000215D3F96668>
inputs = [array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])]
outputs = [<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 2) dtype=float32>]
training = None

    def _set_inputs(self, inputs, outputs=None, training=None):
        """Set model's input and output specs based on the input data received.
    
        This is to be used for Model subclasses, which do not know at instantiation
        time what their inputs look like.
    
        # Arguments
            inputs: Single array, or list of arrays. The arrays could be
                placeholders, Numpy arrays, or data tensors.
                - if placeholders: the model is built on top of these
                  placeholders, and we expect Numpy data to be fed for them
                  when calling `fit`/etc.
                - if Numpy data: we create placeholders matching the shape of
                  the Numpy arrays. We expect Numpy data to be fed for these
                  placeholders when calling `fit`/etc.
                - if data tensors: the model is built on top of these tensors.
                  We do not expect any Numpy data to be provided when calling
                  `fit`/etc.
            outputs: Optional output tensors (if already computed by running
                the model).
            training: Boolean or None. Only relevant in symbolic mode.
                Specifies whether to build the model's graph in inference
                mode (False), training mode (True), or using the Keras
                learning phase (None).
        """
        if self.__class__.__name__ == 'Sequential':
            # Note: we can't test whether the model
            # is `Sequential` via `isinstance`
            # since `Sequential` depends on `Model`.
            if isinstance(inputs, list):
                assert len(inputs) == 1
                inputs = inputs[0]
            self.build(input_shape=(None,) + inputs.shape[1:])
            return
    
        if self.inputs:
            raise ValueError('Model inputs are already set.')
    
        # On-the-fly setting of symbolic model inputs
        # (either by using the tensor provided,
        # or by creating a placeholder if Numpy data was provided).
        self.inputs = []
        self.input_names = []
        self._feed_inputs = []
        self._feed_input_names = []
        self._feed_input_shapes = []
        inputs = to_list(inputs, allow_tuple=True)
    
        for i, v in enumerate(inputs):
            name = 'input_%d' % (i + 1)
            self.input_names.append(name)
            if isinstance(v, list):
                v = np.asarray(v)
                if v.ndim == 1:
                    v = np.expand_dims(v, 1)
            if isinstance(v, (np.ndarray)):
                # We fix the placeholder shape except the batch size.
                # This is suboptimal, but it is the best we can do with the info
                # we have. The user should call `model._set_inputs(placeholders)`
                # to specify custom placeholders if the need arises.
                shape = (None,) + v.shape[1:]
                placeholder = K.placeholder(shape=shape, name=name)
                self.inputs.append(placeholder)
                self._feed_inputs.append(placeholder)
                self._feed_input_names.append(name)
                self._feed_input_shapes.append(shape)
            else:
                # Assumed tensor - TODO(fchollet) additional type check?
                self.inputs.append(v)
                if K.is_placeholder(v):
                    self._feed_inputs.append(v)
                    self._feed_input_names.append(name)
                    self._feed_input_shapes.append(K.int_shape(v))
    
        if outputs is None:
            # Obtain symbolic outputs by calling the model.
            if self._expects_training_arg:
                outputs = self.call(unpack_singleton(self.inputs), training=training)
            else:
                outputs = self.call(unpack_singleton(self.inputs))
        outputs = to_list(outputs, allow_tuple=True)
        self.outputs = None
        self.output_names = [
>           'output_%d' % (i + 1) for i in range(len(self.outputs))]
E       TypeError: object of type 'NoneType' has no len()

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:467: TypeError
_______________________ test_multiple_add_metric_calls ________________________

    def test_multiple_add_metric_calls():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean1 = metrics.Mean(name='metric_1')
                self.mean2 = metrics.Mean(name='metric_2')
    
            def call(self, x):
                self.add_metric(self.mean2(x), name='metric_2')
                self.add_metric(self.mean1(x), name='metric_1')
                self.add_metric(K.sum(x), name='metric_3')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='sgd')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1946: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:504: in _standardize_user_data
    self._set_inputs(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_multiple_add_metric_calls.<locals>.TestModel object at 0x000002158E1A1CC0>
inputs = [array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])]
outputs = [<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 2) dtype=float32>]
training = None

    def _set_inputs(self, inputs, outputs=None, training=None):
        """Set model's input and output specs based on the input data received.
    
        This is to be used for Model subclasses, which do not know at instantiation
        time what their inputs look like.
    
        # Arguments
            inputs: Single array, or list of arrays. The arrays could be
                placeholders, Numpy arrays, or data tensors.
                - if placeholders: the model is built on top of these
                  placeholders, and we expect Numpy data to be fed for them
                  when calling `fit`/etc.
                - if Numpy data: we create placeholders matching the shape of
                  the Numpy arrays. We expect Numpy data to be fed for these
                  placeholders when calling `fit`/etc.
                - if data tensors: the model is built on top of these tensors.
                  We do not expect any Numpy data to be provided when calling
                  `fit`/etc.
            outputs: Optional output tensors (if already computed by running
                the model).
            training: Boolean or None. Only relevant in symbolic mode.
                Specifies whether to build the model's graph in inference
                mode (False), training mode (True), or using the Keras
                learning phase (None).
        """
        if self.__class__.__name__ == 'Sequential':
            # Note: we can't test whether the model
            # is `Sequential` via `isinstance`
            # since `Sequential` depends on `Model`.
            if isinstance(inputs, list):
                assert len(inputs) == 1
                inputs = inputs[0]
            self.build(input_shape=(None,) + inputs.shape[1:])
            return
    
        if self.inputs:
            raise ValueError('Model inputs are already set.')
    
        # On-the-fly setting of symbolic model inputs
        # (either by using the tensor provided,
        # or by creating a placeholder if Numpy data was provided).
        self.inputs = []
        self.input_names = []
        self._feed_inputs = []
        self._feed_input_names = []
        self._feed_input_shapes = []
        inputs = to_list(inputs, allow_tuple=True)
    
        for i, v in enumerate(inputs):
            name = 'input_%d' % (i + 1)
            self.input_names.append(name)
            if isinstance(v, list):
                v = np.asarray(v)
                if v.ndim == 1:
                    v = np.expand_dims(v, 1)
            if isinstance(v, (np.ndarray)):
                # We fix the placeholder shape except the batch size.
                # This is suboptimal, but it is the best we can do with the info
                # we have. The user should call `model._set_inputs(placeholders)`
                # to specify custom placeholders if the need arises.
                shape = (None,) + v.shape[1:]
                placeholder = K.placeholder(shape=shape, name=name)
                self.inputs.append(placeholder)
                self._feed_inputs.append(placeholder)
                self._feed_input_names.append(name)
                self._feed_input_shapes.append(shape)
            else:
                # Assumed tensor - TODO(fchollet) additional type check?
                self.inputs.append(v)
                if K.is_placeholder(v):
                    self._feed_inputs.append(v)
                    self._feed_input_names.append(name)
                    self._feed_input_shapes.append(K.int_shape(v))
    
        if outputs is None:
            # Obtain symbolic outputs by calling the model.
            if self._expects_training_arg:
                outputs = self.call(unpack_singleton(self.inputs), training=training)
            else:
                outputs = self.call(unpack_singleton(self.inputs))
        outputs = to_list(outputs, allow_tuple=True)
        self.outputs = None
        self.output_names = [
>           'output_%d' % (i + 1) for i in range(len(self.outputs))]
E       TypeError: object of type 'NoneType' has no len()

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:467: TypeError
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_methods
test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_methods
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods passed 1 out of the required 1 times. Success!
test_fit_generator passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_dynamic_set_inputs - TypeError: object of type ...
FAILED test_training.py::test_model_metrics_list_in_call - TypeError: object ...
FAILED test_training.py::test_add_metric_in_model_call - TypeError: object of...
FAILED test_training.py::test_multiple_add_metric_calls - TypeError: object o...
============ 4 failed, 29 passed, 1 skipped, 7 warnings in 28.94s =============
