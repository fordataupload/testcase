2020-10-03 19:02:28.985107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py .......s.....F.F..................                      [100%]

================================== FAILURES ===================================
______________________ test_model_with_input_feed_tensor ______________________

    @pytest.mark.skipif(K.backend() != 'tensorflow',
                        reason='Requires TensorFlow backend')
    def test_model_with_input_feed_tensor():
        """We test building a model with a TF variable as input.
        We should be able to call fit, evaluate, predict,
        by only passing them data for the placeholder inputs
        in the model.
        """
        import tensorflow as tf
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))
        b = Input(shape=(3,), name='input_b')
    
        a_2 = Dense(4, name='dense_1')(a)
        dp = Dropout(0.5, name='dropout')
        b_2 = dp(b)
    
        model = Model([a, b], [a_2, b_2])
        model.summary()
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
        model.compile(optimizer, loss, metrics=['mean_squared_error'],
                      loss_weights=loss_weights,
                      sample_weight_mode=None)
    
        # test train_on_batch
        out = model.train_on_batch(input_b_np,
                                   [output_a_np, output_b_np])
        out = model.train_on_batch({'input_b': input_b_np},
                                   [output_a_np, output_b_np])
        out = model.test_on_batch({'input_b': input_b_np},
                                  [output_a_np, output_b_np])
        out = model.predict_on_batch({'input_b': input_b_np})
    
        # test fit
        out = model.fit({'input_b': input_b_np},
                        [output_a_np, output_b_np], epochs=1, batch_size=10)
        out = model.fit(input_b_np,
                        [output_a_np, output_b_np], epochs=1, batch_size=10)
    
        # test evaluate
        out = model.evaluate({'input_b': input_b_np},
                             [output_a_np, output_b_np], batch_size=10)
        out = model.evaluate(input_b_np,
                             [output_a_np, output_b_np], batch_size=10)
    
        # test predict
        out = model.predict({'input_b': input_b_np}, batch_size=10)
        out = model.predict(input_b_np, batch_size=10)
        assert len(out) == 2
    
        # Now test a model with a single input
        # i.e. we don't pass any data to fit the model.
        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))
        a_2 = Dense(4, name='dense_1')(a)
        a_2 = Dropout(0.5, name='dropout')(a_2)
        model = Model(a, a_2)
        model.summary()
    
        optimizer = 'rmsprop'
        loss = 'mse'
        model.compile(optimizer, loss, metrics=['mean_squared_error'])
    
        # test train_on_batch
        out = model.train_on_batch(None,
                                   output_a_np)
        out = model.train_on_batch(None,
                                   output_a_np)
        out = model.test_on_batch(None,
                                  output_a_np)
        out = model.predict_on_batch(None)
        out = model.train_on_batch([],
                                   output_a_np)
        out = model.train_on_batch({},
                                   output_a_np)
    
        # test fit
        out = model.fit(None,
                        output_a_np, epochs=1, batch_size=10)
        out = model.fit(None,
                        output_a_np, epochs=1, batch_size=10)
    
        # test evaluate
        out = model.evaluate(None,
>                            output_a_np, batch_size=10)

test_training.py:928: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000001BDAEE11358>, x = None
y = array([[0.48010221, 0.6050835 , 0.55438818, 0.80736185],
       [0.45841058, 0.79960385, 0.1418953 , 0.68442206],
    ...82],
       [0.83825675, 0.13635159, 0.07878047, 0.63677121],
       [0.55703342, 0.78707802, 0.9082227 , 0.52526033]])
batch_size = 10, verbose = 1, sample_weight = None, steps = None
callbacks = None, max_queue_size = 10, workers = 1, use_multiprocessing = False

    def evaluate(self,
                 x=None,
                 y=None,
                 batch_size=None,
                 verbose=1,
                 sample_weight=None,
                 steps=None,
                 callbacks=None,
                 max_queue_size=10,
                 workers=1,
                 use_multiprocessing=False):
        """Returns the loss value & metrics values for the model in test mode.
    
        Computation is done in batches.
    
        # Arguments
            x: Input data. It could be:
                - A Numpy array (or array-like), or a list of arrays
                  (in case the model has multiple inputs).
                - A dict mapping input names to the corresponding
                  array/tensors, if the model has named inputs.
                - A generator or `keras.utils.Sequence` returning
                  `(inputs, targets)` or `(inputs, targets, sample weights)`.
                - None (default) if feeding from framework-native
                  tensors (e.g. TensorFlow data tensors).
            y: Target data. Like the input data `x`,
                it could be either Numpy array(s), framework-native tensor(s),
                list of Numpy arrays (if the model has multiple outputs) or
                None (default) if feeding from framework-native tensors
                (e.g. TensorFlow data tensors).
                If output layers in the model are named, you can also pass a
                dictionary mapping output names to Numpy arrays.
                If `x` is a generator, or `keras.utils.Sequence` instance,
                `y` should not be specified (since targets will be obtained
                from `x`).
            batch_size: Integer or `None`.
                Number of samples per gradient update.
                If unspecified, `batch_size` will default to 32.
                Do not specify the `batch_size` if your data is in the
                form of symbolic tensors, generators, or
                `keras.utils.Sequence` instances (since they generate batches).
            verbose: 0 or 1. Verbosity mode.
                0 = silent, 1 = progress bar.
            sample_weight: Optional Numpy array of weights for
                the test samples, used for weighting the loss function.
                You can either pass a flat (1D)
                Numpy array with the same length as the input samples
                (1:1 mapping between weights and samples),
                or in the case of temporal data,
                you can pass a 2D array with shape
                `(samples, sequence_length)`,
                to apply a different weight to every timestep of every sample.
                In this case you should make sure to specify
                `sample_weight_mode="temporal"` in `compile()`.
            steps: Integer or `None`.
                Total number of steps (batches of samples)
                before declaring the evaluation round finished.
                Ignored with the default value of `None`.
            callbacks: List of `keras.callbacks.Callback` instances.
                List of callbacks to apply during evaluation.
                See [callbacks](/callbacks).
            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`
                input only. Maximum size for the generator queue.
                If unspecified, `max_queue_size` will default to 10.
            workers: Integer. Used for generator or `keras.utils.Sequence` input
                only. Maximum number of processes to spin up when using
                process-based threading. If unspecified, `workers` will default
                to 1. If 0, will execute the generator on the main thread.
            use_multiprocessing: Boolean. Used for generator or
                `keras.utils.Sequence` input only. If `True`, use process-based
                threading. If unspecified, `use_multiprocessing` will default to
                `False`. Note that because this implementation relies on
                multiprocessing, you should not pass non-picklable arguments to
                the generator as they can't be passed easily to children processes.
    
        # Raises
            ValueError: in case of invalid arguments.
    
        # Returns
            Scalar test loss (if the model has a single output and no metrics)
            or list of scalars (if the model has multiple outputs
            and/or metrics). The attribute `model.metrics_names` will give you
            the display labels for the scalar outputs.
        """
    
        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)
    
        # Case 1: generator-like. Input is Python generator, or Sequence object.
        if training_utils.is_generator_or_sequence(x):
            training_utils.check_generator_arguments(y, sample_weight)
            return self.evaluate_generator(
                x,
                steps=steps,
                verbose=verbose,
                callbacks=callbacks,
                max_queue_size=max_queue_size,
                workers=workers,
                use_multiprocessing=use_multiprocessing)
    
        # Case 2: Symbolic tensors or Numpy array-like.
        if x is None or y is None and steps is None:
>           raise ValueError('If evaluating from data tensors, '
                             'you should specify the `steps` '
                             'argument.')
E           ValueError: If evaluating from data tensors, you should specify the `steps` argument.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1342: ValueError
---------------------------- Captured stdout call -----------------------------
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (10, 3)              0                                            
__________________________________________________________________________________________________
input_b (InputLayer)            (None, 3)            0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (10, 4)              16          input_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 3)            0           input_b[0][0]                    
==================================================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/1

10/10 [==============================] - 0s 0us/step - loss: 0.8449 - dense_1_loss: 0.5901 - dropout_loss: 0.5097 - dense_1_mean_squared_error: 0.5901 - dropout_mean_squared_error: 0.5097
Epoch 1/1

10/10 [==============================] - 0s 2ms/step - loss: 0.7598 - dense_1_loss: 0.5444 - dropout_loss: 0.4309 - dense_1_mean_squared_error: 0.5444 - dropout_mean_squared_error: 0.4309

10/10 [==============================] - 0s 2ms/step

10/10 [==============================] - 0s 0us/step
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (10, 3)                   0         
_________________________________________________________________
dense_1 (Dense)              (10, 4)                   16        
_________________________________________________________________
dropout (Dropout)            (10, 4)                   0         
=================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
_________________________________________________________________
Epoch 1/1

10/10 [==============================] - 0s 2ms/step - loss: 0.5681 - mean_squared_error: 0.5681
Epoch 1/1

10/10 [==============================] - 0s 0us/step - loss: 0.6033 - mean_squared_error: 0.6033
---------------------------- Captured stderr call -----------------------------
2020-10-03 19:02:44.938772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 19:02:44.939379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 19:02:44.939733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 19:02:44.940080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 19:02:44.940460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 19:02:44.940830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 19:02:44.941200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 19:02:44.941573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 19:02:44.942168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 19:02:44.942486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 19:02:44.942834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 19:02:44.943051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 19:02:44.943539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

------------------------------ Captured log call ------------------------------
WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.
________________________ test_model_with_external_loss ________________________

    @pytest.mark.skipif((K.backend() == 'cntk'),
                        reason='cntk does not support external loss yet')
    def test_model_with_external_loss():
        # None loss, only regularization loss.
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1',
                    kernel_regularizer='l1',
                    bias_regularizer='l2')(a)
        dp = Dropout(0.5, name='dropout')
        a_3 = dp(a_2)
    
        model = Model(a, [a_2, a_3])
    
        optimizer = 'rmsprop'
        loss = None
        model.compile(optimizer, loss, metrics=['mae'])
    
        input_a_np = np.random.random((10, 3))
    
        # test train_on_batch
        out = model.train_on_batch(input_a_np, None)
        out = model.test_on_batch(input_a_np, None)
        # fit
        out = model.fit(input_a_np, None)
        # evaluate
>       out = model.evaluate(input_a_np, None)

test_training.py:1045: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000001C0341B2048>
x = array([[0.63471255, 0.84296791, 0.62776627],
       [0.786544  , 0.60071521, 0.01959064],
       [0.23809723, 0.083460...86, 0.57912986, 0.44759934],
       [0.9510789 , 0.03879742, 0.52654611],
       [0.66105301, 0.59213549, 0.14382992]])
y = None, batch_size = 32, verbose = 1, sample_weight = None, steps = None
callbacks = None, max_queue_size = 10, workers = 1, use_multiprocessing = False

    def evaluate(self,
                 x=None,
                 y=None,
                 batch_size=None,
                 verbose=1,
                 sample_weight=None,
                 steps=None,
                 callbacks=None,
                 max_queue_size=10,
                 workers=1,
                 use_multiprocessing=False):
        """Returns the loss value & metrics values for the model in test mode.
    
        Computation is done in batches.
    
        # Arguments
            x: Input data. It could be:
                - A Numpy array (or array-like), or a list of arrays
                  (in case the model has multiple inputs).
                - A dict mapping input names to the corresponding
                  array/tensors, if the model has named inputs.
                - A generator or `keras.utils.Sequence` returning
                  `(inputs, targets)` or `(inputs, targets, sample weights)`.
                - None (default) if feeding from framework-native
                  tensors (e.g. TensorFlow data tensors).
            y: Target data. Like the input data `x`,
                it could be either Numpy array(s), framework-native tensor(s),
                list of Numpy arrays (if the model has multiple outputs) or
                None (default) if feeding from framework-native tensors
                (e.g. TensorFlow data tensors).
                If output layers in the model are named, you can also pass a
                dictionary mapping output names to Numpy arrays.
                If `x` is a generator, or `keras.utils.Sequence` instance,
                `y` should not be specified (since targets will be obtained
                from `x`).
            batch_size: Integer or `None`.
                Number of samples per gradient update.
                If unspecified, `batch_size` will default to 32.
                Do not specify the `batch_size` if your data is in the
                form of symbolic tensors, generators, or
                `keras.utils.Sequence` instances (since they generate batches).
            verbose: 0 or 1. Verbosity mode.
                0 = silent, 1 = progress bar.
            sample_weight: Optional Numpy array of weights for
                the test samples, used for weighting the loss function.
                You can either pass a flat (1D)
                Numpy array with the same length as the input samples
                (1:1 mapping between weights and samples),
                or in the case of temporal data,
                you can pass a 2D array with shape
                `(samples, sequence_length)`,
                to apply a different weight to every timestep of every sample.
                In this case you should make sure to specify
                `sample_weight_mode="temporal"` in `compile()`.
            steps: Integer or `None`.
                Total number of steps (batches of samples)
                before declaring the evaluation round finished.
                Ignored with the default value of `None`.
            callbacks: List of `keras.callbacks.Callback` instances.
                List of callbacks to apply during evaluation.
                See [callbacks](/callbacks).
            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`
                input only. Maximum size for the generator queue.
                If unspecified, `max_queue_size` will default to 10.
            workers: Integer. Used for generator or `keras.utils.Sequence` input
                only. Maximum number of processes to spin up when using
                process-based threading. If unspecified, `workers` will default
                to 1. If 0, will execute the generator on the main thread.
            use_multiprocessing: Boolean. Used for generator or
                `keras.utils.Sequence` input only. If `True`, use process-based
                threading. If unspecified, `use_multiprocessing` will default to
                `False`. Note that because this implementation relies on
                multiprocessing, you should not pass non-picklable arguments to
                the generator as they can't be passed easily to children processes.
    
        # Raises
            ValueError: in case of invalid arguments.
    
        # Returns
            Scalar test loss (if the model has a single output and no metrics)
            or list of scalars (if the model has multiple outputs
            and/or metrics). The attribute `model.metrics_names` will give you
            the display labels for the scalar outputs.
        """
    
        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)
    
        # Case 1: generator-like. Input is Python generator, or Sequence object.
        if training_utils.is_generator_or_sequence(x):
            training_utils.check_generator_arguments(y, sample_weight)
            return self.evaluate_generator(
                x,
                steps=steps,
                verbose=verbose,
                callbacks=callbacks,
                max_queue_size=max_queue_size,
                workers=workers,
                use_multiprocessing=use_multiprocessing)
    
        # Case 2: Symbolic tensors or Numpy array-like.
        if x is None or y is None and steps is None:
>           raise ValueError('If evaluating from data tensors, '
                             'you should specify the `steps` '
                             'argument.')
E           ValueError: If evaluating from data tensors, you should specify the `steps` argument.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1342: ValueError
---------------------------- Captured stdout call -----------------------------
Epoch 1/1

10/10 [==============================] - 0s 0us/step - loss: 0.0443
---------------------------- Captured stderr call -----------------------------
2020-10-03 19:02:48.466126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 19:02:48.466727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 19:02:48.467080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 19:02:48.467429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 19:02:48.467771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 19:02:48.468118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 19:02:48.468466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 19:02:48.468823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 19:02:48.469389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 19:02:48.469698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 19:02:48.470050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 19:02:48.470272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 19:02:48.470770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_methods
test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_methods
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods passed 1 out of the required 1 times. Success!
test_fit_generator passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_model_with_input_feed_tensor - ValueError: If e...
FAILED test_training.py::test_model_with_external_loss - ValueError: If evalu...
============ 2 failed, 31 passed, 1 skipped, 6 warnings in 28.25s =============
