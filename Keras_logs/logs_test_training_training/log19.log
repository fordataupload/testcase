2020-10-03 18:58:27.378448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py ...F...s.....F.F...FFF.F.F..FF.FF.                      [100%]

================================== FAILURES ===================================
_____________________________ test_model_methods ______________________________

    @flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))
    def test_model_methods():
        model = get_model(num_outputs=2)
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        # training/testing doesn't work before compiling.
        with pytest.raises(RuntimeError):
            model.train_on_batch([input_a_np, input_b_np],
                                 [output_a_np, output_b_np])
    
        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
                      sample_weight_mode=None)
    
        # test train_on_batch
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np])
        out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},
>                                  [output_a_np, output_b_np])

test_training.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1508: in train_on_batch
    class_weight=class_weight)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000001B66648D470>
x = {'input_a': array([[0.58779685, 0.15794262, 0.87380434],
       [0.74409112, 0.40067268, 0.43191335],
       [0.898121...7, 0.65904023, 0.74113131],
       [0.6819762 , 0.57123565, 0.63590571],
       [0.79320247, 0.35094188, 0.6808691 ]])}
y = [array([[0.21770301, 0.98809894, 0.27699127, 0.80370889],
       [0.26695717, 0.87441897, 0.89511303, 0.0976287 ],
   ...6, 0.21878775, 0.29632351],
       [0.77271476, 0.02792296, 0.08722874],
       [0.7373451 , 0.44898794, 0.63681747]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
>               raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
E               ValueError: Please do not pass a dictionary as model inputs.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:490: ValueError
---------------------------- Captured stderr call -----------------------------
Using TensorFlow backend.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2020-10-03 18:58:30.747647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-03 18:58:30.862726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:30.865421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:30.871166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:30.874850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:30.876502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:30.881221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:30.884319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:30.893562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:30.894494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:30.895093: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-03 18:58:30.908607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:30.909255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:30.909655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:30.910022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:30.910375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:30.910715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:30.911059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:30.911402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:30.912230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:31.862162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 18:58:31.862608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 18:58:31.862864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 18:58:31.863688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-10-03 18:58:32.478060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
------------------------------ Captured log call ------------------------------
WARNING  tensorflow:deprecation.py:506 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
______________________ test_model_with_input_feed_tensor ______________________

    @pytest.mark.skipif(K.backend() != 'tensorflow',
                        reason='Requires TensorFlow backend')
    def test_model_with_input_feed_tensor():
        """We test building a model with a TF variable as input.
        We should be able to call fit, evaluate, predict,
        by only passing them data for the placeholder inputs
        in the model.
        """
        import tensorflow as tf
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))
        b = Input(shape=(3,), name='input_b')
    
        a_2 = Dense(4, name='dense_1')(a)
        dp = Dropout(0.5, name='dropout')
        b_2 = dp(b)
    
        model = Model([a, b], [a_2, b_2])
        model.summary()
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
        model.compile(optimizer, loss, metrics=['mean_squared_error'],
                      loss_weights=loss_weights,
                      sample_weight_mode=None)
    
        # test train_on_batch
        out = model.train_on_batch(input_b_np,
                                   [output_a_np, output_b_np])
        out = model.train_on_batch({'input_b': input_b_np},
>                                  [output_a_np, output_b_np])

test_training.py:873: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1508: in train_on_batch
    class_weight=class_weight)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000001B8B332BEF0>
x = {'input_b': array([[8.68518216e-01, 1.72156625e-01, 1.55665193e-01],
       [4.60667551e-01, 5.86399262e-01, 6.0118360...1],
       [6.91229888e-01, 1.51224801e-01, 3.55534749e-01],
       [4.54258984e-01, 1.29176623e-01, 6.77182803e-01]])}
y = [array([[0.22121248, 0.60756388, 0.69676961, 0.70775323],
       [0.28450853, 0.81896968, 0.74947241, 0.2292326 ],
   ...4, 0.11331145, 0.80896083],
       [0.77794706, 0.22143895, 0.28153167],
       [0.1169978 , 0.27913914, 0.40023639]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
>               raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
E               ValueError: Please do not pass a dictionary as model inputs.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:490: ValueError
---------------------------- Captured stdout call -----------------------------
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (10, 3)              0                                            
__________________________________________________________________________________________________
input_b (InputLayer)            (None, 3)            0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (10, 4)              16          input_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 3)            0           input_b[0][0]                    
==================================================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
__________________________________________________________________________________________________
---------------------------- Captured stderr call -----------------------------
2020-10-03 18:58:41.094035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:41.094746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:41.095128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:41.095503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:41.095873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:41.096222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:41.096575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:41.096953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:41.097578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:41.097898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 18:58:41.098251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 18:58:41.098472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 18:58:41.098984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

------------------------------ Captured log call ------------------------------
WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.
________________________ test_model_with_external_loss ________________________

    @pytest.mark.skipif((K.backend() == 'cntk'),
                        reason='cntk does not support external loss yet')
    def test_model_with_external_loss():
        # None loss, only regularization loss.
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1',
                    kernel_regularizer='l1',
                    bias_regularizer='l2')(a)
        dp = Dropout(0.5, name='dropout')
        a_3 = dp(a_2)
    
        model = Model(a, [a_2, a_3])
    
        optimizer = 'rmsprop'
        loss = None
        model.compile(optimizer, loss, metrics=['mae'])
    
        input_a_np = np.random.random((10, 3))
    
        # test train_on_batch
        out = model.train_on_batch(input_a_np, None)
        out = model.test_on_batch(input_a_np, None)
        # fit
        out = model.fit(input_a_np, None)
        # evaluate
        out = model.evaluate(input_a_np, None)
    
        # No dropout, external loss.
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1')(a)
        a_3 = Dense(4, name='dense_2')(a)
    
        model = Model(a, [a_2, a_3])
        model.add_loss(K.mean(a_3 + a_2))
    
        optimizer = 'rmsprop'
        loss = None
        model.compile(optimizer, loss, metrics=['mae'])
    
        # test train_on_batch
        out = model.train_on_batch(input_a_np, None)
        out = model.test_on_batch(input_a_np, None)
        # fit
        out = model.fit(input_a_np, None)
        # evaluate
        out = model.evaluate(input_a_np, None)
    
        # Test fit with no external data at all.
        if K.backend() == 'tensorflow':
            import tensorflow as tf
    
            a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))
            a_2 = Dense(4, name='dense_1')(a)
            a_2 = Dropout(0.5, name='dropout')(a_2)
            model = Model(a, a_2)
            model.add_loss(K.mean(a_2))
    
            model.compile(optimizer='rmsprop',
                          loss=None,
                          metrics=['mean_squared_error'])
    
            # test train_on_batch
>           out = model.train_on_batch(None, None)

test_training.py:1082: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1508: in train_on_batch
    class_weight=class_weight)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000001B8B35A9EB8>, x = None
y = None, sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
>                                    'You passed: x=' + str(x))
E                   ValueError: Please provide as model inputs either a single array or a list of arrays. You passed: x=None

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:497: ValueError
---------------------------- Captured stdout call -----------------------------
Epoch 1/1

10/10 [==============================] - 0s 0us/step - loss: 0.0497

10/10 [==============================] - 0s 0us/step
Epoch 1/1

10/10 [==============================] - 0s 0us/step - loss: 0.2361

10/10 [==============================] - 0s 0us/step
---------------------------- Captured stderr call -----------------------------
2020-10-03 18:58:42.627093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:42.627686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:42.628039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:42.628386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:42.628726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:42.629066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:42.629413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:42.629792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:42.630395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:42.630727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 18:58:42.631101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 18:58:42.631334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 18:58:42.631852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
____________________________ test_pandas_dataframe ____________________________

    def test_pandas_dataframe():
        input_a = Input(shape=(3,), name='input_a')
        input_b = Input(shape=(3,), name='input_b')
    
        x = Dense(4, name='dense_1')(input_a)
        y = Dense(3, name='desne_2')(input_b)
    
        model_1 = Model(inputs=input_a, outputs=x)
        model_2 = Model(inputs=[input_a, input_b], outputs=[x, y])
    
        optimizer = 'rmsprop'
        loss = 'mse'
    
        model_1.compile(optimizer=optimizer, loss=loss)
        model_2.compile(optimizer=optimizer, loss=loss)
    
        input_a_df = pd.DataFrame(np.random.random((10, 3)))
        input_b_df = pd.DataFrame(np.random.random((10, 3)))
    
        output_a_df = pd.DataFrame(np.random.random((10, 4)))
        output_b_df = pd.DataFrame(np.random.random((10, 3)))
    
        model_1.fit(input_a_df,
>                   output_a_df)

test_training.py:1380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x000001B8B7A99048>
x =           0         1         2
0  0.468601  0.969798  0.757778
1  0.504859  0.987928  0.232108
2  0.000052  0.634682 ...632  0.211671  0.941263
7  0.957598  0.263393  0.211851
8  0.879296  0.239608  0.163085
9  0.948101  0.873287  0.054579
y =           0         1         2         3
0  0.747899  0.987464  0.753880  0.446733
1  0.621640  0.004898  0.912903  0...36663  0.678387  0.018631  0.731642
8  0.595373  0.413944  0.162102  0.839860
9  0.057444  0.885045  0.131820  0.631285
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 32

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
>                                    'You passed: x=' + str(x))
E                   ValueError: Please provide as model inputs either a single array or a list of arrays. You passed: x=          0         1         2
E                   0  0.468601  0.969798  0.757778
E                   1  0.504859  0.987928  0.232108
E                   2  0.000052  0.634682  0.321529
E                   3  0.236437  0.852638  0.427879
E                   4  0.250562  0.716012  0.950572
E                   5  0.488983  0.846414  0.481314
E                   6  0.257632  0.211671  0.941263
E                   7  0.957598  0.263393  0.211851
E                   8  0.879296  0.239608  0.163085
E                   9  0.948101  0.873287  0.054579

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:497: ValueError
________ test_training_and_eval_methods_on_symbolic_tensors_single_io _________

    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')
    def test_training_and_eval_methods_on_symbolic_tensors_single_io():
        x = keras.layers.Input(shape=(3,), name='input')
        y = keras.layers.Dense(4, name='dense')(x)
        model = keras.Model(x, y)
    
        optimizer = 'rmsprop'
        loss = 'mse'
        metrics = ['mae']
        model.compile(optimizer, loss, metrics=metrics)
    
        inputs = keras.backend.zeros(shape=(10, 3))
        targets = keras.backend.zeros(shape=(10, 4))
    
>       model.fit(inputs, targets, epochs=1, steps_per_epoch=2, verbose=0)

test_training.py:1450: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1239: in fit
    validation_freq=validation_freq)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = <keras.engine.training.Model object at 0x000001B8B7D87400>
fit_function = <tensorflow.python.keras.backend.GraphExecutionFunction object at 0x000001B8B7B3E5F8>
fit_inputs = [], out_labels = ['loss', 'mae'], batch_size = None, epochs = 1
verbose = 0
callbacks = <keras.callbacks.callbacks.CallbackList object at 0x000001B8B7B3E320>
val_function = None, val_inputs = [], shuffle = True, initial_epoch = 0
steps_per_epoch = 2, validation_steps = None, validation_freq = 1

    def fit_loop(model, fit_function, fit_inputs,
                 out_labels=None,
                 batch_size=None,
                 epochs=100,
                 verbose=1,
                 callbacks=None,
                 val_function=None,
                 val_inputs=None,
                 shuffle=True,
                 initial_epoch=0,
                 steps_per_epoch=None,
                 validation_steps=None,
                 validation_freq=1):
        """Abstract fit function for `fit_function(fit_inputs)`.
    
        Assumes that fit_function returns a list, labeled by out_labels.
    
        # Arguments
            model: Keras model instance.
            fit_function: Keras function returning a list of tensors
            fit_inputs: List of tensors to be fed to `fit_function`
            out_labels: List of strings, display names of
                the outputs of `fit_function`
            batch_size: Integer batch size or None if unknown.
            epochs: Number of times to iterate over the data
            verbose: Verbosity mode, 0, 1 or 2
            callbacks: List of callbacks to be called during training and validation
                (if `val_function` and `val_inputs` are not `None`).
            val_function: Keras function to call for validation
            val_inputs: List of tensors to be fed to `val_function`
            shuffle: Whether to shuffle the data at the beginning of each epoch
            initial_epoch: Epoch at which to start training
                (useful for resuming a previous training run)
            steps_per_epoch: Total number of steps (batches of samples)
                before declaring one epoch finished and starting the
                next epoch. Ignored with the default value of `None`.
            validation_steps: Number of steps to run validation for
                (only if doing validation from data tensors).
                Ignored with the default value of `None`.
            validation_freq: Only relevant if validation data is provided. Integer
                or list/tuple/set. If an integer, specifies how many training
                epochs to run before a new validation run is performed, e.g.
                validation_freq=2` runs validation every 2 epochs. If a list,
                tuple, or set, specifies the epochs on which to run validation,
                e.g. `validation_freq=[1, 2, 10]` runs validation at the end
                of the 1st, 2nd, and 10th epochs.
    
        # Returns
            `History` object.
        """
        do_validation = False
        if val_function and val_inputs:
            do_validation = True
            if (verbose and fit_inputs and
               hasattr(fit_inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):
                print('Train on %d samples, validate on %d samples' %
                      (fit_inputs[0].shape[0], val_inputs[0].shape[0]))
        if validation_steps:
            do_validation = True
            if steps_per_epoch is None:
                raise ValueError('Can only use `validation_steps` '
                                 'when doing step-wise '
                                 'training, i.e. `steps_per_epoch` '
                                 'must be set.')
        elif do_validation:
            if steps_per_epoch:
                raise ValueError('Must specify `validation_steps` '
                                 'to perform validation '
                                 'when doing step-wise training.')
    
        num_train_samples = check_num_samples(fit_inputs,
                                              batch_size=batch_size,
                                              steps=steps_per_epoch,
                                              steps_name='steps_per_epoch')
        if num_train_samples is not None:
            index_array = np.arange(num_train_samples)
    
        model.history = cbks.History()
        _callbacks = [cbks.BaseLogger(stateful_metrics=model.metrics_names[1:])]
        if verbose:
            if steps_per_epoch is not None:
                count_mode = 'steps'
            else:
                count_mode = 'samples'
            _callbacks.append(
                cbks.ProgbarLogger(count_mode, stateful_metrics=model.metrics_names[1:]))
        _callbacks += (callbacks or []) + [model.history]
        callbacks = cbks.CallbackList(_callbacks)
        out_labels = out_labels or []
    
        # it's possible to callback a different model than itself
        # (used by Sequential models)
        callback_model = model._get_callback_model()
        callback_metrics = list(model.metrics_names)
        if do_validation:
            callback_metrics += ['val_' + n for n in model.metrics_names]
    
        callbacks.set_model(callback_model)
        callbacks.set_params({
            'batch_size': batch_size,
            'epochs': epochs,
            'steps': steps_per_epoch,
            'samples': num_train_samples,
            'verbose': verbose,
            'do_validation': do_validation,
            'metrics': callback_metrics,
        })
        callbacks._call_begin_hook('train')
        callbacks.model.stop_training = False
        for cbk in callbacks:
            cbk.validation_data = val_inputs
    
        # To prevent a slowdown,
        # we find beforehand the arrays that need conversion.
        feed = (model._feed_inputs +
                model._feed_targets +
                model._feed_sample_weights)
        indices_for_conversion_to_dense = []
        for i in range(len(feed)):
>           if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):
E           IndexError: list index out of range

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_arrays.py:141: IndexError
---------------------------- Captured stderr call -----------------------------
2020-10-03 18:58:47.334634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:47.335231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:47.335582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:47.335926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:47.336264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:47.336609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:47.336954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:47.337311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:47.337872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:47.338186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 18:58:47.338534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 18:58:47.338751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 18:58:47.339240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
_________ test_training_and_eval_methods_on_symbolic_tensors_multi_io _________

    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')
    def test_training_and_eval_methods_on_symbolic_tensors_multi_io():
        a = keras.layers.Input(shape=(3,), name='input_a')
        b = keras.layers.Input(shape=(3,), name='input_b')
    
        dense = keras.layers.Dense(4, name='dense')
        c = dense(a)
        d = dense(b)
        e = keras.layers.Dropout(0.5, name='dropout')(c)
    
        model = keras.models.Model([a, b], [d, e])
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
        metrics = ['mae']
        model.compile(optimizer, loss, metrics=metrics, loss_weights=loss_weights)
    
        input_a_tf = keras.backend.zeros(shape=(10, 3))
        input_b_tf = keras.backend.zeros(shape=(10, 3))
    
        output_d_tf = keras.backend.zeros(shape=(10, 4))
        output_e_tf = keras.backend.zeros(shape=(10, 4))
    
        model.fit(
            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],
            epochs=1,
            steps_per_epoch=2,
>           verbose=0)

test_training.py:1488: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1239: in fit
    validation_freq=validation_freq)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = <keras.engine.training.Model object at 0x000001B8B7A32CC0>
fit_function = <tensorflow.python.keras.backend.GraphExecutionFunction object at 0x000001B8B34B3940>
fit_inputs = [1]
out_labels = ['loss', 'dense_loss', 'dropout_loss', 'dense_mae', 'dropout_mae']
batch_size = None, epochs = 1, verbose = 0
callbacks = <keras.callbacks.callbacks.CallbackList object at 0x000001B8B34B34E0>
val_function = None, val_inputs = [], shuffle = True, initial_epoch = 0
steps_per_epoch = 2, validation_steps = None, validation_freq = 1

    def fit_loop(model, fit_function, fit_inputs,
                 out_labels=None,
                 batch_size=None,
                 epochs=100,
                 verbose=1,
                 callbacks=None,
                 val_function=None,
                 val_inputs=None,
                 shuffle=True,
                 initial_epoch=0,
                 steps_per_epoch=None,
                 validation_steps=None,
                 validation_freq=1):
        """Abstract fit function for `fit_function(fit_inputs)`.
    
        Assumes that fit_function returns a list, labeled by out_labels.
    
        # Arguments
            model: Keras model instance.
            fit_function: Keras function returning a list of tensors
            fit_inputs: List of tensors to be fed to `fit_function`
            out_labels: List of strings, display names of
                the outputs of `fit_function`
            batch_size: Integer batch size or None if unknown.
            epochs: Number of times to iterate over the data
            verbose: Verbosity mode, 0, 1 or 2
            callbacks: List of callbacks to be called during training and validation
                (if `val_function` and `val_inputs` are not `None`).
            val_function: Keras function to call for validation
            val_inputs: List of tensors to be fed to `val_function`
            shuffle: Whether to shuffle the data at the beginning of each epoch
            initial_epoch: Epoch at which to start training
                (useful for resuming a previous training run)
            steps_per_epoch: Total number of steps (batches of samples)
                before declaring one epoch finished and starting the
                next epoch. Ignored with the default value of `None`.
            validation_steps: Number of steps to run validation for
                (only if doing validation from data tensors).
                Ignored with the default value of `None`.
            validation_freq: Only relevant if validation data is provided. Integer
                or list/tuple/set. If an integer, specifies how many training
                epochs to run before a new validation run is performed, e.g.
                validation_freq=2` runs validation every 2 epochs. If a list,
                tuple, or set, specifies the epochs on which to run validation,
                e.g. `validation_freq=[1, 2, 10]` runs validation at the end
                of the 1st, 2nd, and 10th epochs.
    
        # Returns
            `History` object.
        """
        do_validation = False
        if val_function and val_inputs:
            do_validation = True
            if (verbose and fit_inputs and
               hasattr(fit_inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):
                print('Train on %d samples, validate on %d samples' %
                      (fit_inputs[0].shape[0], val_inputs[0].shape[0]))
        if validation_steps:
            do_validation = True
            if steps_per_epoch is None:
                raise ValueError('Can only use `validation_steps` '
                                 'when doing step-wise '
                                 'training, i.e. `steps_per_epoch` '
                                 'must be set.')
        elif do_validation:
            if steps_per_epoch:
                raise ValueError('Must specify `validation_steps` '
                                 'to perform validation '
                                 'when doing step-wise training.')
    
        num_train_samples = check_num_samples(fit_inputs,
                                              batch_size=batch_size,
                                              steps=steps_per_epoch,
                                              steps_name='steps_per_epoch')
        if num_train_samples is not None:
            index_array = np.arange(num_train_samples)
    
        model.history = cbks.History()
        _callbacks = [cbks.BaseLogger(stateful_metrics=model.metrics_names[1:])]
        if verbose:
            if steps_per_epoch is not None:
                count_mode = 'steps'
            else:
                count_mode = 'samples'
            _callbacks.append(
                cbks.ProgbarLogger(count_mode, stateful_metrics=model.metrics_names[1:]))
        _callbacks += (callbacks or []) + [model.history]
        callbacks = cbks.CallbackList(_callbacks)
        out_labels = out_labels or []
    
        # it's possible to callback a different model than itself
        # (used by Sequential models)
        callback_model = model._get_callback_model()
        callback_metrics = list(model.metrics_names)
        if do_validation:
            callback_metrics += ['val_' + n for n in model.metrics_names]
    
        callbacks.set_model(callback_model)
        callbacks.set_params({
            'batch_size': batch_size,
            'epochs': epochs,
            'steps': steps_per_epoch,
            'samples': num_train_samples,
            'verbose': verbose,
            'do_validation': do_validation,
            'metrics': callback_metrics,
        })
        callbacks._call_begin_hook('train')
        callbacks.model.stop_training = False
        for cbk in callbacks:
            cbk.validation_data = val_inputs
    
        # To prevent a slowdown,
        # we find beforehand the arrays that need conversion.
        feed = (model._feed_inputs +
                model._feed_targets +
                model._feed_sample_weights)
        indices_for_conversion_to_dense = []
        for i in range(len(feed)):
>           if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):
E           IndexError: list index out of range

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_arrays.py:141: IndexError
---------------------------- Captured stderr call -----------------------------
2020-10-03 18:58:47.812964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-03 18:58:47.813607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-03 18:58:47.813989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-03 18:58:47.814331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-03 18:58:47.814673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-03 18:58:47.815014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-03 18:58:47.815359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-03 18:58:47.815704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-03 18:58:47.816264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-03 18:58:47.816586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-03 18:58:47.816938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-03 18:58:47.817158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-03 18:58:47.817645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
___________________________ test_dynamic_set_inputs ___________________________

    def test_dynamic_set_inputs():
        model = Sequential()
        model.add(Dense(16, input_dim=32))
        model.add(Activation('relu'))
    
        model2 = Sequential()
        model2.add(model.layers[-1])
        model2.add(Dense(8))
>       preds2 = model2.predict([np.random.random((1, 32))])

test_training.py:1645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1441: in predict
    x, _, _ = self._standardize_user_data(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.sequential.Sequential object at 0x000001B8B34E1C18>
x = [array([[0.70258273, 0.48274232, 0.17351313, 0.35398749, 0.30415584,
        0.99735312, 0.8027363 , 0.66838234, 0.661...684, 0.17500003,
        0.93607419, 0.02788544, 0.78142643, 0.45664108, 0.0033345 ,
        0.26813136, 0.05876913]])]
y = None, sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
        if any(K.is_tensor(v) for v in all_inputs):
            return [], [], []
    
        # What follows is input validation and standardization to list format,
        # in the case where all inputs are value arrays.
    
        if not self._is_graph_network:
            # Case: symbolic-mode subclassed network.
            # Do not do shape validation.
>           feed_input_names = self._feed_input_names
E           AttributeError: 'Sequential' object has no attribute '_feed_input_names'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:565: AttributeError
____________________________ test_validation_freq _____________________________

    def test_validation_freq():
        model = Sequential([Dense(1)])
        model.compile('sgd', 'mse')
    
        def _gen():
            while True:
                yield np.ones((2, 10)), np.ones((2, 1))
    
        x, y = np.ones((10, 10)), np.ones((10, 1))
    
        class ValCounter(Callback):
    
            def __init__(self):
                self.val_runs = 0
    
            def on_test_begin(self, logs=None):
                self.val_runs += 1
    
        # Test in training_arrays.py
        val_counter = ValCounter()
        model.fit(
            x,
            y,
            batch_size=2,
            epochs=4,
            validation_data=(x, y),
            validation_freq=2,
>           callbacks=[val_counter])

test_training.py:1720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.sequential.Sequential object at 0x000001B8B34E4908>
x = array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., ...1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])
y = [array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 2

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
        if any(K.is_tensor(v) for v in all_inputs):
            return [], [], []
    
        # What follows is input validation and standardization to list format,
        # in the case where all inputs are value arrays.
    
        if not self._is_graph_network:
            # Case: symbolic-mode subclassed network.
            # Do not do shape validation.
>           feed_input_names = self._feed_input_names
E           AttributeError: 'Sequential' object has no attribute '_feed_input_names'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:565: AttributeError
_______________________ test_model_metrics_list_in_call _______________________

    def test_model_metrics_list_in_call():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2)
    
            def call(self, x):
                self.add_metric(K.sum(x), name='metric_2')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(
            loss='mse',
            optimizer='adam',
            metrics=[metrics.MeanSquaredError('metric_1')])
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1822: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_model_metrics_list_in_call.<locals>.TestModel object at 0x000001B8B7DBBEF0>
x = array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])
y = [array([[1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 5

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
        if any(K.is_tensor(v) for v in all_inputs):
            return [], [], []
    
        # What follows is input validation and standardization to list format,
        # in the case where all inputs are value arrays.
    
        if not self._is_graph_network:
            # Case: symbolic-mode subclassed network.
            # Do not do shape validation.
>           feed_input_names = self._feed_input_names
E           AttributeError: 'TestModel' object has no attribute '_feed_input_names'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:565: AttributeError
__________________ test_duplicate_metric_name_in_add_metric ___________________

    def test_duplicate_metric_name_in_add_metric():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean = metrics.Mean(name='metric_1')
                self.mean2 = metrics.Mean(name='metric_1')
    
            def call(self, x):
                self.add_metric(self.mean(x), name='metric_1')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='adam')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
        with pytest.raises(ValueError):
>           model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1855: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_duplicate_metric_name_in_add_metric.<locals>.TestModel object at 0x000001B8B32DF6D8>
x = array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])
y = [array([[1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 5

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
        if any(K.is_tensor(v) for v in all_inputs):
            return [], [], []
    
        # What follows is input validation and standardization to list format,
        # in the case where all inputs are value arrays.
    
        if not self._is_graph_network:
            # Case: symbolic-mode subclassed network.
            # Do not do shape validation.
>           feed_input_names = self._feed_input_names
E           AttributeError: 'TestModel' object has no attribute '_feed_input_names'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:565: AttributeError
________________________ test_add_metric_in_model_call ________________________

    def test_add_metric_in_model_call():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean = metrics.Mean(name='metric_1')
    
            def call(self, x):
                self.add_metric(K.sum(x), name='metric_2')
                # Provide same name as in the instance created in __init__
                # for eager mode
                self.add_metric(self.mean(x), name='metric_1')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='sgd')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_add_metric_in_model_call.<locals>.TestModel object at 0x000001B8B7D4F208>
x = array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])
y = [array([[1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 5

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
        if any(K.is_tensor(v) for v in all_inputs):
            return [], [], []
    
        # What follows is input validation and standardization to list format,
        # in the case where all inputs are value arrays.
    
        if not self._is_graph_network:
            # Case: symbolic-mode subclassed network.
            # Do not do shape validation.
>           feed_input_names = self._feed_input_names
E           AttributeError: 'TestModel' object has no attribute '_feed_input_names'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:565: AttributeError
_______________________ test_multiple_add_metric_calls ________________________

    def test_multiple_add_metric_calls():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean1 = metrics.Mean(name='metric_1')
                self.mean2 = metrics.Mean(name='metric_2')
    
            def call(self, x):
                self.add_metric(self.mean2(x), name='metric_2')
                self.add_metric(self.mean1(x), name='metric_1')
                self.add_metric(K.sum(x), name='metric_3')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='sgd')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1946: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <test_training.test_multiple_add_metric_calls.<locals>.TestModel object at 0x000001B8B795A5C0>
x = array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])
y = [array([[1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.],
       [1., 1.]])]
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 5

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = []
        if self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
        if any(K.is_tensor(v) for v in all_inputs):
            return [], [], []
    
        # What follows is input validation and standardization to list format,
        # in the case where all inputs are value arrays.
    
        if not self._is_graph_network:
            # Case: symbolic-mode subclassed network.
            # Do not do shape validation.
>           feed_input_names = self._feed_input_names
E           AttributeError: 'TestModel' object has no attribute '_feed_input_names'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:565: AttributeError
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods failed and was not selected for rerun.
	<class 'ValueError'>
	Please do not pass a dictionary as model inputs.
	[<TracebackEntry C:\Users\mutation\Desktop\testcase\tests\keras\engine\test_training.py:189>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1508>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:490>]
test_fit_generator passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_model_methods - ValueError: Please do not pass ...
FAILED test_training.py::test_model_with_input_feed_tensor - ValueError: Plea...
FAILED test_training.py::test_model_with_external_loss - ValueError: Please p...
FAILED test_training.py::test_pandas_dataframe - ValueError: Please provide a...
FAILED test_training.py::test_training_and_eval_methods_on_symbolic_tensors_single_io
FAILED test_training.py::test_training_and_eval_methods_on_symbolic_tensors_multi_io
FAILED test_training.py::test_dynamic_set_inputs - AttributeError: 'Sequentia...
FAILED test_training.py::test_validation_freq - AttributeError: 'Sequential' ...
FAILED test_training.py::test_model_metrics_list_in_call - AttributeError: 'T...
FAILED test_training.py::test_duplicate_metric_name_in_add_metric - Attribute...
FAILED test_training.py::test_add_metric_in_model_call - AttributeError: 'Tes...
FAILED test_training.py::test_multiple_add_metric_calls - AttributeError: 'Te...
============ 12 failed, 21 passed, 1 skipped, 5 warnings in 22.11s ============
