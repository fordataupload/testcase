2020-10-04 13:12:30.578523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py ...F..Fs......F.....FF....F.......                      [100%]

================================== FAILURES ===================================
_____________________________ test_model_methods ______________________________

values = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 3) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
>       fn(values)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 3) dtype=float32>

    def inner(values):
>     _ = [_check_failed(v) for v in nest.flatten(values)
           if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <list_iterator object at 0x000001B232BDAE48>

    _ = [_check_failed(v) for v in nest.flatten(values)
>        if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

v = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 3) dtype=float32>

    def _check_failed(v):
      # NB. none of the _check_* functions could raise a ValueError, so
      # it is safe to use here.
>     raise ValueError(v)
E     ValueError: Tensor("dropout/cond/Merge:0", shape=(?, 3), dtype=float32)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:248: ValueError

During handling of the above exception, another exception occurred:

    @flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))
    def test_model_methods():
        model = get_model(num_outputs=2)
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        # training/testing doesn't work before compiling.
        with pytest.raises(RuntimeError):
            model.train_on_batch([input_a_np, input_b_np],
                                 [output_a_np, output_b_np])
    
        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
                      sample_weight_mode=None)
    
        # test train_on_batch
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np])
        out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},
                                   [output_a_np, output_b_np])
        out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},
                                   {'dense_1': output_a_np, 'dropout': output_b_np})
    
        # test fit
        out = model.fit([input_a_np, input_b_np],
                        [output_a_np, output_b_np], epochs=1, batch_size=4)
        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},
                        [output_a_np, output_b_np], epochs=1, batch_size=4)
        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},
                        {'dense_1': output_a_np, 'dropout': output_b_np},
                        epochs=1, batch_size=4)
    
        # test validation_split
        out = model.fit([input_a_np, input_b_np],
                        [output_a_np, output_b_np],
                        epochs=1, batch_size=4, validation_split=0.5)
        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},
                        [output_a_np, output_b_np],
                        epochs=1, batch_size=4, validation_split=0.5)
    
        # test validation data
        out = model.fit([input_a_np, input_b_np],
                        [output_a_np, output_b_np],
                        epochs=1, batch_size=4,
                        validation_data=([input_a_np, input_b_np],
                                         [output_a_np, output_b_np]))
        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},
                        [output_a_np, output_b_np],
                        epochs=1, batch_size=4, validation_split=0.5,
                        validation_data=({'input_a': input_a_np,
                                          'input_b': input_b_np},
                                         [output_a_np, output_b_np]))
        out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},
                        {'dense_1': output_a_np, 'dropout': output_b_np},
                        epochs=1, batch_size=4, validation_split=0.5,
                        validation_data=(
                            {'input_a': input_a_np, 'input_b': input_b_np},
                            {'dense_1': output_a_np, 'dropout': output_b_np}))
    
        # test_on_batch
        out = model.test_on_batch([input_a_np, input_b_np],
                                  [output_a_np, output_b_np])
        out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},
                                  [output_a_np, output_b_np])
        out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},
                                  {'dense_1': output_a_np, 'dropout': output_b_np})
    
        # predict_on_batch
        out = model.predict_on_batch([input_a_np, input_b_np])
        out = model.predict_on_batch({'input_a': input_a_np,
                                      'input_b': input_b_np})
    
        # predict, evaluate
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        out = model.evaluate([input_a_np, input_b_np],
                             [output_a_np, output_b_np],
                             batch_size=4)
        out = model.predict([input_a_np, input_b_np], batch_size=4)
    
        # with sample_weight
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        sample_weight = [None, np.random.random((10,))]
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np],
                                   sample_weight=sample_weight)
    
        out = model.test_on_batch([input_a_np, input_b_np],
                                  [output_a_np, output_b_np],
                                  sample_weight=sample_weight)
    
        # test accuracy metric
        model.compile(optimizer, loss, metrics=['acc'],
                      sample_weight_mode=None)
    
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np])
        assert len(out) == 5
        out = model.test_on_batch([input_a_np, input_b_np],
                                  [output_a_np, output_b_np])
        assert len(out) == 5
    
        # this should also work
        model.compile(optimizer, loss, metrics={'dense_1': 'acc'},
                      sample_weight_mode=None)
    
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np])
        assert len(out) == 4
        out = model.test_on_batch([input_a_np, input_b_np],
                                  [output_a_np, output_b_np])
        assert len(out) == 4
    
        # and this as well
        model.compile(optimizer, loss, metrics={'dense_1': ['acc']},
                      sample_weight_mode=None)
    
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np])
        assert len(out) == 4
        out = model.test_on_batch([input_a_np, input_b_np],
                                  [output_a_np, output_b_np])
        assert len(out) == 4
    
        tracker_cb = TrackerCallback()
    
        out = model.fit([input_a_np, input_b_np],
                        [output_a_np, output_b_np], epochs=5, batch_size=4,
                        initial_epoch=2, callbacks=[tracker_cb])
        assert tracker_cb.trained_epochs == [2, 3, 4]
    
        # test starting from non-zero initial epoch for generator too
        tracker_cb = TrackerCallback()
    
        @threadsafe_generator
        def gen_data(batch_sz):
            while True:
                yield ([np.random.random((batch_sz, 3)),
                        np.random.random((batch_sz, 3))],
                       [np.random.random((batch_sz, 4)),
                        np.random.random((batch_sz, 3))])
    
        out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,
                                  initial_epoch=2, callbacks=[tracker_cb])
        assert tracker_cb.trained_epochs == [2, 3, 4]
    
        # test with a custom metric function
        def mse(y_true, y_pred):
            return K.mean(K.pow(y_true - y_pred, 2))
    
        model.compile(optimizer, loss, metrics=[mse],
                      sample_weight_mode=None)
    
        out = model.train_on_batch([input_a_np, input_b_np],
                                   [output_a_np, output_b_np])
        out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)
        assert len(out) == out_len
        out = model.test_on_batch([input_a_np, input_b_np],
                                  [output_a_np, output_b_np])
        assert len(out) == out_len
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        out = model.fit([input_a_np, input_b_np],
                        [output_a_np, output_b_np],
                        batch_size=4, epochs=1)
        out = model.evaluate([input_a_np, input_b_np],
                             [output_a_np, output_b_np],
                             batch_size=4)
        out = model.predict([input_a_np, input_b_np], batch_size=4)
    
        # enable verbose for evaluate_generator
        out = model.evaluate_generator(gen_data(4), steps=3, verbose=1)
        # pass generator directly so `is_generator_or_sequence`
        # doesn't get confused.
        out = model.evaluate(gen_data(4).it, steps=3, verbose=1)
    
        # empty batch
        with pytest.raises(ValueError):
            @threadsafe_generator
            def gen_data():
                while True:
                    yield (np.asarray([]), np.asarray([]))
    
            out = model.evaluate_generator(gen_data(), steps=1)
        with pytest.raises(ValueError):
            @threadsafe_generator
            def gen_data():
                while True:
                    yield (np.asarray([]), np.asarray([]))
    
            out = model.evaluate(gen_data().it, steps=1)
    
        # x is not a list of numpy arrays.
        with pytest.raises(ValueError):
            out = model.predict([None])
    
        # x does not match _feed_input_names.
        with pytest.raises(ValueError):
            out = model.predict([input_a_np, None, input_b_np])
        with pytest.raises(ValueError):
            out = model.predict([None, input_a_np, input_b_np])
    
        # all input/output/weight arrays should have the same number of samples.
        with pytest.raises(ValueError):
            out = model.train_on_batch([input_a_np, input_b_np[:2]],
                                       [output_a_np, output_b_np],
                                       sample_weight=sample_weight)
        with pytest.raises(ValueError):
            out = model.train_on_batch([input_a_np, input_b_np],
                                       [output_a_np, output_b_np[:2]],
                                       sample_weight=sample_weight)
        with pytest.raises(ValueError):
            out = model.train_on_batch([input_a_np, input_b_np],
                                       [output_a_np, output_b_np],
                                       sample_weight=[sample_weight[1],
                                                      sample_weight[1][:2]])
    
        # `sample_weight` is neither a dict nor a list.
        with pytest.raises(TypeError):
            out = model.train_on_batch([input_a_np, input_b_np],
                                       [output_a_np, output_b_np],
                                       sample_weight=tuple(sample_weight))
    
        # `validation_data` is neither a tuple nor a triple.
        with pytest.raises(ValueError):
            out = model.fit([input_a_np, input_b_np],
                            [output_a_np, output_b_np],
                            epochs=1, batch_size=4,
                            validation_data=([input_a_np, input_b_np],))
    
        # `loss` does not match outputs.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss=['mse', 'mae', 'mape'])
    
        # `loss_weights` does not match output_names.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})
    
        # `loss_weights` does not match outputs.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss='mse', loss_weights=[0.5])
    
        # `loss_weights` is invalid type.
        with pytest.raises(TypeError):
            model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))
    
        # `sample_weight_mode` does not match output_names.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss='mse',
                          sample_weight_mode={'lstm': 'temporal'})
    
        # `sample_weight_mode` does not match output_names.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])
    
        # `sample_weight_mode` matches output_names partially.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss='mse',
                          sample_weight_mode={'dense_1': 'temporal'})
    
        # `loss` does not exist.
        with pytest.raises(ValueError):
            model.compile(optimizer, loss=[])
    
>       model.compile(optimizer, loss=['mse', 'mae'])

test_training.py:448: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611: in mean_absolute_error
    y_pred = K.constant(y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649: in constant
    value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929: in constant
    return constant_op.constant(value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449: in make_tensor_proto
    _AssertCompatible(values, dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 3) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
        fn(values)
      except ValueError as e:
        [mismatch] = e.args
        if dtype is None:
          raise TypeError("List of Tensors when single Tensor expected")
        else:
          raise TypeError("Expected %s, got %s of type '%s' instead." %
>                         (dtype.name, repr(mismatch), type(mismatch).__name__))
E         TypeError: Expected float32, got <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 3) dtype=float32> of type 'Tensor' instead.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331: TypeError
---------------------------- Captured stdout call -----------------------------
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.6705 - dense_1_loss: 0.4136 - dropout_loss: 0.5137
10/10 [==============================] - 0s 2ms/step - loss: 0.6040 - dense_1_loss: 0.3630 - dropout_loss: 0.4282
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.7381 - dense_1_loss: 0.4862 - dropout_loss: 0.5039
10/10 [==============================] - 0s 2ms/step - loss: 0.5924 - dense_1_loss: 0.3732 - dropout_loss: 0.4177
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.6310 - dense_1_loss: 0.4812 - dropout_loss: 0.2995
10/10 [==============================] - 0s 2ms/step - loss: 0.5308 - dense_1_loss: 0.3548 - dropout_loss: 0.3053
Train on 5 samples, validate on 5 samples
Epoch 1/1

4/5 [=======================>......] - ETA: 0s - loss: 0.7077 - dense_1_loss: 0.3725 - dropout_loss: 0.6706
5/5 [==============================] - 0s 9ms/step - loss: 0.7218 - dense_1_loss: 0.4461 - dropout_loss: 0.5936 - val_loss: 0.3822 - val_dense_1_loss: 0.2671 - val_dropout_loss: 0.1051
Train on 5 samples, validate on 5 samples
Epoch 1/1

4/5 [=======================>......] - ETA: 0s - loss: 0.7380 - dense_1_loss: 0.4146 - dropout_loss: 0.6468
5/5 [==============================] - 0s 6ms/step - loss: 0.6922 - dense_1_loss: 0.3693 - dropout_loss: 0.5082 - val_loss: 0.3791 - val_dense_1_loss: 0.2640 - val_dropout_loss: 0.1051
Train on 10 samples, validate on 10 samples
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.5945 - dense_1_loss: 0.3508 - dropout_loss: 0.4874
10/10 [==============================] - 0s 3ms/step - loss: 0.5494 - dense_1_loss: 0.3418 - dropout_loss: 0.3637 - val_loss: 0.4213 - val_dense_1_loss: 0.3553 - val_dropout_loss: 0.1314
Train on 10 samples, validate on 10 samples
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.6312 - dense_1_loss: 0.2907 - dropout_loss: 0.6811
10/10 [==============================] - 0s 3ms/step - loss: 0.5755 - dense_1_loss: 0.3650 - dropout_loss: 0.4094 - val_loss: 0.4162 - val_dense_1_loss: 0.3502 - val_dropout_loss: 0.1314
Train on 10 samples, validate on 10 samples
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.5417 - dense_1_loss: 0.3991 - dropout_loss: 0.2853
10/10 [==============================] - 0s 3ms/step - loss: 0.5818 - dense_1_loss: 0.3305 - dropout_loss: 0.4966 - val_loss: 0.4116 - val_dense_1_loss: 0.3456 - val_dropout_loss: 0.1314

 4/10 [===========>..................] - ETA: 0s
10/10 [==============================] - 0s 2ms/step
Epoch 3/5

 4/10 [===========>..................] - ETA: 0s - loss: 0.6083 - dense_1_loss: 0.2896 - dropout_loss: 0.3187 - dense_1_acc: 0.0000e+00
10/10 [==============================] - 0s 2ms/step - loss: 0.7750 - dense_1_loss: 0.3237 - dropout_loss: 0.4420 - dense_1_acc: 0.1000
Epoch 4/5

 4/10 [===========>..................] - ETA: 0s - loss: 0.5809 - dense_1_loss: 0.2610 - dropout_loss: 0.3199 - dense_1_acc: 0.0000e+00
10/10 [==============================] - 0s 2ms/step - loss: 0.7191 - dense_1_loss: 0.2969 - dropout_loss: 0.4267 - dense_1_acc: 0.1000
Epoch 5/5

 4/10 [===========>..................] - ETA: 0s - loss: 0.6827 - dense_1_loss: 0.3026 - dropout_loss: 0.3801 - dense_1_acc: 0.0000e+00
10/10 [==============================] - 0s 2ms/step - loss: 0.7649 - dense_1_loss: 0.2788 - dropout_loss: 0.5260 - dense_1_acc: 0.1000
Epoch 3/5

1/3 [=========>....................] - ETA: 0s - loss: 0.7874 - dense_1_loss: 0.3507 - dropout_loss: 0.4367 - dense_1_acc: 0.0000e+00
3/3 [==============================] - 0s 10ms/step - loss: 0.6653 - dense_1_loss: 0.2774 - dropout_loss: 0.3879 - dense_1_acc: 0.1667
Epoch 4/5

1/3 [=========>....................] - ETA: 0s - loss: 0.9537 - dense_1_loss: 0.4014 - dropout_loss: 0.5523 - dense_1_acc: 0.0000e+00
3/3 [==============================] - 0s 10ms/step - loss: 0.8854 - dense_1_loss: 0.3554 - dropout_loss: 0.5301 - dense_1_acc: 0.0833
Epoch 5/5

1/3 [=========>....................] - ETA: 0s - loss: 0.7433 - dense_1_loss: 0.3851 - dropout_loss: 0.3583 - dense_1_acc: 0.2500
3/3 [==============================] - 0s 5ms/step - loss: 0.9746 - dense_1_loss: 0.3936 - dropout_loss: 0.5810 - dense_1_acc: 0.0833
Epoch 1/1

 4/10 [===========>..................] - ETA: 0s - loss: 0.6602 - dense_1_loss: 0.3865 - dropout_loss: 0.2737 - dense_1_mse: 0.3865 - dropout_mse: 0.2737
10/10 [==============================] - 0s 3ms/step - loss: 0.7654 - dense_1_loss: 0.3559 - dropout_loss: 0.3994 - dense_1_mse: 0.3559 - dropout_mse: 0.3994

 4/10 [===========>..................] - ETA: 0s
10/10 [==============================] - 0s 2ms/step

1/3 [=========>....................] - ETA: 0s
3/3 [==============================] - 0s 10ms/step

1/3 [=========>....................] - ETA: 0s
3/3 [==============================] - 0s 5ms/step
---------------------------- Captured stderr call -----------------------------
Using TensorFlow backend.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2020-10-04 13:12:33.937144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-04 13:12:34.067140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-04 13:12:34.068815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-04 13:12:34.073986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-04 13:12:34.078464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-04 13:12:34.080262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-04 13:12:34.086790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-04 13:12:34.091306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-04 13:12:34.103464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-04 13:12:34.104408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-04 13:12:34.105067: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-04 13:12:34.119125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-04 13:12:34.119752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-04 13:12:34.120098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-04 13:12:34.120440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-04 13:12:34.120779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-04 13:12:34.121128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-04 13:12:34.121471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-04 13:12:34.121819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-04 13:12:34.122646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-04 13:12:35.197653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-04 13:12:35.198218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-04 13:12:35.198547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-04 13:12:35.199628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-10-04 13:12:35.750246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
------------------------------ Captured log call ------------------------------
WARNING  tensorflow:deprecation.py:506 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
______________________ test_training_with_loss_instance _______________________

values = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
>       fn(values)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>

    def inner(values):
>     _ = [_check_failed(v) for v in nest.flatten(values)
           if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <list_iterator object at 0x000001B4B4547A20>

    _ = [_check_failed(v) for v in nest.flatten(values)
>        if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

v = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>

    def _check_failed(v):
      # NB. none of the _check_* functions could raise a ValueError, so
      # it is safe to use here.
>     raise ValueError(v)
E     ValueError: Tensor("dense_1/BiasAdd:0", shape=(?, 4), dtype=float32)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:248: ValueError

During handling of the above exception, another exception occurred:

    def test_training_with_loss_instance():
        a = Input(shape=(3,), name='input_a')
        b = Input(shape=(3,), name='input_b')
    
        dense = Dense(4, name='dense')
        c = dense(a)
        d = dense(b)
        e = Dropout(0.5, name='dropout')(c)
    
        model = Model([a, b], [d, e])
        loss_weights = [1., 0.5]
        model.compile(
            'sgd',
            loss=losses.MeanSquaredError(),
            metrics=['mae'],
>           loss_weights=loss_weights)

test_training.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611: in mean_absolute_error
    y_pred = K.constant(y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649: in constant
    value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929: in constant
    return constant_op.constant(value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449: in make_tensor_proto
    _AssertCompatible(values, dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
        fn(values)
      except ValueError as e:
        [mismatch] = e.args
        if dtype is None:
          raise TypeError("List of Tensors when single Tensor expected")
        else:
          raise TypeError("Expected %s, got %s of type '%s' instead." %
>                         (dtype.name, repr(mismatch), type(mismatch).__name__))
E         TypeError: Expected float32, got <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32> of type 'Tensor' instead.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331: TypeError
________________________ test_model_with_partial_loss _________________________

values = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
>       fn(values)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 4) dtype=float32>

    def inner(values):
>     _ = [_check_failed(v) for v in nest.flatten(values)
           if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <list_iterator object at 0x000001B4B4A52E10>

    _ = [_check_failed(v) for v in nest.flatten(values)
>        if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

v = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 4) dtype=float32>

    def _check_failed(v):
      # NB. none of the _check_* functions could raise a ValueError, so
      # it is safe to use here.
>     raise ValueError(v)
E     ValueError: Tensor("dropout/cond/Merge:0", shape=(?, 4), dtype=float32)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:248: ValueError

During handling of the above exception, another exception occurred:

    def test_model_with_partial_loss():
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1')(a)
        dp = Dropout(0.5, name='dropout')
        a_3 = dp(a_2)
        model = Model(a, [a_2, a_3])
    
        optimizer = 'rmsprop'
        loss = {'dropout': 'mse'}
>       model.compile(optimizer, loss, metrics=['mae'])

test_training.py:988: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611: in mean_absolute_error
    y_pred = K.constant(y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649: in constant
    value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929: in constant
    return constant_op.constant(value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449: in make_tensor_proto
    _AssertCompatible(values, dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
        fn(values)
      except ValueError as e:
        [mismatch] = e.args
        if dtype is None:
          raise TypeError("List of Tensors when single Tensor expected")
        else:
          raise TypeError("Expected %s, got %s of type '%s' instead." %
>                         (dtype.name, repr(mismatch), type(mismatch).__name__))
E         TypeError: Expected float32, got <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 4) dtype=float32> of type 'Tensor' instead.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331: TypeError
________ test_training_and_eval_methods_on_symbolic_tensors_single_io _________

values = <tf.Tensor 'dense/BiasAdd:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
>       fn(values)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dense/BiasAdd:0' shape=(?, 4) dtype=float32>

    def inner(values):
>     _ = [_check_failed(v) for v in nest.flatten(values)
           if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <list_iterator object at 0x000001B4B4B84630>

    _ = [_check_failed(v) for v in nest.flatten(values)
>        if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

v = <tf.Tensor 'dense/BiasAdd:0' shape=(?, 4) dtype=float32>

    def _check_failed(v):
      # NB. none of the _check_* functions could raise a ValueError, so
      # it is safe to use here.
>     raise ValueError(v)
E     ValueError: Tensor("dense/BiasAdd:0", shape=(?, 4), dtype=float32)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:248: ValueError

During handling of the above exception, another exception occurred:

    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')
    def test_training_and_eval_methods_on_symbolic_tensors_single_io():
        x = keras.layers.Input(shape=(3,), name='input')
        y = keras.layers.Dense(4, name='dense')(x)
        model = keras.Model(x, y)
    
        optimizer = 'rmsprop'
        loss = 'mse'
        metrics = ['mae']
>       model.compile(optimizer, loss, metrics=metrics)

test_training.py:1445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611: in mean_absolute_error
    y_pred = K.constant(y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649: in constant
    value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929: in constant
    return constant_op.constant(value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449: in make_tensor_proto
    _AssertCompatible(values, dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dense/BiasAdd:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
        fn(values)
      except ValueError as e:
        [mismatch] = e.args
        if dtype is None:
          raise TypeError("List of Tensors when single Tensor expected")
        else:
          raise TypeError("Expected %s, got %s of type '%s' instead." %
>                         (dtype.name, repr(mismatch), type(mismatch).__name__))
E         TypeError: Expected float32, got <tf.Tensor 'dense/BiasAdd:0' shape=(?, 4) dtype=float32> of type 'Tensor' instead.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331: TypeError
_________ test_training_and_eval_methods_on_symbolic_tensors_multi_io _________

values = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
>       fn(values)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>

    def inner(values):
>     _ = [_check_failed(v) for v in nest.flatten(values)
           if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <list_iterator object at 0x000001B4B4801048>

    _ = [_check_failed(v) for v in nest.flatten(values)
>        if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

v = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>

    def _check_failed(v):
      # NB. none of the _check_* functions could raise a ValueError, so
      # it is safe to use here.
>     raise ValueError(v)
E     ValueError: Tensor("dense_1/BiasAdd:0", shape=(?, 4), dtype=float32)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:248: ValueError

During handling of the above exception, another exception occurred:

    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')
    def test_training_and_eval_methods_on_symbolic_tensors_multi_io():
        a = keras.layers.Input(shape=(3,), name='input_a')
        b = keras.layers.Input(shape=(3,), name='input_b')
    
        dense = keras.layers.Dense(4, name='dense')
        c = dense(a)
        d = dense(b)
        e = keras.layers.Dropout(0.5, name='dropout')(c)
    
        model = keras.models.Model([a, b], [d, e])
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
        metrics = ['mae']
>       model.compile(optimizer, loss, metrics=metrics, loss_weights=loss_weights)

test_training.py:1476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611: in mean_absolute_error
    y_pred = K.constant(y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649: in constant
    value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929: in constant
    return constant_op.constant(value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449: in make_tensor_proto
    _AssertCompatible(values, dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
        fn(values)
      except ValueError as e:
        [mismatch] = e.args
        if dtype is None:
          raise TypeError("List of Tensors when single Tensor expected")
        else:
          raise TypeError("Expected %s, got %s of type '%s' instead." %
>                         (dtype.name, repr(mismatch), type(mismatch).__name__))
E         TypeError: Expected float32, got <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 4) dtype=float32> of type 'Tensor' instead.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331: TypeError
____________________________ test_loss_correctness ____________________________

values = <tf.Tensor 'bias_1/add:0' shape=(?, 1) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
>       fn(values)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'bias_1/add:0' shape=(?, 1) dtype=float32>

    def inner(values):
>     _ = [_check_failed(v) for v in nest.flatten(values)
           if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <list_iterator object at 0x000001B4B4474C88>

    _ = [_check_failed(v) for v in nest.flatten(values)
>        if not isinstance(v, expected_types)]

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

v = <tf.Tensor 'bias_1/add:0' shape=(?, 1) dtype=float32>

    def _check_failed(v):
      # NB. none of the _check_* functions could raise a ValueError, so
      # it is safe to use here.
>     raise ValueError(v)
E     ValueError: Tensor("bias_1/add:0", shape=(?, 1), dtype=float32)

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:248: ValueError

During handling of the above exception, another exception occurred:

    def test_loss_correctness():
        class Bias(Layer):
    
            def build(self, input_shape):
                self.bias = self.add_weight('bias', (1,), initializer='zeros')
    
            def call(self, inputs):
                return inputs + self.bias
    
        inp = Input(shape=(1,))
        out = Bias()(inp)
        model = Model(inp, out)
        model.compile(
            keras.optimizers.SGD(lr=0.1),
>           loss=keras.losses.MeanAbsoluteError())

test_training.py:1749: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611: in mean_absolute_error
    y_pred = K.constant(y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649: in constant
    value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929: in constant
    return constant_op.constant(value, dtype=dtype, shape=shape, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449: in make_tensor_proto
    _AssertCompatible(values, dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = <tf.Tensor 'bias_1/add:0' shape=(?, 1) dtype=float32>
dtype = tf.float32

    def _AssertCompatible(values, dtype):
      if dtype is None:
        fn = _check_not_tensor
      else:
        try:
          fn = _TF_TO_IS_OK[dtype]
        except KeyError:
          # There isn't a specific fn, so we try to do the best possible.
          if dtype.is_integer:
            fn = _check_int
          elif dtype.is_floating:
            fn = _check_float
          elif dtype.is_complex:
            fn = _check_complex
          elif dtype.is_quantized:
            fn = _check_quantized
          else:
            fn = _check_not_tensor
    
      try:
        fn(values)
      except ValueError as e:
        [mismatch] = e.args
        if dtype is None:
          raise TypeError("List of Tensors when single Tensor expected")
        else:
          raise TypeError("Expected %s, got %s of type '%s' instead." %
>                         (dtype.name, repr(mismatch), type(mismatch).__name__))
E         TypeError: Expected float32, got <tf.Tensor 'bias_1/add:0' shape=(?, 1) dtype=float32> of type 'Tensor' instead.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331: TypeError
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_methods
test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_methods
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods failed and was not selected for rerun.
	<class 'TypeError'>
	Expected float32, got <tf.Tensor 'dropout/cond/Merge:0' shape=(?, 3) dtype=float32> of type 'Tensor' instead.
	[<TracebackEntry C:\Users\mutation\Desktop\testcase\tests\keras\engine\test_training.py:448>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:611>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:649>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:929>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:449>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:331>]
test_fit_generator passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_model_methods - TypeError: Expected float32, go...
FAILED test_training.py::test_training_with_loss_instance - TypeError: Expect...
FAILED test_training.py::test_model_with_partial_loss - TypeError: Expected f...
FAILED test_training.py::test_training_and_eval_methods_on_symbolic_tensors_single_io
FAILED test_training.py::test_training_and_eval_methods_on_symbolic_tensors_multi_io
FAILED test_training.py::test_loss_correctness - TypeError: Expected float32,...
============ 6 failed, 27 passed, 1 skipped, 7 warnings in 29.87s =============
