2020-10-04 13:05:51.321563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py ...FFFFsFF...FF.FFFFFF...F.FF.FFFF                      [100%]

================================== FAILURES ===================================
_____________________________ test_model_methods ______________________________

    @flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))
    def test_model_methods():
        model = get_model(num_outputs=2)
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        # training/testing doesn't work before compiling.
        with pytest.raises(RuntimeError):
            model.train_on_batch([input_a_np, input_b_np],
                                 [output_a_np, output_b_np])
    
        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
>                     sample_weight_mode=None)

test_training.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
---------------------------- Captured stderr call -----------------------------
Using TensorFlow backend.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
------------------------------ Captured log call ------------------------------
WARNING  tensorflow:deprecation.py:506 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
_____________________________ test_fit_generator ______________________________

    @flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))
    def test_fit_generator():
        model = get_model(num_outputs=2)
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
    
        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
>                     sample_weight_mode=None)

test_training.py:480: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
__________________________ test_fit_generator_shape ___________________________

    def test_fit_generator_shape():
        # predict_generator output shape behavior should be consistent
        def expected_shape(batch_size, n_batches):
            return (batch_size * n_batches, 4), (batch_size * n_batches, 3)
    
        model = get_model(num_outputs=2)
        optimizer = 'rmsprop'
        loss = 'mse'
    
        # Multiple outputs and one step.
        batch_size = 5
        sequence_length = 1
        shape_0, shape_1 = expected_shape(batch_size, sequence_length)
        out = model.predict_generator(
            RandomSequence(batch_size, sequence_length=sequence_length))
        assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1
    
        out = model.predict(
            RandomSequence(batch_size, sequence_length=sequence_length))
        assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1
    
        # Multiple outputs and multiple steps.
        batch_size = 5
        sequence_length = 2
        shape_0, shape_1 = expected_shape(batch_size, sequence_length)
        out = model.predict_generator(
            RandomSequence(batch_size, sequence_length=sequence_length))
        assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1
    
        out = model.predict(
            RandomSequence(batch_size, sequence_length=sequence_length))
        assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1
    
        # Create a model with a single output.
        single_output_model = get_model(num_outputs=1)
        single_output_model.compile(optimizer, loss,
>                                   metrics=[], sample_weight_mode=None)

test_training.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
---------------------------- Captured stderr call -----------------------------
2020-10-04 13:05:55.306612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-04 13:05:55.444004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-04 13:05:55.446136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-04 13:05:55.452285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-04 13:05:55.458037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-04 13:05:55.459823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-04 13:05:55.465992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-04 13:05:55.470216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-04 13:05:55.482240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-04 13:05:55.483320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-04 13:05:55.484109: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-04 13:05:55.499456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-04 13:05:55.500077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-04 13:05:55.500428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-04 13:05:55.500773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-04 13:05:55.501116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-04 13:05:55.501473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-04 13:05:55.501820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-04 13:05:55.502170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-04 13:05:55.503023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-04 13:05:56.557176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-04 13:05:56.557587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-04 13:05:56.557824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-04 13:05:56.558659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-10-04 13:05:57.060317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
------------------------------ Captured log call ------------------------------
WARNING  tensorflow:module_wrapper.py:139 From C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
______________________ test_training_with_loss_instance _______________________

    def test_training_with_loss_instance():
        a = Input(shape=(3,), name='input_a')
        b = Input(shape=(3,), name='input_b')
    
        dense = Dense(4, name='dense')
        c = dense(a)
        d = dense(b)
        e = Dropout(0.5, name='dropout')(c)
    
        model = Model([a, b], [d, e])
        loss_weights = [1., 0.5]
        model.compile(
            'sgd',
            loss=losses.MeanSquaredError(),
            metrics=['mae'],
>           loss_weights=loss_weights)

test_training.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
___________________________ test_trainable_argument ___________________________

    def test_trainable_argument():
        x = np.random.random((5, 3))
        y = np.random.random((5, 2))
    
        model = Sequential()
        model.add(Dense(2, input_dim=3, trainable=False))
>       model.compile('rmsprop', 'mse')

test_training.py:785: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
__________________________ test_with_list_as_targets __________________________

    def test_with_list_as_targets():
        model = Sequential()
        model.add(Dense(1, input_dim=3, trainable=False))
>       model.compile('rmsprop', 'mse')

test_training.py:805: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
______________________ test_model_with_input_feed_tensor ______________________

    @pytest.mark.skipif(K.backend() != 'tensorflow',
                        reason='Requires TensorFlow backend')
    def test_model_with_input_feed_tensor():
        """We test building a model with a TF variable as input.
        We should be able to call fit, evaluate, predict,
        by only passing them data for the placeholder inputs
        in the model.
        """
        import tensorflow as tf
    
        input_a_np = np.random.random((10, 3))
        input_b_np = np.random.random((10, 3))
    
        output_a_np = np.random.random((10, 4))
        output_b_np = np.random.random((10, 3))
    
        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))
        b = Input(shape=(3,), name='input_b')
    
        a_2 = Dense(4, name='dense_1')(a)
        dp = Dropout(0.5, name='dropout')
        b_2 = dp(b)
    
        model = Model([a, b], [a_2, b_2])
        model.summary()
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
        model.compile(optimizer, loss, metrics=['mean_squared_error'],
                      loss_weights=loss_weights,
>                     sample_weight_mode=None)

test_training.py:867: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
---------------------------- Captured stdout call -----------------------------
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (10, 3)              0                                            
__________________________________________________________________________________________________
input_b (InputLayer)            (None, 3)            0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (10, 4)              16          input_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 3)            0           input_b[0][0]                    
==================================================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
__________________________________________________________________________________________________
________________________ test_model_with_partial_loss _________________________

    def test_model_with_partial_loss():
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1')(a)
        dp = Dropout(0.5, name='dropout')
        a_3 = dp(a_2)
        model = Model(a, [a_2, a_3])
    
        optimizer = 'rmsprop'
        loss = {'dropout': 'mse'}
>       model.compile(optimizer, loss, metrics=['mae'])

test_training.py:988: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
_____________________________ test_target_tensors _____________________________

    def test_target_tensors():
        # single-output, as list
        model = keras.models.Sequential()
        model.add(keras.layers.Dense(4, input_shape=(4,), name='dense'))
        input_val = np.random.random((10, 4))
        target_val = np.random.random((10, 4))
        target = keras.backend.variable(target_val)
>       model.compile(optimizer='rmsprop', loss='mse', target_tensors=[target])

test_training.py:1181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
______________________ test_model_custom_target_tensors _______________________

    @pytest.mark.skipif(K.backend() == 'tensorflow' and
                        tf.__version__.startswith('2'),
                        reason='Cannot have tensors as dict keys in TF2')
    def test_model_custom_target_tensors():
        a = Input(shape=(3,), name='input_a')
        b = Input(shape=(3,), name='input_b')
    
        a_2 = Dense(4, name='dense_1')(a)
        dp = Dropout(0.5, name='dropout')
        b_2 = dp(b)
    
        y = K.placeholder([10, 4], name='y')
        y1 = K.placeholder([10, 3], name='y1')
        y2 = K.placeholder([7, 5], name='y2')
        model = Model([a, b], [a_2, b_2])
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
    
        # test list of target tensors
        with pytest.raises(ValueError):
            model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
                          sample_weight_mode=None, target_tensors=[y, y1, y2])
        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,
>                     sample_weight_mode=None, target_tensors=[y, y1])

test_training.py:1276: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
__________________ test_trainable_weights_count_consistency ___________________

    @pytest.mark.skipif(sys.version_info < (3,),
                        reason='Cannot catch warnings in python 2')
    def test_trainable_weights_count_consistency():
        """Tests the trainable weights consistency check of Model.
    
        This verifies that a warning is shown if model.trainable is modified
        and the model is summarized/run without a new call to .compile()
    
        Reproduce issue #8121
        """
        a = Input(shape=(3,), name='input_a')
        model1 = Model(inputs=a, outputs=Dense(1)(a))
    
        model1.trainable = False
        b = Input(shape=(3,), name='input_b')
        y = model1(b)
        model2 = Model(inputs=b, outputs=Dense(1)(y))
    
>       model2.compile(optimizer='adam', loss='mse')

test_training.py:1331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
____________________________ test_pandas_dataframe ____________________________

    def test_pandas_dataframe():
        input_a = Input(shape=(3,), name='input_a')
        input_b = Input(shape=(3,), name='input_b')
    
        x = Dense(4, name='dense_1')(input_a)
        y = Dense(3, name='desne_2')(input_b)
    
        model_1 = Model(inputs=input_a, outputs=x)
        model_2 = Model(inputs=[input_a, input_b], outputs=[x, y])
    
        optimizer = 'rmsprop'
        loss = 'mse'
    
>       model_1.compile(optimizer=optimizer, loss=loss)

test_training.py:1370: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
________ test_training_and_eval_methods_on_symbolic_tensors_single_io _________

    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')
    def test_training_and_eval_methods_on_symbolic_tensors_single_io():
        x = keras.layers.Input(shape=(3,), name='input')
        y = keras.layers.Dense(4, name='dense')(x)
        model = keras.Model(x, y)
    
        optimizer = 'rmsprop'
        loss = 'mse'
        metrics = ['mae']
>       model.compile(optimizer, loss, metrics=metrics)

test_training.py:1445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
_________ test_training_and_eval_methods_on_symbolic_tensors_multi_io _________

    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')
    def test_training_and_eval_methods_on_symbolic_tensors_multi_io():
        a = keras.layers.Input(shape=(3,), name='input_a')
        b = keras.layers.Input(shape=(3,), name='input_b')
    
        dense = keras.layers.Dense(4, name='dense')
        c = dense(a)
        d = dense(b)
        e = keras.layers.Dropout(0.5, name='dropout')(c)
    
        model = keras.models.Model([a, b], [d, e])
    
        optimizer = 'rmsprop'
        loss = 'mse'
        loss_weights = [1., 0.5]
        metrics = ['mae']
>       model.compile(optimizer, loss, metrics=metrics, loss_weights=loss_weights)

test_training.py:1476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
____________________________ test_validation_freq _____________________________

    def test_validation_freq():
        model = Sequential([Dense(1)])
        model.compile('sgd', 'mse')
    
        def _gen():
            while True:
                yield np.ones((2, 10)), np.ones((2, 1))
    
        x, y = np.ones((10, 10)), np.ones((10, 1))
    
        class ValCounter(Callback):
    
            def __init__(self):
                self.val_runs = 0
    
            def on_test_begin(self, logs=None):
                self.val_runs += 1
    
        # Test in training_arrays.py
        val_counter = ValCounter()
        model.fit(
            x,
            y,
            batch_size=2,
            epochs=4,
            validation_data=(x, y),
            validation_freq=2,
>           callbacks=[val_counter])

test_training.py:1720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:550: in _standardize_user_data
    target_tensors=target_tensors)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
___________________________ test_model_metrics_list ___________________________

    def test_model_metrics_list():
    
        class LayerWithAddMetric(Layer):
    
            def __init__(self):
                super(LayerWithAddMetric, self).__init__()
                self.dense = keras.layers.Dense(1, kernel_initializer='ones')
    
            def __call__(self, inputs):
                outputs = self.dense(inputs)
                return outputs
    
        class LayerWithNestedAddMetricLayer(Layer):
    
            def __init__(self):
                super(LayerWithNestedAddMetricLayer, self).__init__()
                self.layer = LayerWithAddMetric()
    
            def call(self, inputs):
                outputs = self.layer(inputs)
                self.add_metric(K.sum(outputs), name='metric_4')
                return outputs
    
        x = Input(shape=(1,))
        y = LayerWithNestedAddMetricLayer()(x)
    
        model = keras.models.Model(x, y)
        model.add_metric(K.sum(y), name='metric_2')
        model.add_metric(metrics.Mean(name='metric_3')(y))
    
        model.compile(
            'sgd',
            loss='mse',
>           metrics=[metrics.MeanSquaredError('metric_1')])

test_training.py:1790: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
_______________________ test_model_metrics_list_in_call _______________________

    def test_model_metrics_list_in_call():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2)
    
            def call(self, x):
                self.add_metric(K.sum(x), name='metric_2')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(
            loss='mse',
            optimizer='adam',
            metrics=[metrics.MeanSquaredError('metric_1')])
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1822: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:550: in _standardize_user_data
    target_tensors=target_tensors)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
__________________________ test_add_metric_on_model ___________________________

    def test_add_metric_on_model():
        x = Input(shape=(1,))
        y = Dense(1, kernel_initializer='ones', trainable=False)(x)
        model = Model(x, y)
        model.add_metric(K.sum(y), name='metric_1')
        model.add_metric(metrics.Mean(name='metric_2')(y))
>       model.compile('sgd', loss='mse', metrics=['mse'])

test_training.py:1864: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:842: in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:1033: in call_metric_function
    update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\metrics_utils.py:42: in decorated
    update_op = update_state_fn(*args, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\metrics.py:318: in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
________________________ test_add_metric_in_model_call ________________________

    def test_add_metric_in_model_call():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean = metrics.Mean(name='metric_1')
    
            def call(self, x):
                self.add_metric(K.sum(x), name='metric_2')
                # Provide same name as in the instance created in __init__
                # for eager mode
                self.add_metric(self.mean(x), name='metric_1')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='sgd')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:550: in _standardize_user_data
    target_tensors=target_tensors)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
_______________________ test_multiple_add_metric_calls ________________________

    def test_multiple_add_metric_calls():
    
        class TestModel(Model):
    
            def __init__(self):
                super(TestModel, self).__init__(name='test_model')
                self.dense1 = keras.layers.Dense(2, kernel_initializer='ones')
                self.mean1 = metrics.Mean(name='metric_1')
                self.mean2 = metrics.Mean(name='metric_2')
    
            def call(self, x):
                self.add_metric(self.mean2(x), name='metric_2')
                self.add_metric(self.mean1(x), name='metric_1')
                self.add_metric(K.sum(x), name='metric_3')
                return self.dense1(x)
    
        model = TestModel()
        model.compile(loss='mse', optimizer='sgd')
    
        x = np.ones(shape=(10, 1))
        y = np.ones(shape=(10, 2))
>       history = model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))

test_training.py:1946: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:550: in _standardize_user_data
    target_tensors=target_tensors)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
________________________ test_add_metric_in_layer_call ________________________

    def test_add_metric_in_layer_call():
    
        class TestLayer(Layer):
    
            def build(self, input_shape):
                self.a = self.add_weight(
                    'a', (1, 1), initializer='ones', trainable=False)
                self.built = True
    
            def call(self, inputs):
                self.add_metric(K.sum(inputs), name='metric_1')
                return inputs + 1
    
        inp = Input(shape=(1,))
        x = TestLayer(input_shape=(1,))(inp)
        x = keras.layers.Dense(2, kernel_initializer='ones')(x)
    
        model = Model(inp, x)
>       model.compile('adam', loss='mse')

test_training.py:1977: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229: in compile
    self.total_loss = self._prepare_total_loss(masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692: in _prepare_total_loss
    y_true, y_pred, sample_weight=sample_weight)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71: in __call__
    losses = self.call(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132: in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606: in mean_squared_error
    return K.mean(K.square(y_pred - y_true), axis=-1)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903: in binary_op_wrapper
    y, dtype_hint=x.dtype.base_dtype, name="y")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = None, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods failed and was not selected for rerun.
	<class 'ValueError'>
	None values not supported.
	[<TracebackEntry C:\Users\mutation\Desktop\testcase\tests\keras\engine\test_training.py:183>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437>]
test_fit_generator failed and was not selected for rerun.
	<class 'ValueError'>
	None values not supported.
	[<TracebackEntry C:\Users\mutation\Desktop\testcase\tests\keras\engine\test_training.py:480>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:229>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:692>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:71>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:132>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:606>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:903>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265>, <TracebackEntry C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437>]

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_model_methods - ValueError: None values not sup...
FAILED test_training.py::test_fit_generator - ValueError: None values not sup...
FAILED test_training.py::test_fit_generator_shape - ValueError: None values n...
FAILED test_training.py::test_training_with_loss_instance - ValueError: None ...
FAILED test_training.py::test_trainable_argument - ValueError: None values no...
FAILED test_training.py::test_with_list_as_targets - ValueError: None values ...
FAILED test_training.py::test_model_with_input_feed_tensor - ValueError: None...
FAILED test_training.py::test_model_with_partial_loss - ValueError: None valu...
FAILED test_training.py::test_target_tensors - ValueError: None values not su...
FAILED test_training.py::test_model_custom_target_tensors - ValueError: None ...
FAILED test_training.py::test_trainable_weights_count_consistency - ValueErro...
FAILED test_training.py::test_pandas_dataframe - ValueError: None values not ...
FAILED test_training.py::test_training_and_eval_methods_on_symbolic_tensors_single_io
FAILED test_training.py::test_training_and_eval_methods_on_symbolic_tensors_multi_io
FAILED test_training.py::test_validation_freq - ValueError: None values not s...
FAILED test_training.py::test_model_metrics_list - ValueError: None values no...
FAILED test_training.py::test_model_metrics_list_in_call - ValueError: None v...
FAILED test_training.py::test_add_metric_on_model - ValueError: None values n...
FAILED test_training.py::test_add_metric_in_model_call - ValueError: None val...
FAILED test_training.py::test_multiple_add_metric_calls - ValueError: None va...
FAILED test_training.py::test_add_metric_in_layer_call - ValueError: None val...
============ 21 failed, 12 passed, 1 skipped, 5 warnings in 16.92s ============
