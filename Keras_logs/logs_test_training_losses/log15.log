2020-10-04 13:09:46.808340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 34 items

test_training.py ..F....s..........................                      [100%]

================================== FAILURES ===================================
_______________________ test_weighted_masked_objective ________________________

    def test_weighted_masked_objective():
        a = Input(shape=(3,), name='input_a')
    
        # weighted_masked_objective
        def mask_dummy(y_true=None, y_pred=None, weight=None):
            return K.placeholder(y_true.shape)
    
        weighted_function = training_utils.weighted_masked_objective(
            losses.categorical_crossentropy)
>       weighted_function(a, a, None)

test_training.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:400: in weighted
    score_array = fn(y_true, y_pred)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\losses.py:691: in categorical_crossentropy
    return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:3383: in categorical_crossentropy
    target, output, from_logits=from_logits, axis=axis)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\keras\backend.py:4364: in categorical_crossentropy
    return -math_ops.reduce_sum(target * math_ops.log(output), axis)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\math_ops.py:924: in r_binary_op_wrapper
    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name="x")
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1184: in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1242: in convert_to_tensor_v2
    as_ref=False)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\ops.py:1297: in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:286: in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:227: in constant
    allow_broadcast=True)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\constant_op.py:265: in _constant_impl
    allow_broadcast=allow_broadcast))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

values = None, dtype = tf.float32, shape = None, verify_shape = False
allow_broadcast = True

    @tf_export("make_tensor_proto")
    def make_tensor_proto(values, dtype=None, shape=None, verify_shape=False,
                          allow_broadcast=False):
      """Create a TensorProto.
    
      In TensorFlow 2.0, representing tensors as protos should no longer be a
      common workflow. That said, this utility function is still useful for
      generating TF Serving request protos:
    
        request = tensorflow_serving.apis.predict_pb2.PredictRequest()
        request.model_spec.name = "my_model"
        request.model_spec.signature_name = "serving_default"
        request.inputs["images"].CopyFrom(tf.make_tensor_proto(X_new))
    
      make_tensor_proto accepts "values" of a python scalar, a python list, a
      numpy ndarray, or a numpy scalar.
    
      If "values" is a python scalar or a python list, make_tensor_proto
      first convert it to numpy ndarray. If dtype is None, the
      conversion tries its best to infer the right numpy data
      type. Otherwise, the resulting numpy array has a compatible data
      type with the given dtype.
    
      In either case above, the numpy ndarray (either the caller provided
      or the auto converted) must have the compatible type with dtype.
    
      make_tensor_proto then converts the numpy array to a tensor proto.
    
      If "shape" is None, the resulting tensor proto represents the numpy
      array precisely.
    
      Otherwise, "shape" specifies the tensor's shape and the numpy array
      can not have more elements than what "shape" specifies.
    
      Args:
        values:         Values to put in the TensorProto.
        dtype:          Optional tensor_pb2 DataType value.
        shape:          List of integers representing the dimensions of tensor.
        verify_shape:   Boolean that enables verification of a shape of values.
        allow_broadcast:  Boolean that enables allowing scalars and 1 length vector
            broadcasting. Cannot be true when verify_shape is true.
    
      Returns:
        A `TensorProto`. Depending on the type, it may contain data in the
        "tensor_content" attribute, which is not directly useful to Python programs.
        To access the values you should convert the proto back to a numpy ndarray
        with `tf.make_ndarray(proto)`.
    
        If `values` is a `TensorProto`, it is immediately returned; `dtype` and
        `shape` are ignored.
    
      Raises:
        TypeError:  if unsupported types are provided.
        ValueError: if arguments have inappropriate values or if verify_shape is
         True and shape of values is not equals to a shape from the argument.
    
      """
      if allow_broadcast and verify_shape:
        raise ValueError("allow_broadcast and verify_shape are not both allowed.")
      if isinstance(values, tensor_pb2.TensorProto):
        return values
    
      if dtype:
        dtype = dtypes.as_dtype(dtype)
    
      is_quantized = (
          dtype in [
              dtypes.qint8, dtypes.quint8, dtypes.qint16, dtypes.quint16,
              dtypes.qint32
          ])
    
      if _is_array_like(values):
        values = np.asarray(values)
    
      # We first convert value to a numpy array or scalar.
      if isinstance(values, (np.ndarray, np.generic)):
        if dtype and dtype.is_numpy_compatible:
          nparray = values.astype(dtype.as_numpy_dtype)
        else:
          nparray = values
      else:
        if values is None:
>         raise ValueError("None values not supported.")
E         ValueError: None values not supported.

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\tensor_util.py:437: ValueError
============================== warnings summary ===============================
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\_pytest\config\__init__.py:1040: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: flaky
    self._mark_plugins_for_rewrite(hook)

test_training.py::test_model_methods
test_training.py::test_model_with_partial_loss
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_methods
test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dropout missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dropout.
    'be expecting any data to be passed to {0}.'.format(name))

test_training.py::test_model_with_external_loss
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
===Flaky Test Report===

test_model_methods passed 1 out of the required 1 times. Success!
test_fit_generator passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
=========================== short test summary info ===========================
FAILED test_training.py::test_weighted_masked_objective - ValueError: None va...
============ 1 failed, 32 passed, 1 skipped, 7 warnings in 30.70s =============
