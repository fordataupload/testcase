2020-10-05 15:54:22.675694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:54:25.361881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-05 15:54:25.495065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:54:25.496784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:54:25.502603: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:54:25.508278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:54:25.510060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:54:25.516873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:54:25.521317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:54:25.533339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:54:25.534352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:54:25.535122: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-05 15:54:25.549609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:54:25.550154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:54:25.550496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:54:25.550835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:54:25.551174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:54:25.551529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:54:25.551875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:54:25.552215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:54:25.553109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:54:26.620949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-05 15:54:26.621360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-05 15:54:26.621602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-05 15:54:26.622481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 31 items

test_topology.py .........................FFF...                         [100%]

================================== FAILURES ===================================
__________________ test_layer_sharing_at_heterogeneous_depth __________________

    def test_layer_sharing_at_heterogeneous_depth():
        x_val = np.random.random((10, 5))
    
        x = Input(shape=(5,))
        A = Dense(5, name='A')
        B = Dense(5, name='B')
        output = A(B(A(B(x))))
        M = Model(x, output)
    
>       output_val = M.predict(x_val)

test_topology.py:723: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1462: in predict
    callbacks=callbacks)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = <keras.engine.training.Model object at 0x000001D1367779B0>, f = None
ins = [array([[0.1763219 , 0.678622  , 0.34180529, 0.30715164, 0.78881296],
       [0.31837136, 0.17102289, 0.28640157, 0.77...0.56901684, 0.21940796, 0.85022325, 0.97496567],
       [0.06806259, 0.89110078, 0.65986531, 0.33277061, 0.36307292]])]
batch_size = 32, verbose = 0, steps = None
callbacks = <keras.callbacks.callbacks.CallbackList object at 0x000001D1367770B8>

    def predict_loop(model, f, ins,
                     batch_size=32,
                     verbose=0,
                     steps=None,
                     callbacks=None):
        """Abstract method to loop over some data in batches.
    
        # Arguments
            model: Keras model instance.
            f: Keras function returning a list of tensors.
            ins: list of tensors to be fed to `f`.
            batch_size: integer batch size.
            verbose: verbosity mode.
            steps: Total number of steps (batches of samples)
                before declaring `predict_loop` finished.
                Ignored with the default value of `None`.
            callbacks: List of callbacks or an instance of
                `keras.callbacks.CallbackList` to be called during prediction.
    
        # Returns
            Array of predictions (if the model has a single output)
            or list of arrays of predictions
            (if the model has multiple outputs).
        """
        num_samples = check_num_samples(ins,
                                        batch_size=batch_size,
                                        steps=steps,
                                        steps_name='steps')
    
        # Check if callbacks have not been already configured
        if not isinstance(callbacks, cbks.CallbackList):
            callbacks = cbks.CallbackList(callbacks)
            callback_model = model._get_callback_model()
            callbacks.set_model(callback_model)
            callback_params = {
                'batch_size': batch_size,
                'steps': steps,
                'samples': num_samples,
                'verbose': verbose,
            }
            callbacks.set_params(callback_params)
    
        if verbose == 1:
            if steps is not None:
                progbar = Progbar(target=steps)
            else:
                progbar = Progbar(target=num_samples)
    
        indices_for_conversion_to_dense = []
        for i in range(len(model._feed_inputs)):
            if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):
                indices_for_conversion_to_dense.append(i)
    
        callbacks.model.stop_training = False
        callbacks._call_begin_hook('predict')
    
        if steps is not None:
            # Step-based predictions.
            # Since we do not know how many samples
            # we will see, we cannot pre-allocate
            # the returned Numpy arrays.
            # Instead, we store one array per batch seen
            # and concatenate them upon returning.
            unconcatenated_outs = []
            for step in range(steps):
                batch_logs = {'batch': step, 'size': 1}
                callbacks._call_batch_hook('predict', 'begin', step, batch_logs)
                batch_outs = f(ins)
                batch_outs = to_list(batch_outs)
                if step == 0:
                    for batch_out in batch_outs:
                        unconcatenated_outs.append([])
                for i, batch_out in enumerate(batch_outs):
                    unconcatenated_outs[i].append(batch_out)
    
                batch_logs['outputs'] = batch_outs
                callbacks._call_batch_hook('predict', 'end', step, batch_logs)
                if verbose == 1:
                    progbar.update(step + 1)
            callbacks.on_predict_end()
            if len(unconcatenated_outs) == 1:
                return np.concatenate(unconcatenated_outs[0], axis=0)
            return [np.concatenate(unconcatenated_outs[i], axis=0)
                    for i in range(len(unconcatenated_outs))]
        else:
            # Sample-based predictions.
            outs = []
            batches = make_batches(num_samples, batch_size)
            index_array = np.arange(num_samples)
            for batch_index, (batch_start, batch_end) in enumerate(batches):
                batch_ids = index_array[batch_start:batch_end]
                if ins and isinstance(ins[-1], int):
                    # Do not slice the training phase flag.
                    ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
                else:
                    ins_batch = slice_arrays(ins, batch_ids)
                for i in indices_for_conversion_to_dense:
                    ins_batch[i] = ins_batch[i].toarray()
    
                batch_logs = {'batch': batch_index, 'size': len(batch_ids)}
                callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)
>               batch_outs = f(ins_batch)
E               TypeError: 'NoneType' object is not callable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_arrays.py:324: TypeError
____________ test_layer_sharing_at_heterogeneous_depth_with_concat ____________

    def test_layer_sharing_at_heterogeneous_depth_with_concat():
        input_shape = (16, 9, 3)
        input_layer = Input(shape=input_shape)
    
        A = Dense(3, name='dense_A')
        B = Dense(3, name='dense_B')
        C = Dense(3, name='dense_C')
    
        x1 = B(A(input_layer))
        x2 = A(C(input_layer))
        output = layers.concatenate([x1, x2])
    
        M = Model(inputs=input_layer, outputs=output)
    
        x_val = np.random.random((10, 16, 9, 3))
>       output_val = M.predict(x_val)

test_topology.py:750: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1462: in predict
    callbacks=callbacks)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = <keras.engine.training.Model object at 0x000001D1366EE400>, f = None
ins = [array([[[[0.03841362, 0.31952024, 0.8988563 ],
         [0.99429536, 0.8894162 , 0.24451608],
         [0.60649037, 0...3018219, 0.09571741],
         [0.59663349, 0.79030638, 0.88537263],
         [0.79292757, 0.67241611, 0.60008727]]]])]
batch_size = 32, verbose = 0, steps = None
callbacks = <keras.callbacks.callbacks.CallbackList object at 0x000001D1368B5B00>

    def predict_loop(model, f, ins,
                     batch_size=32,
                     verbose=0,
                     steps=None,
                     callbacks=None):
        """Abstract method to loop over some data in batches.
    
        # Arguments
            model: Keras model instance.
            f: Keras function returning a list of tensors.
            ins: list of tensors to be fed to `f`.
            batch_size: integer batch size.
            verbose: verbosity mode.
            steps: Total number of steps (batches of samples)
                before declaring `predict_loop` finished.
                Ignored with the default value of `None`.
            callbacks: List of callbacks or an instance of
                `keras.callbacks.CallbackList` to be called during prediction.
    
        # Returns
            Array of predictions (if the model has a single output)
            or list of arrays of predictions
            (if the model has multiple outputs).
        """
        num_samples = check_num_samples(ins,
                                        batch_size=batch_size,
                                        steps=steps,
                                        steps_name='steps')
    
        # Check if callbacks have not been already configured
        if not isinstance(callbacks, cbks.CallbackList):
            callbacks = cbks.CallbackList(callbacks)
            callback_model = model._get_callback_model()
            callbacks.set_model(callback_model)
            callback_params = {
                'batch_size': batch_size,
                'steps': steps,
                'samples': num_samples,
                'verbose': verbose,
            }
            callbacks.set_params(callback_params)
    
        if verbose == 1:
            if steps is not None:
                progbar = Progbar(target=steps)
            else:
                progbar = Progbar(target=num_samples)
    
        indices_for_conversion_to_dense = []
        for i in range(len(model._feed_inputs)):
            if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):
                indices_for_conversion_to_dense.append(i)
    
        callbacks.model.stop_training = False
        callbacks._call_begin_hook('predict')
    
        if steps is not None:
            # Step-based predictions.
            # Since we do not know how many samples
            # we will see, we cannot pre-allocate
            # the returned Numpy arrays.
            # Instead, we store one array per batch seen
            # and concatenate them upon returning.
            unconcatenated_outs = []
            for step in range(steps):
                batch_logs = {'batch': step, 'size': 1}
                callbacks._call_batch_hook('predict', 'begin', step, batch_logs)
                batch_outs = f(ins)
                batch_outs = to_list(batch_outs)
                if step == 0:
                    for batch_out in batch_outs:
                        unconcatenated_outs.append([])
                for i, batch_out in enumerate(batch_outs):
                    unconcatenated_outs[i].append(batch_out)
    
                batch_logs['outputs'] = batch_outs
                callbacks._call_batch_hook('predict', 'end', step, batch_logs)
                if verbose == 1:
                    progbar.update(step + 1)
            callbacks.on_predict_end()
            if len(unconcatenated_outs) == 1:
                return np.concatenate(unconcatenated_outs[0], axis=0)
            return [np.concatenate(unconcatenated_outs[i], axis=0)
                    for i in range(len(unconcatenated_outs))]
        else:
            # Sample-based predictions.
            outs = []
            batches = make_batches(num_samples, batch_size)
            index_array = np.arange(num_samples)
            for batch_index, (batch_start, batch_end) in enumerate(batches):
                batch_ids = index_array[batch_start:batch_end]
                if ins and isinstance(ins[-1], int):
                    # Do not slice the training phase flag.
                    ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
                else:
                    ins_batch = slice_arrays(ins, batch_ids)
                for i in indices_for_conversion_to_dense:
                    ins_batch[i] = ins_batch[i].toarray()
    
                batch_logs = {'batch': batch_index, 'size': len(batch_ids)}
                callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)
>               batch_outs = f(ins_batch)
E               TypeError: 'NoneType' object is not callable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_arrays.py:324: TypeError
_______________ test_layer_sharing_at_heterogeneous_depth_order _______________

    def test_layer_sharing_at_heterogeneous_depth_order():
        # This tests for the bug in this issue
        # https://github.com/keras-team/keras/issues/11159
        # It occurs with layer sharing at heterogeneous depth when
        # the layers need to be applied in an order that differs from
        # the order that occurs in the config.
    
        input_shape = (1, 12)
        input_layer = Input(shape=input_shape)
    
        A = Dense(12, name='layer_a')
        r1 = layers.Reshape((12,))(input_layer)
        Aout1 = A(r1)
    
        r2 = layers.Reshape((12,))(A(input_layer))
        Aout2 = A(r2)
    
        # Note: if the order of the layers in the concat is
        # changed to ([Aout1, Aout2]) the bug doesn't trigger
        c1 = layers.concatenate([Aout2, Aout1])
        output = Dense(2, name='layer_b')(c1)
    
        M = Model(inputs=input_layer, outputs=output)
    
        x_val = np.random.random((10,) + input_shape)
>       output_val = M.predict(x_val)

test_topology.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1462: in predict
    callbacks=callbacks)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = <keras.engine.training.Model object at 0x000001D1368CD978>, f = None
ins = [array([[[0.30465991, 0.44046421, 0.83141206, 0.58271391, 0.76349942,
         0.86290348, 0.20746119, 0.50228128, 0.1..., 0.66844046,
         0.0225124 , 0.69026815, 0.97715438, 0.88064858, 0.55976244,
         0.77187299, 0.79682031]]])]
batch_size = 32, verbose = 0, steps = None
callbacks = <keras.callbacks.callbacks.CallbackList object at 0x000001D1368CEDD8>

    def predict_loop(model, f, ins,
                     batch_size=32,
                     verbose=0,
                     steps=None,
                     callbacks=None):
        """Abstract method to loop over some data in batches.
    
        # Arguments
            model: Keras model instance.
            f: Keras function returning a list of tensors.
            ins: list of tensors to be fed to `f`.
            batch_size: integer batch size.
            verbose: verbosity mode.
            steps: Total number of steps (batches of samples)
                before declaring `predict_loop` finished.
                Ignored with the default value of `None`.
            callbacks: List of callbacks or an instance of
                `keras.callbacks.CallbackList` to be called during prediction.
    
        # Returns
            Array of predictions (if the model has a single output)
            or list of arrays of predictions
            (if the model has multiple outputs).
        """
        num_samples = check_num_samples(ins,
                                        batch_size=batch_size,
                                        steps=steps,
                                        steps_name='steps')
    
        # Check if callbacks have not been already configured
        if not isinstance(callbacks, cbks.CallbackList):
            callbacks = cbks.CallbackList(callbacks)
            callback_model = model._get_callback_model()
            callbacks.set_model(callback_model)
            callback_params = {
                'batch_size': batch_size,
                'steps': steps,
                'samples': num_samples,
                'verbose': verbose,
            }
            callbacks.set_params(callback_params)
    
        if verbose == 1:
            if steps is not None:
                progbar = Progbar(target=steps)
            else:
                progbar = Progbar(target=num_samples)
    
        indices_for_conversion_to_dense = []
        for i in range(len(model._feed_inputs)):
            if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):
                indices_for_conversion_to_dense.append(i)
    
        callbacks.model.stop_training = False
        callbacks._call_begin_hook('predict')
    
        if steps is not None:
            # Step-based predictions.
            # Since we do not know how many samples
            # we will see, we cannot pre-allocate
            # the returned Numpy arrays.
            # Instead, we store one array per batch seen
            # and concatenate them upon returning.
            unconcatenated_outs = []
            for step in range(steps):
                batch_logs = {'batch': step, 'size': 1}
                callbacks._call_batch_hook('predict', 'begin', step, batch_logs)
                batch_outs = f(ins)
                batch_outs = to_list(batch_outs)
                if step == 0:
                    for batch_out in batch_outs:
                        unconcatenated_outs.append([])
                for i, batch_out in enumerate(batch_outs):
                    unconcatenated_outs[i].append(batch_out)
    
                batch_logs['outputs'] = batch_outs
                callbacks._call_batch_hook('predict', 'end', step, batch_logs)
                if verbose == 1:
                    progbar.update(step + 1)
            callbacks.on_predict_end()
            if len(unconcatenated_outs) == 1:
                return np.concatenate(unconcatenated_outs[0], axis=0)
            return [np.concatenate(unconcatenated_outs[i], axis=0)
                    for i in range(len(unconcatenated_outs))]
        else:
            # Sample-based predictions.
            outs = []
            batches = make_batches(num_samples, batch_size)
            index_array = np.arange(num_samples)
            for batch_index, (batch_start, batch_end) in enumerate(batches):
                batch_ids = index_array[batch_start:batch_end]
                if ins and isinstance(ins[-1], int):
                    # Do not slice the training phase flag.
                    ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
                else:
                    ins_batch = slice_arrays(ins, batch_ids)
                for i in indices_for_conversion_to_dense:
                    ins_batch[i] = ins_batch[i].toarray()
    
                batch_logs = {'batch': batch_index, 'size': len(batch_ids)}
                callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)
>               batch_outs = f(ins_batch)
E               TypeError: 'NoneType' object is not callable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_arrays.py:324: TypeError
============================== warnings summary ===============================
test_topology.py::test_recursion
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_1.
  Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.
  The tensor that caused the issue was: dense_1_12/BiasAdd:0
    str(x.name))

test_topology.py::test_activity_regularization_with_model_composition
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output model_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_1.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
=========================== short test summary info ===========================
FAILED test_topology.py::test_layer_sharing_at_heterogeneous_depth - TypeErro...
FAILED test_topology.py::test_layer_sharing_at_heterogeneous_depth_with_concat
FAILED test_topology.py::test_layer_sharing_at_heterogeneous_depth_order - Ty...
================== 3 failed, 28 passed, 2 warnings in 7.64s ===================
