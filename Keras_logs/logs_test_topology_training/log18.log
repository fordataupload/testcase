2020-10-05 15:49:31.744902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:49:35.537155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-05 15:49:35.670394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:49:35.672232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:49:35.686152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:49:35.692937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:49:35.694935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:49:35.701355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:49:35.705606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:49:35.717981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:49:35.718939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:49:35.719695: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-05 15:49:35.733426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:49:35.734054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:49:35.734417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:49:35.734761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:49:35.735099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:49:35.735450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:49:35.735794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:49:35.736139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:49:35.736971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:49:36.826564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-05 15:49:36.826982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-05 15:49:36.827215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-05 15:49:36.827993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 31 items

test_topology.py .........F............F......F.                         [100%]

================================== FAILURES ===================================
___________________________ test_multi_input_layer ____________________________

    def test_multi_input_layer():
        ####################################################
        # test multi-input layer
        a = Input(shape=(32,), name='input_a')
        b = Input(shape=(32,), name='input_b')
    
        dense = Dense(16, name='dense_1')
        a_2 = dense(a)
        b_2 = dense(b)
    
        merged = layers.concatenate([a_2, b_2], name='merge')
        assert merged._keras_shape == (None, 16 * 2)
        merge_layer, merge_node_index, merge_tensor_index = merged._keras_history
    
        assert merge_node_index == 0
        assert merge_tensor_index == 0
    
        assert len(merge_layer._inbound_nodes) == 1
        assert len(merge_layer._outbound_nodes) == 0
    
        assert len(merge_layer._inbound_nodes[0].input_tensors) == 2
        assert len(merge_layer._inbound_nodes[0].inbound_layers) == 2
    
        c = Dense(64, name='dense_2')(merged)
        d = Dense(5, name='dense_3')(c)
    
        model = Model(inputs=[a, b], outputs=[c, d], name='model')
        assert len(model.layers) == 6
        expected_shapes = [(None, 64), (None, 5)]
        assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes
        assert model.compute_mask([a, b], [None, None]) == [None, None]
        assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes
    
        # we don't check names of first 2 layers (inputs) because
        # ordering of same-level layers is not fixed
        expected_names = ['dense_1', 'merge', 'dense_2', 'dense_3']
        assert [l.name for l in model.layers][2:] == expected_names
        assert [l.name for l in model._input_layers] == ['input_a', 'input_b']
        assert [l.name for l in model._output_layers] == ['dense_2', 'dense_3']
    
        # actually run model
        fn = K.function(model.inputs, model.outputs)
        input_a_np = np.random.random((10, 32))
        input_b_np = np.random.random((10, 32))
        fn_outputs = fn([input_a_np, input_b_np])
        assert [x.shape for x in fn_outputs] == [(10, 64), (10, 5)]
    
        # test get_source_inputs
        source_inputs = get_source_inputs(c)
        assert source_inputs[0] is a
        assert source_inputs[1] is b
    
        # serialization / deserialization
        json_config = model.to_json()
        recreated_model = model_from_json(json_config)
>       recreated_model.compile('rmsprop', 'mse')

test_topology.py:308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x0000018DE4347EF0>
metrics_dict = None
y_true = <tf.Tensor 'dense_2_target:0' shape=(?, ?) dtype=float32>
y_pred = <tf.Tensor 'dense_2_1/BiasAdd:0' shape=(?, 64) dtype=float32>
mask = None, weights = None

    def _handle_per_output_metrics(self,
                                   metrics_dict,
                                   y_true,
                                   y_pred,
                                   mask,
                                   weights=None):
        """Calls metric functions for a single output.
    
        # Arguments
            metrics_dict: A dict with metric names as keys and metric fns as values.
            y_true: Target output.
            y_pred: Predicted output.
            mask: Computed mask value for the current output.
            weights: Weights to be applied on the current output.
        """
    
>       for metric_name, metric_fn in metrics_dict.items():
E       AttributeError: 'NoneType' object has no attribute 'items'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:839: AttributeError
---------------------------- Captured stderr call -----------------------------
2020-10-05 15:49:38.289795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:49:38.290421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:49:38.290766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:49:38.291113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:49:38.291448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:49:38.291794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:49:38.292137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:49:38.292485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:49:38.293125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:49:38.293438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-05 15:49:38.293786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-05 15:49:38.294003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-05 15:49:38.294605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
_______________________ test_recursion_with_bn_and_loss _______________________

    def test_recursion_with_bn_and_loss():
        model1 = Sequential([
            layers.Dense(5, input_dim=5, activity_regularizer='l1'),
            layers.BatchNormalization(),
            layers.Dense(5),
        ])
    
        print('NEW MODEL')
        inputs = layers.Input(shape=(5,))
        outputs = model1(inputs)
        model2 = Model(inputs=inputs, outputs=outputs)
    
        assert len(model1.updates) == 2
        assert len(model2.updates) == 2
        assert len(model1.losses) == 1
        assert len(model2.losses) == 1, model2.layers[1]._per_input_losses
    
>       model1.compile(optimizer='sgd', loss='categorical_crossentropy')

test_topology.py:655: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:222: in compile
    masks=masks)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:871: in _handle_metrics
    self._per_output_metrics[i], target, output, output_mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.sequential.Sequential object at 0x0000018D9EA6E128>
metrics_dict = None
y_true = <tf.Tensor 'dense_2_target:0' shape=(?, ?) dtype=float32>
y_pred = <tf.Tensor 'dense_2/BiasAdd:0' shape=(?, 5) dtype=float32>, mask = None
weights = None

    def _handle_per_output_metrics(self,
                                   metrics_dict,
                                   y_true,
                                   y_pred,
                                   mask,
                                   weights=None):
        """Calls metric functions for a single output.
    
        # Arguments
            metrics_dict: A dict with metric names as keys and metric fns as values.
            y_true: Target output.
            y_pred: Predicted output.
            mask: Computed mask value for the current output.
            weights: Weights to be applied on the current output.
        """
    
>       for metric_name, metric_fn in metrics_dict.items():
E       AttributeError: 'NoneType' object has no attribute 'items'

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:839: AttributeError
---------------------------- Captured stdout call -----------------------------
NEW MODEL
____________________ test_constant_initializer_with_numpy _____________________

    def test_constant_initializer_with_numpy():
        model = Sequential()
        model.add(Dense(2, input_shape=(3,),
                        kernel_initializer=Constant(1.)))
        model.add(Dense(3))
>       model.compile(loss='mse', optimizer='sgd', metrics=['acc'])

test_topology.py:833: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:214: in compile
    self._set_metric_attributes()
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:806: in _set_metric_attributes
    self._per_output_metrics[i], i))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.sequential.Sequential object at 0x000001902F8A09E8>
metrics_dict = OrderedDict([('acc', <keras.metrics.MeanMetricWrapper object at 0x000001902FA785F8>)])
output_index = 0

    def _set_per_output_metric_attributes(self, metrics_dict, output_index):
        """Sets the metric attributes on the model for the given output.
    
        # Arguments
            metrics_dict: A dict with metric names as keys and metric fns as values.
            output_index: The index of the model output for which the metric
                attributes are added.
    
        # Returns
            Metrics dict updated with unique metric names as keys.
        """
        updated_metrics_dict = None
        for metric_name, metric_fn in metrics_dict.items():
            metric_name = self._add_unique_metric_name(metric_name, output_index)
    
            # Update the name on the metric class to be the unique generated name.
            metric_fn.name = metric_name
>           updated_metrics_dict[metric_name] = metric_fn
E           TypeError: 'NoneType' object does not support item assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:789: TypeError
============================== warnings summary ===============================
test_topology.py::test_recursion
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_1.
  Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.
  The tensor that caused the issue was: dense_1_12/BiasAdd:0
    str(x.name))

test_topology.py::test_activity_regularization_with_model_composition
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output model_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_1.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
=========================== short test summary info ===========================
FAILED test_topology.py::test_multi_input_layer - AttributeError: 'NoneType' ...
FAILED test_topology.py::test_recursion_with_bn_and_loss - AttributeError: 'N...
FAILED test_topology.py::test_constant_initializer_with_numpy - TypeError: 'N...
================== 3 failed, 28 passed, 2 warnings in 7.05s ===================
