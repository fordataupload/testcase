2020-10-05 15:47:42.315821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:47:44.911098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-05 15:47:45.045695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:47:45.047475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:47:45.053094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:47:45.058900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:47:45.060683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:47:45.067056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:47:45.071378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:47:45.083363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:47:45.084362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:47:45.085134: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-05 15:47:45.100321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:47:45.100881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:47:45.101225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:47:45.101569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:47:45.101905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:47:45.102248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:47:45.102592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:47:45.102940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:47:45.103802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:47:46.074428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-05 15:47:46.074845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-05 15:47:46.075092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-05 15:47:46.075859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 31 items

test_topology.py ......................FF.FFF...                         [100%]

================================== FAILURES ===================================
_______________________ test_recursion_with_bn_and_loss _______________________

    def test_recursion_with_bn_and_loss():
        model1 = Sequential([
            layers.Dense(5, input_dim=5, activity_regularizer='l1'),
            layers.BatchNormalization(),
            layers.Dense(5),
        ])
    
        print('NEW MODEL')
        inputs = layers.Input(shape=(5,))
        outputs = model1(inputs)
        model2 = Model(inputs=inputs, outputs=outputs)
    
        assert len(model1.updates) == 2
        assert len(model2.updates) == 2
        assert len(model1.losses) == 1
        assert len(model2.losses) == 1, model2.layers[1]._per_input_losses
    
        model1.compile(optimizer='sgd', loss='categorical_crossentropy')
        model2.compile(optimizer='sgd', loss='categorical_crossentropy')
    
        x = np.ones((3, 5))
        y = np.ones((3, 5))
>       model1.fit(x, y, verbose=0, epochs=1)

test_topology.py:660: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1154: in fit
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.sequential.Sequential object at 0x0000023CB3FDAF98>
x = array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]])
y = array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]])
sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = 32

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = None
        if not self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
>       if any(K.is_tensor(v) for v in all_inputs):
E       TypeError: 'NoneType' object is not iterable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:556: TypeError
---------------------------- Captured stdout call -----------------------------
NEW MODEL
_____________ test_activity_regularization_with_model_composition _____________

    def test_activity_regularization_with_model_composition():
    
        def reg(x):
            return K.sum(x)
    
        net_a_input = Input((2,))
        net_a = net_a_input
        net_a = Dense(2, kernel_initializer='ones',
                      use_bias=False,
                      activity_regularizer=reg)(net_a)
        model_a = Model([net_a_input], [net_a])
    
        net_b_input = Input((2,))
        net_b = model_a(net_b_input)
        model_b = Model([net_b_input], [net_b])
    
        model_b.compile(optimizer='sgd', loss=None)
        x = np.ones((1, 2))
>       loss = model_b.evaluate(x)

test_topology.py:682: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1349: in evaluate
    batch_size=batch_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x0000023CB3FDAA20>
x = array([[1., 1.]]), y = None, sample_weight = None, class_weight = None
check_array_lengths = True, batch_size = 32

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = None
        if not self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
>       if any(K.is_tensor(v) for v in all_inputs):
E       TypeError: 'NoneType' object is not iterable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:556: TypeError
__________________ test_layer_sharing_at_heterogeneous_depth __________________

    def test_layer_sharing_at_heterogeneous_depth():
        x_val = np.random.random((10, 5))
    
        x = Input(shape=(5,))
        A = Dense(5, name='A')
        B = Dense(5, name='B')
        output = A(B(A(B(x))))
        M = Model(x, output)
    
>       output_val = M.predict(x_val)

test_topology.py:723: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1441: in predict
    x, _, _ = self._standardize_user_data(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x0000023CB3EF2CF8>
x = array([[0.35890213, 0.75315631, 0.80315252, 0.81658767, 0.68814738],
       [0.49433953, 0.50050187, 0.7770156 , 0.081... 0.91012912, 0.32178832, 0.33114515, 0.26436859],
       [0.14714565, 0.20136593, 0.01660775, 0.3309503 , 0.88904855]])
y = None, sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = None
        if not self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
>       if any(K.is_tensor(v) for v in all_inputs):
E       TypeError: 'NoneType' object is not iterable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:556: TypeError
____________ test_layer_sharing_at_heterogeneous_depth_with_concat ____________

    def test_layer_sharing_at_heterogeneous_depth_with_concat():
        input_shape = (16, 9, 3)
        input_layer = Input(shape=input_shape)
    
        A = Dense(3, name='dense_A')
        B = Dense(3, name='dense_B')
        C = Dense(3, name='dense_C')
    
        x1 = B(A(input_layer))
        x2 = A(C(input_layer))
        output = layers.concatenate([x1, x2])
    
        M = Model(inputs=input_layer, outputs=output)
    
        x_val = np.random.random((10, 16, 9, 3))
>       output_val = M.predict(x_val)

test_topology.py:750: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1441: in predict
    x, _, _ = self._standardize_user_data(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x0000023CB429FC18>
x = array([[[[0.9082802 , 0.13490497, 0.5640816 ],
         [0.89542305, 0.25315916, 0.98015804],
         [0.83088247, 0....61040424, 0.66477743],
         [0.34381673, 0.72407714, 0.11756502],
         [0.70710522, 0.94085548, 0.78421127]]]])
y = None, sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = None
        if not self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
>       if any(K.is_tensor(v) for v in all_inputs):
E       TypeError: 'NoneType' object is not iterable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:556: TypeError
_______________ test_layer_sharing_at_heterogeneous_depth_order _______________

    def test_layer_sharing_at_heterogeneous_depth_order():
        # This tests for the bug in this issue
        # https://github.com/keras-team/keras/issues/11159
        # It occurs with layer sharing at heterogeneous depth when
        # the layers need to be applied in an order that differs from
        # the order that occurs in the config.
    
        input_shape = (1, 12)
        input_layer = Input(shape=input_shape)
    
        A = Dense(12, name='layer_a')
        r1 = layers.Reshape((12,))(input_layer)
        Aout1 = A(r1)
    
        r2 = layers.Reshape((12,))(A(input_layer))
        Aout2 = A(r2)
    
        # Note: if the order of the layers in the concat is
        # changed to ([Aout1, Aout2]) the bug doesn't trigger
        c1 = layers.concatenate([Aout2, Aout1])
        output = Dense(2, name='layer_b')(c1)
    
        M = Model(inputs=input_layer, outputs=output)
    
        x_val = np.random.random((10,) + input_shape)
>       output_val = M.predict(x_val)

test_topology.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1441: in predict
    x, _, _ = self._standardize_user_data(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.engine.training.Model object at 0x0000023CB43B80B8>
x = array([[[0.54688389, 0.86620797, 0.75891084, 0.73688615, 0.89963027,
         0.04598732, 0.2900752 , 0.24286255, 0.43... , 0.52277655,
         0.19477315, 0.15844916, 0.94881922, 0.69975998, 0.4947219 ,
         0.13133118, 0.94335976]]])
y = None, sample_weight = None, class_weight = None, check_array_lengths = True
batch_size = None

    def _standardize_user_data(self, x,
                               y=None,
                               sample_weight=None,
                               class_weight=None,
                               check_array_lengths=True,
                               batch_size=None):
        all_inputs = None
        if not self.built:
            # We need to use `x` to set the model inputs.
            # We type-check that `x` and `y` are either single arrays
            # or lists of arrays.
            if isinstance(x, (list, tuple)):
                if not all(isinstance(v, np.ndarray) or
                           K.is_tensor(v) for v in x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs += list(x)
            elif isinstance(x, dict):
                raise ValueError('Please do not pass a dictionary '
                                 'as model inputs.')
            else:
                if not isinstance(x, np.ndarray) and not K.is_tensor(x):
                    raise ValueError('Please provide as model inputs '
                                     'either a single '
                                     'array or a list of arrays. '
                                     'You passed: x=' + str(x))
                all_inputs.append(x)
    
            # Build the model using the retrieved inputs (value or symbolic).
            # If values, then in symbolic-mode placeholders will be created
            # to match the value shapes.
            if not self.inputs:
                self._set_inputs(x)
    
        if y is not None:
            if not self.optimizer:
                raise RuntimeError('You must compile a model before '
                                   'training/testing. '
                                   'Use `model.compile(optimizer, loss)`.')
            if not self._is_compiled:
                # On-the-fly compilation of the model.
                # We need to use `y` to set the model targets.
                if isinstance(y, (list, tuple)):
                    if not all(isinstance(v, np.ndarray) or
                               K.is_tensor(v) for v in y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                elif isinstance(y, dict):
                    raise ValueError('Please do not pass a dictionary '
                                     'as model targets.')
                else:
                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):
                        raise ValueError('Please provide as model targets '
                                         'either a single '
                                         'array or a list of arrays. '
                                         'You passed: y=' + str(y))
                # Typecheck that all inputs are *either* value *or* symbolic.
                if y is not None:
                    all_inputs += to_list(y, allow_tuple=True)
                if any(K.is_tensor(v) for v in all_inputs):
                    if not all(K.is_tensor(v) for v in all_inputs):
                        raise ValueError('Do not pass inputs that mix Numpy '
                                         'arrays and symbolic tensors. '
                                         'You passed: x=' + str(x) +
                                         '; y=' + str(y))
    
                # Handle target tensors if any passed.
                y = to_list(y, allow_tuple=True)
                target_tensors = [v for v in y if K.is_tensor(v)]
                if not target_tensors:
                    target_tensors = None
                self.compile(optimizer=self.optimizer,
                             loss=self.loss,
                             metrics=self._compile_metrics,
                             weighted_metrics=self._compile_weighted_metrics,
                             loss_weights=self.loss_weights,
                             target_tensors=target_tensors)
    
        # If `x` and `y` were all symbolic,
        # then the model should not be fed any inputs and targets.
        # Note: in this case, `any` and `all` are equivalent since we disallow
        # mixed symbolic/value inputs.
>       if any(K.is_tensor(v) for v in all_inputs):
E       TypeError: 'NoneType' object is not iterable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:556: TypeError
============================== warnings summary ===============================
test_topology.py::test_recursion
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_1.
  Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.
  The tensor that caused the issue was: dense_1_12/BiasAdd:0
    str(x.name))

test_topology.py::test_activity_regularization_with_model_composition
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output model_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_1.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
=========================== short test summary info ===========================
FAILED test_topology.py::test_recursion_with_bn_and_loss - TypeError: 'NoneTy...
FAILED test_topology.py::test_activity_regularization_with_model_composition
FAILED test_topology.py::test_layer_sharing_at_heterogeneous_depth - TypeErro...
FAILED test_topology.py::test_layer_sharing_at_heterogeneous_depth_with_concat
FAILED test_topology.py::test_layer_sharing_at_heterogeneous_depth_order - Ty...
================== 5 failed, 26 passed, 2 warnings in 6.50s ===================
