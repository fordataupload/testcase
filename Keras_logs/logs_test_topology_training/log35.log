2020-10-05 15:53:27.081287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:53:30.852191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-05 15:53:30.971101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:53:30.973037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:53:30.977442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:53:30.982141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:53:30.983823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:53:30.988904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:53:30.992222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:53:31.001520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:53:31.002494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:53:31.003126: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-05 15:53:31.015878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:73:00.0
2020-10-05 15:53:31.016458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-10-05 15:53:31.016800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-10-05 15:53:31.017146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-10-05 15:53:31.017491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-10-05 15:53:31.017837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-10-05 15:53:31.018184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-10-05 15:53:31.018531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-05 15:53:31.019369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-10-05 15:53:31.975876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-05 15:53:31.976295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-10-05 15:53:31.976535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-10-05 15:53:31.977269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8686 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:73:00.0, compute capability: 7.5)
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\engine
plugins: flaky-3.7.0
collected 31 items

test_topology.py ......................F........                         [100%]

================================== FAILURES ===================================
_______________________ test_recursion_with_bn_and_loss _______________________

    def test_recursion_with_bn_and_loss():
        model1 = Sequential([
            layers.Dense(5, input_dim=5, activity_regularizer='l1'),
            layers.BatchNormalization(),
            layers.Dense(5),
        ])
    
        print('NEW MODEL')
        inputs = layers.Input(shape=(5,))
        outputs = model1(inputs)
        model2 = Model(inputs=inputs, outputs=outputs)
    
        assert len(model1.updates) == 2
        assert len(model2.updates) == 2
        assert len(model1.losses) == 1
        assert len(model2.losses) == 1, model2.layers[1]._per_input_losses
    
        model1.compile(optimizer='sgd', loss='categorical_crossentropy')
        model2.compile(optimizer='sgd', loss='categorical_crossentropy')
    
        x = np.ones((3, 5))
        y = np.ones((3, 5))
>       model1.fit(x, y, verbose=0, epochs=1)

test_topology.py:660: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training.py:1239: in fit
    validation_freq=validation_freq)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = <keras.engine.sequential.Sequential object at 0x000001B030FCAFD0>
fit_function = None
fit_inputs = [array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]]), array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]]), array([1., 1., 1.], dtype=float32), 1]
out_labels = ['loss'], batch_size = 32, epochs = 1, verbose = 0
callbacks = <keras.callbacks.callbacks.CallbackList object at 0x000001B031063DD8>
val_function = None, val_inputs = [], shuffle = True, initial_epoch = 0
steps_per_epoch = None, validation_steps = None, validation_freq = 1

    def fit_loop(model, fit_function, fit_inputs,
                 out_labels=None,
                 batch_size=None,
                 epochs=100,
                 verbose=1,
                 callbacks=None,
                 val_function=None,
                 val_inputs=None,
                 shuffle=True,
                 initial_epoch=0,
                 steps_per_epoch=None,
                 validation_steps=None,
                 validation_freq=1):
        """Abstract fit function for `fit_function(fit_inputs)`.
    
        Assumes that fit_function returns a list, labeled by out_labels.
    
        # Arguments
            model: Keras model instance.
            fit_function: Keras function returning a list of tensors
            fit_inputs: List of tensors to be fed to `fit_function`
            out_labels: List of strings, display names of
                the outputs of `fit_function`
            batch_size: Integer batch size or None if unknown.
            epochs: Number of times to iterate over the data
            verbose: Verbosity mode, 0, 1 or 2
            callbacks: List of callbacks to be called during training and validation
                (if `val_function` and `val_inputs` are not `None`).
            val_function: Keras function to call for validation
            val_inputs: List of tensors to be fed to `val_function`
            shuffle: Whether to shuffle the data at the beginning of each epoch
            initial_epoch: Epoch at which to start training
                (useful for resuming a previous training run)
            steps_per_epoch: Total number of steps (batches of samples)
                before declaring one epoch finished and starting the
                next epoch. Ignored with the default value of `None`.
            validation_steps: Number of steps to run validation for
                (only if doing validation from data tensors).
                Ignored with the default value of `None`.
            validation_freq: Only relevant if validation data is provided. Integer
                or list/tuple/set. If an integer, specifies how many training
                epochs to run before a new validation run is performed, e.g.
                validation_freq=2` runs validation every 2 epochs. If a list,
                tuple, or set, specifies the epochs on which to run validation,
                e.g. `validation_freq=[1, 2, 10]` runs validation at the end
                of the 1st, 2nd, and 10th epochs.
    
        # Returns
            `History` object.
        """
        do_validation = False
        if val_function and val_inputs:
            do_validation = True
            if (verbose and fit_inputs and
               hasattr(fit_inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):
                print('Train on %d samples, validate on %d samples' %
                      (fit_inputs[0].shape[0], val_inputs[0].shape[0]))
        if validation_steps:
            do_validation = True
            if steps_per_epoch is None:
                raise ValueError('Can only use `validation_steps` '
                                 'when doing step-wise '
                                 'training, i.e. `steps_per_epoch` '
                                 'must be set.')
        elif do_validation:
            if steps_per_epoch:
                raise ValueError('Must specify `validation_steps` '
                                 'to perform validation '
                                 'when doing step-wise training.')
    
        num_train_samples = check_num_samples(fit_inputs,
                                              batch_size=batch_size,
                                              steps=steps_per_epoch,
                                              steps_name='steps_per_epoch')
        if num_train_samples is not None:
            index_array = np.arange(num_train_samples)
    
        model.history = cbks.History()
        _callbacks = [cbks.BaseLogger(stateful_metrics=model.metrics_names[1:])]
        if verbose:
            if steps_per_epoch is not None:
                count_mode = 'steps'
            else:
                count_mode = 'samples'
            _callbacks.append(
                cbks.ProgbarLogger(count_mode, stateful_metrics=model.metrics_names[1:]))
        _callbacks += (callbacks or []) + [model.history]
        callbacks = cbks.CallbackList(_callbacks)
        out_labels = out_labels or []
    
        # it's possible to callback a different model than itself
        # (used by Sequential models)
        callback_model = model._get_callback_model()
        callback_metrics = list(model.metrics_names)
        if do_validation:
            callback_metrics += ['val_' + n for n in model.metrics_names]
    
        callbacks.set_model(callback_model)
        callbacks.set_params({
            'batch_size': batch_size,
            'epochs': epochs,
            'steps': steps_per_epoch,
            'samples': num_train_samples,
            'verbose': verbose,
            'do_validation': do_validation,
            'metrics': callback_metrics,
        })
        callbacks._call_begin_hook('train')
        callbacks.model.stop_training = False
        for cbk in callbacks:
            cbk.validation_data = val_inputs
    
        # To prevent a slowdown,
        # we find beforehand the arrays that need conversion.
        feed = (model._feed_inputs +
                model._feed_targets +
                model._feed_sample_weights)
        indices_for_conversion_to_dense = []
        for i in range(len(feed)):
            if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):
                indices_for_conversion_to_dense.append(i)
    
        for epoch in range(initial_epoch, epochs):
            model.reset_metrics()
            callbacks.on_epoch_begin(epoch)
            epoch_logs = {}
            if steps_per_epoch is not None:
                for step_index in range(steps_per_epoch):
                    batch_logs = {'batch': step_index, 'size': 1}
                    callbacks._call_batch_hook('train', 'begin', step_index, batch_logs)
                    outs = fit_function(fit_inputs)
    
                    outs = to_list(outs)
                    for l, o in zip(out_labels, outs):
                        batch_logs[l] = o
    
                    callbacks._call_batch_hook('train', 'end', step_index, batch_logs)
                    if callback_model.stop_training:
                        break
    
                if do_validation and should_run_validation(validation_freq, epoch):
                    val_outs = test_loop(model, val_function, val_inputs,
                                         steps=validation_steps,
                                         callbacks=callbacks,
                                         verbose=0)
                    val_outs = to_list(val_outs)
                    # Same labels assumed.
                    for l, o in zip(out_labels, val_outs):
                        epoch_logs['val_' + l] = o
            else:
                if shuffle == 'batch':
                    index_array = batch_shuffle(index_array, batch_size)
                elif shuffle:
                    np.random.shuffle(index_array)
    
                batches = make_batches(num_train_samples, batch_size)
                for batch_index, (batch_start, batch_end) in enumerate(batches):
                    batch_ids = index_array[batch_start:batch_end]
                    try:
                        if isinstance(fit_inputs[-1], int):
                            # Do not slice the training phase flag.
                            ins_batch = slice_arrays(
                                fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]
                        else:
                            ins_batch = slice_arrays(fit_inputs, batch_ids)
                    except TypeError:
                        raise TypeError('TypeError while preparing batch. '
                                        'If using HDF5 input data, '
                                        'pass shuffle="batch".')
                    batch_logs = {'batch': batch_index, 'size': len(batch_ids)}
                    callbacks._call_batch_hook('train', 'begin', batch_index, batch_logs)
                    for i in indices_for_conversion_to_dense:
                        ins_batch[i] = ins_batch[i].toarray()
    
>                   outs = fit_function(ins_batch)
E                   TypeError: 'NoneType' object is not callable

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_arrays.py:196: TypeError
---------------------------- Captured stdout call -----------------------------
NEW MODEL
============================== warnings summary ===============================
test_topology.py::test_recursion
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_1.
  Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.
  The tensor that caused the issue was: dense_1_12/BiasAdd:0
    str(x.name))

test_topology.py::test_activity_regularization_with_model_composition
  C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\training_utils.py:819: UserWarning: Output model_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_1.
    'be expecting any data to be passed to {0}.'.format(name))

-- Docs: https://docs.pytest.org/en/stable/warnings.html
=========================== short test summary info ===========================
FAILED test_topology.py::test_recursion_with_bn_and_loss - TypeError: 'NoneTy...
================== 1 failed, 30 passed, 2 warnings in 7.11s ===================
