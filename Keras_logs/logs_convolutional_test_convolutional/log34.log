2020-10-03 17:08:18.433890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
============================= test session starts =============================
platform win32 -- Python 3.6.12, pytest-6.0.2, py-1.9.0, pluggy-0.13.1
rootdir: C:\Users\mutation\Desktop\testcase\tests\keras\layers
plugins: flaky-3.7.0
collected 110 items

convolutional_test.py ........FFFFF..................................... [ 45%]
..............FFFF........................................FF             [100%]

================================== FAILURES ===================================
_____________________ test_convolution_2d[strides0-valid] _____________________

strides = (1, 1), padding = 'valid'

    @pytest.mark.parametrize(
        'strides,padding',
        [(strides, padding)
         for padding in _convolution_paddings
         for strides in [(1, 1), (2, 2)]
         if not (padding == 'same' and strides != (1, 1))]
    )
    def test_convolution_2d(strides, padding):
        num_samples = 2
        filters = 2
        stack_size = 3
        kernel_size = (3, 2)
        num_row = 7
        num_col = 6
    
        layer_test(convolutional.Conv2D,
                   kwargs={'filters': filters,
                           'kernel_size': kernel_size,
                           'padding': padding,
                           'strides': strides,
                           'data_format': 'channels_first'},
>                  input_shape=(num_samples, stack_size, num_row, num_col))

convolutional_test.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.layers.convolutional.Conv2D object at 0x000001AB1B529A90>
inputs = <tf.Tensor 'input_1:0' shape=(?, 3, 7, 6) dtype=float32>

    def call(self, inputs):
        if self.rank == 1:
            outputs = K.conv1d(
                inputs,
                self.kernel,
                strides=self.strides[0],
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate[0])
        if self.rank == 3:
            outputs = K.conv2d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
        if self.rank == 3:
            outputs = K.conv3d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
    
        if self.use_bias:
            outputs = K.bias_add(
>               outputs,
                self.bias,
                data_format=self.data_format)
E           UnboundLocalError: local variable 'outputs' referenced before assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:183: UnboundLocalError
_____________________ test_convolution_2d[strides1-valid] _____________________

strides = (2, 2), padding = 'valid'

    @pytest.mark.parametrize(
        'strides,padding',
        [(strides, padding)
         for padding in _convolution_paddings
         for strides in [(1, 1), (2, 2)]
         if not (padding == 'same' and strides != (1, 1))]
    )
    def test_convolution_2d(strides, padding):
        num_samples = 2
        filters = 2
        stack_size = 3
        kernel_size = (3, 2)
        num_row = 7
        num_col = 6
    
        layer_test(convolutional.Conv2D,
                   kwargs={'filters': filters,
                           'kernel_size': kernel_size,
                           'padding': padding,
                           'strides': strides,
                           'data_format': 'channels_first'},
>                  input_shape=(num_samples, stack_size, num_row, num_col))

convolutional_test.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.layers.convolutional.Conv2D object at 0x000001AB6A055860>
inputs = <tf.Tensor 'input_1:0' shape=(?, 3, 7, 6) dtype=float32>

    def call(self, inputs):
        if self.rank == 1:
            outputs = K.conv1d(
                inputs,
                self.kernel,
                strides=self.strides[0],
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate[0])
        if self.rank == 3:
            outputs = K.conv2d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
        if self.rank == 3:
            outputs = K.conv3d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
    
        if self.use_bias:
            outputs = K.bias_add(
>               outputs,
                self.bias,
                data_format=self.data_format)
E           UnboundLocalError: local variable 'outputs' referenced before assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:183: UnboundLocalError
_____________________ test_convolution_2d[strides2-same] ______________________

strides = (1, 1), padding = 'same'

    @pytest.mark.parametrize(
        'strides,padding',
        [(strides, padding)
         for padding in _convolution_paddings
         for strides in [(1, 1), (2, 2)]
         if not (padding == 'same' and strides != (1, 1))]
    )
    def test_convolution_2d(strides, padding):
        num_samples = 2
        filters = 2
        stack_size = 3
        kernel_size = (3, 2)
        num_row = 7
        num_col = 6
    
        layer_test(convolutional.Conv2D,
                   kwargs={'filters': filters,
                           'kernel_size': kernel_size,
                           'padding': padding,
                           'strides': strides,
                           'data_format': 'channels_first'},
>                  input_shape=(num_samples, stack_size, num_row, num_col))

convolutional_test.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.layers.convolutional.Conv2D object at 0x000001AB1B52D6A0>
inputs = <tf.Tensor 'input_1:0' shape=(?, 3, 7, 6) dtype=float32>

    def call(self, inputs):
        if self.rank == 1:
            outputs = K.conv1d(
                inputs,
                self.kernel,
                strides=self.strides[0],
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate[0])
        if self.rank == 3:
            outputs = K.conv2d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
        if self.rank == 3:
            outputs = K.conv3d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
    
        if self.use_bias:
            outputs = K.bias_add(
>               outputs,
                self.bias,
                data_format=self.data_format)
E           UnboundLocalError: local variable 'outputs' referenced before assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:183: UnboundLocalError
______________________ test_convolution_2d_channels_last ______________________

    def test_convolution_2d_channels_last():
        num_samples = 2
        filters = 2
        stack_size = 3
        num_row = 7
        num_col = 6
        padding = 'valid'
        strides = (2, 2)
    
        layer_test(convolutional.Conv2D,
                   kwargs={'filters': filters,
                           'kernel_size': 3,
                           'padding': padding,
                           'data_format': 'channels_last',
                           'activation': None,
                           'kernel_regularizer': 'l2',
                           'bias_regularizer': 'l2',
                           'activity_regularizer': 'l2',
                           'kernel_constraint': 'max_norm',
                           'bias_constraint': 'max_norm',
                           'strides': strides},
>                  input_shape=(num_samples, num_row, num_col, stack_size))

convolutional_test.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.layers.convolutional.Conv2D object at 0x000001AB6A01E828>
inputs = <tf.Tensor 'input_1:0' shape=(?, 7, 6, 3) dtype=float32>

    def call(self, inputs):
        if self.rank == 1:
            outputs = K.conv1d(
                inputs,
                self.kernel,
                strides=self.strides[0],
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate[0])
        if self.rank == 3:
            outputs = K.conv2d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
        if self.rank == 3:
            outputs = K.conv3d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
    
        if self.use_bias:
            outputs = K.bias_add(
>               outputs,
                self.bias,
                data_format=self.data_format)
E           UnboundLocalError: local variable 'outputs' referenced before assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:183: UnboundLocalError
________________________ test_convolution_2d_dilation _________________________

    @pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),
                        reason='cntk only supports dilated conv on GPU')
    def test_convolution_2d_dilation():
        num_samples = 2
        filters = 2
        stack_size = 3
        kernel_size = (3, 2)
        num_row = 7
        num_col = 6
        padding = 'valid'
    
        layer_test(convolutional.Conv2D,
                   kwargs={'filters': filters,
                           'kernel_size': kernel_size,
                           'padding': padding,
                           'dilation_rate': (2, 2)},
>                  input_shape=(num_samples, num_row, num_col, stack_size))

convolutional_test.py:175: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.layers.convolutional.Conv2D object at 0x000001AB69FE7128>
inputs = <tf.Tensor 'input_1:0' shape=(?, 7, 6, 3) dtype=float32>

    def call(self, inputs):
        if self.rank == 1:
            outputs = K.conv1d(
                inputs,
                self.kernel,
                strides=self.strides[0],
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate[0])
        if self.rank == 3:
            outputs = K.conv2d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
        if self.rank == 3:
            outputs = K.conv3d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
    
        if self.use_bias:
            outputs = K.bias_add(
>               outputs,
                self.bias,
                data_format=self.data_format)
E           UnboundLocalError: local variable 'outputs' referenced before assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:183: UnboundLocalError
_____________________ test_convolution_3d[valid-strides0] _____________________

padding = 'valid', strides = (1, 1, 1)

    @pytest.mark.parametrize(
        'padding,strides',
        [(padding, strides)
         for padding in _convolution_paddings
         for strides in [(1, 1, 1), (2, 2, 2)]
         if not (padding == 'same' and strides != (1, 1, 1))]
    )
    def test_convolution_3d(padding, strides):
        num_samples = 2
        filters = 2
        stack_size = 3
    
        input_len_dim1 = 9
        input_len_dim2 = 8
        input_len_dim3 = 8
    
        layer_test(convolutional.Convolution3D,
                   kwargs={'filters': filters,
                           'kernel_size': 3,
                           'padding': padding,
                           'strides': strides},
                   input_shape=(num_samples,
                                input_len_dim1, input_len_dim2, input_len_dim3,
>                               stack_size))

convolutional_test.py:521: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:171: in call
    dilation_rate=self.dilation_rate)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:3717: in conv2d
    **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:898: in convolution
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:1009: in convolution_internal
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py:1553: in conv3d
    dilations=dilations, name=name)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x000001AB50910E80>
op_type_name = 'Conv3D', name = 'conv3d_1/convolution/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x000001AB50903978>
op_def = name: "Conv3D"
input_arg {
  name: "input"
  type_attr: "T"
}
input_arg {
  name: "filter"
  type_attr: "T"
}
output_a...s"
  type: "list(int)"
  default_value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x000001AB6B847748>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type %s that does not "
                    "match type %s of argument '%s'." %
                    (input_name, op_type_name, dtypes.as_dtype(attr_value).name,
                     dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
>                                    attr_def.allowed_values.list.s))))
E               ValueError: Attr 'data_format' of 'Conv3D' Op passed string 'NHWC' not in: "NDHWC", "NCDHW".

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:714: ValueError
_____________________ test_convolution_3d[valid-strides1] _____________________

padding = 'valid', strides = (2, 2, 2)

    @pytest.mark.parametrize(
        'padding,strides',
        [(padding, strides)
         for padding in _convolution_paddings
         for strides in [(1, 1, 1), (2, 2, 2)]
         if not (padding == 'same' and strides != (1, 1, 1))]
    )
    def test_convolution_3d(padding, strides):
        num_samples = 2
        filters = 2
        stack_size = 3
    
        input_len_dim1 = 9
        input_len_dim2 = 8
        input_len_dim3 = 8
    
        layer_test(convolutional.Convolution3D,
                   kwargs={'filters': filters,
                           'kernel_size': 3,
                           'padding': padding,
                           'strides': strides},
                   input_shape=(num_samples,
                                input_len_dim1, input_len_dim2, input_len_dim3,
>                               stack_size))

convolutional_test.py:521: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:171: in call
    dilation_rate=self.dilation_rate)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:3717: in conv2d
    **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:898: in convolution
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:1009: in convolution_internal
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py:1553: in conv3d
    dilations=dilations, name=name)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x000001AB50910E80>
op_type_name = 'Conv3D', name = 'conv3d_1/convolution/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x000001AB50903978>
op_def = name: "Conv3D"
input_arg {
  name: "input"
  type_attr: "T"
}
input_arg {
  name: "filter"
  type_attr: "T"
}
output_a...s"
  type: "list(int)"
  default_value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x000001AB6C390EB8>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type %s that does not "
                    "match type %s of argument '%s'." %
                    (input_name, op_type_name, dtypes.as_dtype(attr_value).name,
                     dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
>                                    attr_def.allowed_values.list.s))))
E               ValueError: Attr 'data_format' of 'Conv3D' Op passed string 'NHWC' not in: "NDHWC", "NCDHW".

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:714: ValueError
_____________________ test_convolution_3d[same-strides2] ______________________

padding = 'same', strides = (1, 1, 1)

    @pytest.mark.parametrize(
        'padding,strides',
        [(padding, strides)
         for padding in _convolution_paddings
         for strides in [(1, 1, 1), (2, 2, 2)]
         if not (padding == 'same' and strides != (1, 1, 1))]
    )
    def test_convolution_3d(padding, strides):
        num_samples = 2
        filters = 2
        stack_size = 3
    
        input_len_dim1 = 9
        input_len_dim2 = 8
        input_len_dim3 = 8
    
        layer_test(convolutional.Convolution3D,
                   kwargs={'filters': filters,
                           'kernel_size': 3,
                           'padding': padding,
                           'strides': strides},
                   input_shape=(num_samples,
                                input_len_dim1, input_len_dim2, input_len_dim3,
>                               stack_size))

convolutional_test.py:521: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:171: in call
    dilation_rate=self.dilation_rate)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:3717: in conv2d
    **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:898: in convolution
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:1009: in convolution_internal
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py:1553: in conv3d
    dilations=dilations, name=name)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x000001AB50910E80>
op_type_name = 'Conv3D', name = 'conv3d_1/convolution/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x000001AB50903978>
op_def = name: "Conv3D"
input_arg {
  name: "input"
  type_attr: "T"
}
input_arg {
  name: "filter"
  type_attr: "T"
}
output_a...s"
  type: "list(int)"
  default_value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x000001AB6C1FAA20>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type %s that does not "
                    "match type %s of argument '%s'." %
                    (input_name, op_type_name, dtypes.as_dtype(attr_value).name,
                     dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
>                                    attr_def.allowed_values.list.s))))
E               ValueError: Attr 'data_format' of 'Conv3D' Op passed string 'NHWC' not in: "NDHWC", "NCDHW".

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:714: ValueError
_____________________ test_convolution_3d_additional_args _____________________

    def test_convolution_3d_additional_args():
        num_samples = 2
        filters = 2
        stack_size = 3
        padding = 'valid'
        strides = (2, 2, 2)
    
        input_len_dim1 = 9
        input_len_dim2 = 8
        input_len_dim3 = 8
    
        layer_test(convolutional.Convolution3D,
                   kwargs={'filters': filters,
                           'kernel_size': (1, 2, 3),
                           'padding': padding,
                           'activation': None,
                           'kernel_regularizer': 'l2',
                           'bias_regularizer': 'l2',
                           'activity_regularizer': 'l2',
                           'kernel_constraint': 'max_norm',
                           'bias_constraint': 'max_norm',
                           'strides': strides},
                   input_shape=(num_samples,
                                input_len_dim1, input_len_dim2, input_len_dim3,
>                               stack_size))

convolutional_test.py:548: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:171: in call
    dilation_rate=self.dilation_rate)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:3717: in conv2d
    **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:898: in convolution
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:1009: in convolution_internal
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py:1553: in conv3d
    dilations=dilations, name=name)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x000001AB50910E80>
op_type_name = 'Conv3D', name = 'conv3d_1/convolution/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x000001AB50903978>
op_def = name: "Conv3D"
input_arg {
  name: "input"
  type_attr: "T"
}
input_arg {
  name: "filter"
  type_attr: "T"
}
output_a...s"
  type: "list(int)"
  default_value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x000001AB6C298320>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type %s that does not "
                    "match type %s of argument '%s'." %
                    (input_name, op_type_name, dtypes.as_dtype(attr_value).name,
                     dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
>                                    attr_def.allowed_values.list.s))))
E               ValueError: Attr 'data_format' of 'Conv3D' Op passed string 'NHWC' not in: "NDHWC", "NCDHW".

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:714: ValueError
___________________ test_conv_float64[input_shape1-Conv2D] ____________________

input_shape = (2, 4, 4, 2)
conv_class = <class 'keras.layers.convolutional.Conv2D'>

    @pytest.mark.skipif((K.backend() == 'cntk'),
                        reason='CNTK does not support float64')
    @pytest.mark.parametrize(
        'input_shape,conv_class',
        [((2, 4, 2), convolutional.Conv1D),
         ((2, 4, 4, 2), convolutional.Conv2D),
         ((2, 4, 4, 4, 2), convolutional.Conv3D)]
    )
    def test_conv_float64(input_shape, conv_class):
        kernel_size = 3
        strides = 1
        filters = 3
        K.set_floatx('float64')
        layer_test(conv_class,
                   kwargs={'filters': filters,
                           'kernel_size': kernel_size,
                           'padding': 'valid',
                           'strides': strides},
>                  input_shape=input_shape)

convolutional_test.py:1138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <keras.layers.convolutional.Conv2D object at 0x000001AB6B3CCE80>
inputs = <tf.Tensor 'input_1:0' shape=(?, 4, 4, 2) dtype=float64>

    def call(self, inputs):
        if self.rank == 1:
            outputs = K.conv1d(
                inputs,
                self.kernel,
                strides=self.strides[0],
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate[0])
        if self.rank == 3:
            outputs = K.conv2d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
        if self.rank == 3:
            outputs = K.conv3d(
                inputs,
                self.kernel,
                strides=self.strides,
                padding=self.padding,
                data_format=self.data_format,
                dilation_rate=self.dilation_rate)
    
        if self.use_bias:
            outputs = K.bias_add(
>               outputs,
                self.bias,
                data_format=self.data_format)
E           UnboundLocalError: local variable 'outputs' referenced before assignment

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:183: UnboundLocalError
___________________ test_conv_float64[input_shape2-Conv3D] ____________________

input_shape = (2, 4, 4, 4, 2)
conv_class = <class 'keras.layers.convolutional.Conv3D'>

    @pytest.mark.skipif((K.backend() == 'cntk'),
                        reason='CNTK does not support float64')
    @pytest.mark.parametrize(
        'input_shape,conv_class',
        [((2, 4, 2), convolutional.Conv1D),
         ((2, 4, 4, 2), convolutional.Conv2D),
         ((2, 4, 4, 4, 2), convolutional.Conv3D)]
    )
    def test_conv_float64(input_shape, conv_class):
        kernel_size = 3
        strides = 1
        filters = 3
        K.set_floatx('float64')
        layer_test(conv_class,
                   kwargs={'filters': filters,
                           'kernel_size': kernel_size,
                           'padding': 'valid',
                           'strides': strides},
>                  input_shape=input_shape)

convolutional_test.py:1138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\utils\test_utils.py:94: in layer_test
    y = layer(x)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\engine\base_layer.py:489: in __call__
    output = self.call(inputs, **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\layers\convolutional.py:171: in call
    dilation_rate=self.dilation_rate)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\keras\backend\tensorflow_backend.py:3717: in conv2d
    **kwargs)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:898: in convolution
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\nn_ops.py:1009: in convolution_internal
    name=name)
C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py:1553: in conv3d
    dilations=dilations, name=name)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.framework.op_def_library.OpDefLibrary object at 0x000001AB50910E80>
op_type_name = 'Conv3D', name = 'conv3d_1/convolution/', keywords = {}
op_info = <tensorflow.python.framework.op_def_library._OpInfo object at 0x000001AB50903978>
op_def = name: "Conv3D"
input_arg {
  name: "input"
  type_attr: "T"
}
input_arg {
  name: "filter"
  type_attr: "T"
}
output_a...s"
  type: "list(int)"
  default_value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}

g = <tensorflow.python.framework.ops.Graph object at 0x000001AB6A096438>
deprecation_version = 0, default_type_attr_map = {}

    def _apply_op_helper(self, op_type_name, name=None, **keywords):
      """Implementation of apply_op that returns output_structure, op."""
      op_info = self._ops.get(op_type_name, None)
      if op_info is None:
        raise RuntimeError("Unrecognized Op name " + op_type_name)
      op_def = op_info.op_def
    
      # Determine the graph context.
      try:
        # Need to flatten all the arguments into a list.
        # pylint: disable=protected-access
        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))
        # pylint: enable=protected-access
      except AssertionError as e:
        raise RuntimeError(
            "Cannot determine graph for Op '%s' due to: %s"
            % (op_type_name, e.message))
    
      # Default name if not specified.
      if name is None:
        name = op_type_name
    
      # Check for deprecation
      deprecation_version = op_def.deprecation.version
      if deprecation_version:
        producer = g.graph_def_versions.producer
        if producer >= deprecation_version:
          raise NotImplementedError(
              ("Op %s is not available in GraphDef version %d. "
               "It has been removed in version %d. %s.") %
              (op_type_name, producer, deprecation_version,
               op_def.deprecation.explanation))
    
      # Fill in the list of default types for all "type" attrs.  This
      # will be used to choose a preferred dtype to convert to in the
      # absence of input type information.
      #
      # TODO(b/31302892): Currently the defaults don't work in the right
      # way if you have two inputs, one of whose type resolution depends
      # on the other.  Handling this will require restructuring this code
      # significantly.
      default_type_attr_map = {}
      for attr_def in op_def.attr:
        if attr_def.type != "type":
          continue
        key = attr_def.name
        if attr_def.HasField("default_value"):
          default_type_attr_map[key] = dtypes.as_dtype(
              attr_def.default_value.type)
    
      # Requires that op_def has passed validation (using the C++
      # ValidateOpDef() from ../framework/op_def_util.h).
      attrs = {}
      inputs = []
      input_types = []
      with g.as_default(), ops.name_scope(name) as scope:
    
        # Perform input type inference
        inferred_from = {}
        for input_arg in op_def.input_arg:
          input_name = input_arg.name
          if input_name in keywords:
            values = keywords.pop(input_name)
          elif input_name + "_" in keywords:
            # Handle the case where the name is a keyword or built-in
            # for Python so we use the name + _ instead.
            input_name += "_"
            values = keywords.pop(input_name)
          else:
            raise TypeError("No argument for input " + input_name)
    
          # Goals:
          # * Convert values to Tensors if it contains constants.
          # * Verify that values is a list if that matches the input_arg's
          #   type.
          # * If the input_arg's type is determined by attrs, either set
          #   those attrs and validate those attr values are legal (if
          #   they have not yet been set) or validate the input matches
          #   the type indicated by the attrs (if they have already been
          #   inferred via an earlier input).
          # * If the input_arg has an explicit type, make sure the input
          #   conforms.
    
          if _IsListParameter(input_arg):
            if not _IsListValue(values):
              raise TypeError(
                  "Expected list for '%s' argument to '%s' Op, not %s." %
                  (input_name, op_type_name, values))
            # In cases where we expect all elements of the list to have the
            # same dtype, try to cast non-Tensor elements to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.number_attr:
              if input_arg.type_attr in attrs:
                dtype = attrs[input_arg.type_attr]
              else:
                for t in values:
                  if isinstance(t, ops.Tensor):
                    dtype = t.dtype
                    break
    
              # dtype still not found, prefer using the default dtype
              # from the attr.
              if dtype is None and input_arg.type_attr in default_type_attr_map:
                default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              if not input_arg.is_ref and dtype:
                dtype = dtypes.as_dtype(dtype).base_dtype
              values = ops.internal_convert_n_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype if dtype else None,
                  preferred_dtype=default_dtype,
                  as_ref=input_arg.is_ref)
              if input_arg.number_attr and len(
                  set(v.dtype.base_dtype for v in values)) > 1:
                raise TypeError()  # All types should match.
            except (TypeError, ValueError):
              # What types does the conversion function think values have?
              observed_types = []
              for value in values:
                try:
                  converted_value = ops.internal_convert_to_tensor(
                      value, as_ref=input_arg.is_ref)
                  observed_types.append(converted_value.dtype.base_dtype.name)
                except (TypeError, ValueError):
                  observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
              observed = ", ".join(observed_types)
    
              prefix = (
                  "Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                  (input_name, op_type_name, observed))
              if input_arg.number_attr:
                if input_arg.type != types_pb2.DT_INVALID:
                  raise TypeError("%s that do not match expected type %s." %
                                  (prefix, dtype.name))
                elif input_arg.type_attr in attrs:
                  raise TypeError("%s that do not match type %s inferred from "
                                  "earlier arguments." %
                                  (prefix, dtype.name))
                else:
                  raise TypeError("%s that don't all match." % prefix)
              else:
                raise TypeError(
                    "%s that are invalid. Tensors: %s" % (prefix, values))
    
            types = [x.dtype for x in values]
            inputs.extend(values)
          else:
            # In cases where we have an expected type, try to convert non-Tensor
            # arguments to that type.
            dtype = None
            default_dtype = None
            if input_arg.type != types_pb2.DT_INVALID:
              dtype = input_arg.type
            elif input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            elif input_arg.type_attr in default_type_attr_map:
              # The dtype could not be inferred solely from the inputs,
              # so we prefer the attr's default, so code that adds a new attr
              # with a default is backwards compatible.
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
            try:
              values = ops.internal_convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
            except TypeError as err:
              if dtype is None:
                raise err
              else:
                raise TypeError(
                    "Expected %s passed to parameter '%s' of op '%s', got %s of "
                    "type '%s' instead. Error: %s" %
                    (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,
                     repr(values), type(values).__name__, err))
            except ValueError:
              # What type does convert_to_tensor think it has?
              try:
                observed = ops.internal_convert_to_tensor(
                    values, as_ref=input_arg.is_ref).dtype.name
              except ValueError as err:
                raise ValueError(
                    "Tried to convert '%s' to a tensor and failed. Error: %s" %
                    (input_name, err))
              prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                        (input_name, op_type_name, observed))
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError("%s expected type of %s." %
                                (prefix, dtypes.as_dtype(input_arg.type).name))
              else:
                # Update the maps with the default, if needed.
                k = input_arg.type_attr
                if k in default_type_attr_map:
                  if k not in attrs:
                    attrs[k] = default_type_attr_map[k]
                    if k not in inferred_from:
                      inferred_from[k] = "Default in OpDef"
    
                raise TypeError(
                    "%s type %s of argument '%s'." %
                    (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
    
            types = [values.dtype]
            inputs.append(values)
          base_types = [x.base_dtype for x in types]
    
          if input_arg.number_attr:
            # <number-attr> * <type> or <number-attr> * <type-attr>
            if input_arg.number_attr in attrs:
              if len(values) != attrs[input_arg.number_attr]:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d must match "
                    "length %d of argument '%s'." %
                    (input_name, op_type_name, len(values),
                     attrs[input_arg.number_attr],
                     inferred_from[input_arg.number_attr]))
            else:
              attrs[input_arg.number_attr] = len(values)
              inferred_from[input_arg.number_attr] = input_name
              num_attr = _Attr(op_def, input_arg.number_attr)
              if num_attr.has_minimum and len(values) < num_attr.minimum:
                raise ValueError(
                    "List argument '%s' to '%s' Op with length %d shorter "
                    "than minimum length %d." %
                    (input_name, op_type_name, len(values), num_attr.minimum))
            # All tensors must have the same base type.
            if any(bt != base_types[0] for bt in base_types):
              raise TypeError(
                  "All tensors passed to '%s' of '%s' Op "
                  "must have the same type." %
                  (input_name, op_type_name))
            if input_arg.type != types_pb2.DT_INVALID:
              # <number-attr> * <type> case
              if base_types and base_types[0] != input_arg.type:
                assert False, "Unreachable"
            elif input_arg.type_attr in attrs:
              # <number-attr> * <type-attr> case, where <type-attr> already
              # has an inferred value.
              if base_types and base_types[0] != attrs[input_arg.type_attr]:
                assert False, "Unreachable"
            else:
              # <number-attr> * <type-attr> case, where we are now setting
              # the <type-attr> based on this input
              if not base_types:
                raise TypeError(
                    "Don't know how to infer type variable from empty input "
                    "list passed to input '%s' of '%s' Op." %
                    (input_name, op_type_name))
              attrs[input_arg.type_attr] = base_types[0]
              inferred_from[input_arg.type_attr] = input_name
              type_attr = _Attr(op_def, input_arg.type_attr)
              _SatisfiesTypeConstraint(base_types[0], type_attr,
                                       param_name=input_name)
          elif input_arg.type_attr:
            # <type-attr>
            attr_value = base_types[0]
            if input_arg.type_attr in attrs:
              if attrs[input_arg.type_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type %s that does not "
                    "match type %s of argument '%s'." %
                    (input_name, op_type_name, dtypes.as_dtype(attr_value).name,
                     dtypes.as_dtype(attrs[input_arg.type_attr]).name,
                     inferred_from[input_arg.type_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_attr),
                                         param_name=input_name)
              attrs[input_arg.type_attr] = attr_value
              inferred_from[input_arg.type_attr] = input_name
          elif input_arg.type_list_attr:
            # <type-list-attr>
            attr_value = base_types
            if input_arg.type_list_attr in attrs:
              if attrs[input_arg.type_list_attr] != attr_value:
                raise TypeError(
                    "Input '%s' of '%s' Op has type list of %s that does not "
                    "match type list %s of argument '%s'." %
                    (input_name, op_type_name,
                     ", ".join(dtypes.as_dtype(x).name for x in attr_value),
                     ", ".join(dtypes.as_dtype(x).name
                               for x in attrs[input_arg.type_list_attr]),
                     inferred_from[input_arg.type_list_attr]))
            else:
              for base_type in base_types:
                _SatisfiesTypeConstraint(base_type,
                                         _Attr(op_def, input_arg.type_list_attr),
                                         param_name=input_name)
              attrs[input_arg.type_list_attr] = attr_value
              inferred_from[input_arg.type_list_attr] = input_name
          else:
            # single Tensor with specified type
            if base_types[0] != input_arg.type:
              assert False, "Unreachable"
    
          if input_arg.is_ref:
            if not all(x._is_ref_dtype for x in types):  # pylint: disable=protected-access
              raise TypeError(
                  ("'%s' Op requires that input '%s' be a mutable tensor "
                   "(e.g.: a tf.Variable)") % (op_type_name, input_name))
            input_types.extend(types)
          else:
            input_types.extend(base_types)
    
        # Process remaining attrs
        for attr in op_def.attr:
          # Skip attrs that have already had their values inferred
          if attr.name in attrs:
            if attr.name in keywords:
              raise TypeError(
                  "Should not specify value for inferred attr '%s'." % attr.name)
            continue
          if attr.name in keywords:
            attrs[attr.name] = keywords.pop(attr.name)
          elif attr.name + "_" in keywords:
            # Attrs whose names match Python keywords have an extra '_'
            # appended, so we must check for that as well.
            attrs[attr.name] = keywords.pop(attr.name + "_")
          else:
            raise TypeError("No argument for attr " + attr.name)
    
        # Convert attr values to AttrValue protos.
        attr_protos = {}
        for attr_def in op_def.attr:
          key = attr_def.name
          value = attrs[key]
          attr_value = attr_value_pb2.AttrValue()
          if attr_def.HasField("default_value") and value is None:
            attr_value.CopyFrom(attr_def.default_value)
            attr_protos[key] = attr_value
            continue
          if attr_def.type.startswith("list("):
            if not _IsListValue(value):
              raise TypeError("Expected list for attr " + key)
            if attr_def.has_minimum:
              if len(value) < attr_def.minimum:
                raise ValueError("Attr '%s' of '%s' Op passed list of length %d "
                                 "less than minimum %d." %
                                 (key, op_type_name, len(value),
                                  attr_def.minimum))
            attr_value.list.SetInParent()
          if attr_def.type == "string":
            attr_value.s = _MakeStr(value, key)
            if attr_def.HasField("allowed_values"):
              if attr_value.s not in attr_def.allowed_values.list.s:
                raise ValueError(
                    "Attr '%s' of '%s' Op passed string '%s' not in: \"%s\"." %
                    (key, op_type_name, compat.as_text(attr_value.s),
                     '", "'.join(map(compat.as_text,
>                                    attr_def.allowed_values.list.s))))
E               ValueError: Attr 'data_format' of 'Conv3D' Op passed string 'NHWC' not in: "NDHWC", "NCDHW".

C:\ProgramData\Anaconda3\envs\keras\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:714: ValueError
=========================== short test summary info ===========================
FAILED convolutional_test.py::test_convolution_2d[strides0-valid] - UnboundLo...
FAILED convolutional_test.py::test_convolution_2d[strides1-valid] - UnboundLo...
FAILED convolutional_test.py::test_convolution_2d[strides2-same] - UnboundLoc...
FAILED convolutional_test.py::test_convolution_2d_channels_last - UnboundLoca...
FAILED convolutional_test.py::test_convolution_2d_dilation - UnboundLocalErro...
FAILED convolutional_test.py::test_convolution_3d[valid-strides0] - ValueErro...
FAILED convolutional_test.py::test_convolution_3d[valid-strides1] - ValueErro...
FAILED convolutional_test.py::test_convolution_3d[same-strides2] - ValueError...
FAILED convolutional_test.py::test_convolution_3d_additional_args - ValueErro...
FAILED convolutional_test.py::test_conv_float64[input_shape1-Conv2D] - Unboun...
FAILED convolutional_test.py::test_conv_float64[input_shape2-Conv3D] - ValueE...
======================= 11 failed, 99 passed in 31.10s ========================
